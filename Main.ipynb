{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPT0ipYE28wL",
        "outputId": "64830031-c78c-4ffd-c22b-41ded31a42a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n## install finrl library\\n!pip install wrds\\n!pip install swig\\n!pip install finrl==0.3.5\\n\\n## instal elegantrl\\n# !pip install elegantrl==0.3.3\\n\\n!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NEED TO INSTALL THE FOLLOWING WITH PIP FIRST:\n",
        "\n",
        "\"\"\"\n",
        "wrds,\n",
        "swig,\n",
        "finrl==0.3.5\n",
        "elegantrl==0.3.3\n",
        "git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from stable_baselines3.common.logger import configure\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RtUc_ofKmpdy"
      },
      "outputs": [],
      "source": [
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        ")\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "e3e37681-442d-43e9-9c68-9b05074164a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (14880, 8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "\n",
        "tickers_list = ['MSFT', 'AAPL', 'CAT', 'CSCO', 'NKE']\n",
        "\n",
        "df = YahooDownloader(start_date = '2012-01-01',\n",
        "                     end_date = '2023-10-31',\n",
        "                     ticker_list = tickers_list).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "736fd30d-93a5-4262-977b-d1674949af2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['MSFT', 'AAPL', 'CAT', 'CSCO', 'NKE']\n"
          ]
        }
      ],
      "source": [
        "print(tickers_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "47d495fa-e186-4921-ec51-b01092859a52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14880, 8)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "c029d2f9-31f5-440e-83b6-5318c104210d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>14.621429</td>\n",
              "      <td>14.732143</td>\n",
              "      <td>14.607143</td>\n",
              "      <td>12.449689</td>\n",
              "      <td>302220800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>92.769997</td>\n",
              "      <td>95.110001</td>\n",
              "      <td>92.769997</td>\n",
              "      <td>67.953003</td>\n",
              "      <td>8177000</td>\n",
              "      <td>CAT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>18.549999</td>\n",
              "      <td>18.860001</td>\n",
              "      <td>18.480000</td>\n",
              "      <td>12.924058</td>\n",
              "      <td>41236600</td>\n",
              "      <td>CSCO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>26.549999</td>\n",
              "      <td>26.959999</td>\n",
              "      <td>26.389999</td>\n",
              "      <td>21.278032</td>\n",
              "      <td>64731500</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>24.342501</td>\n",
              "      <td>24.497499</td>\n",
              "      <td>24.174999</td>\n",
              "      <td>21.074886</td>\n",
              "      <td>10944400</td>\n",
              "      <td>NKE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14875</th>\n",
              "      <td>2023-10-30</td>\n",
              "      <td>333.410004</td>\n",
              "      <td>339.450012</td>\n",
              "      <td>331.829987</td>\n",
              "      <td>336.626770</td>\n",
              "      <td>22828100</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14876</th>\n",
              "      <td>2023-10-30</td>\n",
              "      <td>169.020004</td>\n",
              "      <td>171.169998</td>\n",
              "      <td>168.869995</td>\n",
              "      <td>170.065933</td>\n",
              "      <td>51131000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14877</th>\n",
              "      <td>2023-10-30</td>\n",
              "      <td>240.940002</td>\n",
              "      <td>243.600006</td>\n",
              "      <td>239.179993</td>\n",
              "      <td>242.160004</td>\n",
              "      <td>4478300</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14878</th>\n",
              "      <td>2023-10-30</td>\n",
              "      <td>51.349998</td>\n",
              "      <td>51.639999</td>\n",
              "      <td>51.090000</td>\n",
              "      <td>51.171814</td>\n",
              "      <td>13322400</td>\n",
              "      <td>CSCO</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14879</th>\n",
              "      <td>2023-10-30</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>102.050003</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>101.458427</td>\n",
              "      <td>8206700</td>\n",
              "      <td>NKE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14880 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             date        open        high         low       close     volume  \\\n",
              "0      2012-01-03   14.621429   14.732143   14.607143   12.449689  302220800   \n",
              "1      2012-01-03   92.769997   95.110001   92.769997   67.953003    8177000   \n",
              "2      2012-01-03   18.549999   18.860001   18.480000   12.924058   41236600   \n",
              "3      2012-01-03   26.549999   26.959999   26.389999   21.278032   64731500   \n",
              "4      2012-01-03   24.342501   24.497499   24.174999   21.074886   10944400   \n",
              "...           ...         ...         ...         ...         ...        ...   \n",
              "14875  2023-10-30  333.410004  339.450012  331.829987  336.626770   22828100   \n",
              "14876  2023-10-30  169.020004  171.169998  168.869995  170.065933   51131000   \n",
              "14877  2023-10-30  240.940002  243.600006  239.179993  242.160004    4478300   \n",
              "14878  2023-10-30   51.349998   51.639999   51.090000   51.171814   13322400   \n",
              "14879  2023-10-30   99.000000  102.050003   99.000000  101.458427    8206700   \n",
              "\n",
              "        tic  day  \n",
              "0      AAPL    1  \n",
              "1       CAT    1  \n",
              "2      CSCO    1  \n",
              "3      MSFT    1  \n",
              "4       NKE    1  \n",
              "...     ...  ...  \n",
              "14875  MSFT    0  \n",
              "14876  AAPL    0  \n",
              "14877   CAT    0  \n",
              "14878  CSCO    0  \n",
              "14879   NKE    0  \n",
              "\n",
              "[14880 rows x 8 columns]"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.sort_values(['date','tic'],ignore_index=True).head()\n",
        "df.sort_values(['date'],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmKP-1ii3RLS",
        "outputId": "b33407d9-0e79-485a-c292-2e329b2a2d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (2975, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "\n",
        "\n",
        "feature_engineer = FeatureEngineer(\n",
        "    use_technical_indicator=True,\n",
        "    tech_indicator_list = ['macd',\n",
        "    'boll_ub',\n",
        "    'boll_lb',\n",
        "    'rsi_30',\n",
        "    'cci_30',\n",
        "    'dx_30',\n",
        "    'close_30_sma',\n",
        "    'close_60_sma'],\n",
        "    use_vix=True,\n",
        "    use_turbulence=True,\n",
        "    user_defined_feature = False)\n",
        "\n",
        "states_df = feature_engineer.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "import pandas as pd\n",
        "dates = list(pd.date_range(states_df['date'].min(),states_df['date'].max()).astype(str))\n",
        "\n",
        "preprocessed_df = pd.DataFrame(list(product(dates,tickers_list)),columns=[\"date\",\"tic\"])\n",
        "preprocessed_df = preprocessed_df.merge(states_df,how=\"left\",on=[\"date\",\"tic\"],)\n",
        "preprocessed_df = preprocessed_df[preprocessed_df['date'].isin(states_df['date'])]\n",
        "preprocessed_df = preprocessed_df.sort_values(['date','tic'])\n",
        "\n",
        "preprocessed_df = preprocessed_df.fillna(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>1.487500e+04</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "      <td>14875.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>87.925341</td>\n",
              "      <td>88.823777</td>\n",
              "      <td>87.011258</td>\n",
              "      <td>81.711926</td>\n",
              "      <td>5.318533e+07</td>\n",
              "      <td>2.024874</td>\n",
              "      <td>0.364079</td>\n",
              "      <td>85.793759</td>\n",
              "      <td>76.633687</td>\n",
              "      <td>53.993698</td>\n",
              "      <td>25.419957</td>\n",
              "      <td>24.035344</td>\n",
              "      <td>80.960192</td>\n",
              "      <td>80.175403</td>\n",
              "      <td>17.832192</td>\n",
              "      <td>5.082796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>69.802263</td>\n",
              "      <td>70.572683</td>\n",
              "      <td>68.999996</td>\n",
              "      <td>69.519045</td>\n",
              "      <td>1.044569e+08</td>\n",
              "      <td>1.398985</td>\n",
              "      <td>1.978481</td>\n",
              "      <td>73.222779</td>\n",
              "      <td>65.009080</td>\n",
              "      <td>9.108032</td>\n",
              "      <td>112.768150</td>\n",
              "      <td>17.081371</td>\n",
              "      <td>68.799795</td>\n",
              "      <td>68.013646</td>\n",
              "      <td>6.851859</td>\n",
              "      <td>9.983662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.856071</td>\n",
              "      <td>14.271429</td>\n",
              "      <td>13.753571</td>\n",
              "      <td>10.578132</td>\n",
              "      <td>5.857000e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-9.607839</td>\n",
              "      <td>11.796429</td>\n",
              "      <td>10.061002</td>\n",
              "      <td>25.806161</td>\n",
              "      <td>-519.458107</td>\n",
              "      <td>0.002358</td>\n",
              "      <td>11.423214</td>\n",
              "      <td>11.510131</td>\n",
              "      <td>9.140000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35.806250</td>\n",
              "      <td>36.121250</td>\n",
              "      <td>35.495001</td>\n",
              "      <td>31.222950</td>\n",
              "      <td>6.484750e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.265390</td>\n",
              "      <td>32.151753</td>\n",
              "      <td>29.122308</td>\n",
              "      <td>47.574028</td>\n",
              "      <td>-60.106072</td>\n",
              "      <td>10.040956</td>\n",
              "      <td>30.320554</td>\n",
              "      <td>29.099533</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>1.100484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>58.730000</td>\n",
              "      <td>59.349998</td>\n",
              "      <td>58.250000</td>\n",
              "      <td>54.248795</td>\n",
              "      <td>1.986530e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.231522</td>\n",
              "      <td>56.488090</td>\n",
              "      <td>51.163763</td>\n",
              "      <td>53.864373</td>\n",
              "      <td>43.016073</td>\n",
              "      <td>21.417965</td>\n",
              "      <td>53.548150</td>\n",
              "      <td>53.097536</td>\n",
              "      <td>16.070000</td>\n",
              "      <td>2.442872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>123.434998</td>\n",
              "      <td>124.844997</td>\n",
              "      <td>121.505001</td>\n",
              "      <td>116.092136</td>\n",
              "      <td>4.488855e+07</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.905560</td>\n",
              "      <td>123.432461</td>\n",
              "      <td>105.970707</td>\n",
              "      <td>59.981754</td>\n",
              "      <td>108.892142</td>\n",
              "      <td>35.287715</td>\n",
              "      <td>114.693447</td>\n",
              "      <td>114.526896</td>\n",
              "      <td>20.549999</td>\n",
              "      <td>5.185709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>361.750000</td>\n",
              "      <td>366.779999</td>\n",
              "      <td>352.440002</td>\n",
              "      <td>358.003845</td>\n",
              "      <td>1.506120e+09</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.481134</td>\n",
              "      <td>358.153223</td>\n",
              "      <td>327.322526</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>666.478672</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>338.987468</td>\n",
              "      <td>332.702074</td>\n",
              "      <td>82.690002</td>\n",
              "      <td>137.878037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               open          high           low         close        volume  \\\n",
              "count  14875.000000  14875.000000  14875.000000  14875.000000  1.487500e+04   \n",
              "mean      87.925341     88.823777     87.011258     81.711926  5.318533e+07   \n",
              "std       69.802263     70.572683     68.999996     69.519045  1.044569e+08   \n",
              "min       13.856071     14.271429     13.753571     10.578132  5.857000e+05   \n",
              "25%       35.806250     36.121250     35.495001     31.222950  6.484750e+06   \n",
              "50%       58.730000     59.349998     58.250000     54.248795  1.986530e+07   \n",
              "75%      123.434998    124.844997    121.505001    116.092136  4.488855e+07   \n",
              "max      361.750000    366.779999    352.440002    358.003845  1.506120e+09   \n",
              "\n",
              "                day          macd       boll_ub       boll_lb        rsi_30  \\\n",
              "count  14875.000000  14875.000000  14875.000000  14875.000000  14875.000000   \n",
              "mean       2.024874      0.364079     85.793759     76.633687     53.993698   \n",
              "std        1.398985      1.978481     73.222779     65.009080      9.108032   \n",
              "min        0.000000     -9.607839     11.796429     10.061002     25.806161   \n",
              "25%        1.000000     -0.265390     32.151753     29.122308     47.574028   \n",
              "50%        2.000000      0.231522     56.488090     51.163763     53.864373   \n",
              "75%        3.000000      0.905560    123.432461    105.970707     59.981754   \n",
              "max        4.000000     13.481134    358.153223    327.322526    100.000000   \n",
              "\n",
              "             cci_30         dx_30  close_30_sma  close_60_sma           vix  \\\n",
              "count  14875.000000  14875.000000  14875.000000  14875.000000  14875.000000   \n",
              "mean      25.419957     24.035344     80.960192     80.175403     17.832192   \n",
              "std      112.768150     17.081371     68.799795     68.013646      6.851859   \n",
              "min     -519.458107      0.002358     11.423214     11.510131      9.140000   \n",
              "25%      -60.106072     10.040956     30.320554     29.099533     13.370000   \n",
              "50%       43.016073     21.417965     53.548150     53.097536     16.070000   \n",
              "75%      108.892142     35.287715    114.693447    114.526896     20.549999   \n",
              "max      666.478672    100.000000    338.987468    332.702074     82.690002   \n",
              "\n",
              "         turbulence  \n",
              "count  14875.000000  \n",
              "mean       5.082796  \n",
              "std        9.983662  \n",
              "min        0.000000  \n",
              "25%        1.100484  \n",
              "50%        2.442872  \n",
              "75%        5.185709  \n",
              "max      137.878037  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qaVGjLtgbI",
        "outputId": "0fc3244d-de6e-4519-992f-1f7e12a5596e"
      },
      "outputs": [],
      "source": [
        "train = data_split(preprocessed_df, '2012-01-01','2020-07-01')\n",
        "test = data_split(preprocessed_df, '2020-07-01','2023-10-31')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "17d10eef-8f0b-4bce-a3fe-8a114f906e32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 51)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stock_size = len(tickers_list)\n",
        "state_space = 1 + 2*stock_size + len(['macd',\n",
        "    'boll_ub',\n",
        "    'boll_lb',\n",
        "    'rsi_30',\n",
        "    'cci_30',\n",
        "    'dx_30',\n",
        "    'close_30_sma',\n",
        "    'close_60_sma'])*stock_size\n",
        "\n",
        "# 8 indictor/price features PER stock (there's 5 here)\n",
        "# Plus, the raw price data is captured again as 2 extra features per stock (typically Open and Close price).\n",
        "# So + 2N state variables\n",
        "# Hence 8*5 (indicators) + 2*5 (raw price) + 1 (offset variable)\n",
        "\n",
        "stock_size, state_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nThe training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\\n\\nOur market environment, based on OpenAI Gym, simulates stock markets with historical market data.\\n\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "\n",
        "\n",
        "training_environment, initial_observations = StockTradingEnv(df = train, hmax= 100,\n",
        "    initial_amount= 1000000, # STARTING AMOUNT HERE\n",
        "    num_stock_shares= [0] * stock_size,\n",
        "    buy_cost_pct= [.1/100] * stock_size, # Transaction fee percent of buys per stock\n",
        "    sell_cost_pct= [.1/100] * stock_size,\n",
        "    state_space= state_space,\n",
        "    stock_dim= stock_size, # Stock dimensions\n",
        "    tech_indicator_list= ['macd',\n",
        "    'boll_ub',\n",
        "    'boll_lb',\n",
        "    'rsi_30',\n",
        "    'cci_30',\n",
        "    'dx_30',\n",
        "    'close_30_sma',\n",
        "    'close_60_sma'],\n",
        "    action_space= stock_size, \n",
        "    reward_scaling= 1e-4).get_sb_env() \n",
        "# creates a vectorized environment compatible with Stable Baselines algorithms\n",
        "# uses DummyVecEnv from Stable Baselines to create a vectorized wrapper of the trading env\n",
        "# wraps the env in a Vectorized environment that handles all the multiprocessing - steps, resets etc.\n",
        "# It calls reset() on the vectorized env to get the initial observations\n",
        "\"\"\"\n",
        "The training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
        "\n",
        "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUCnkn-HIbmj",
        "outputId": "baf0ae36-87e3-46c0-f243-dfb7a72bdda4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a2c\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n",
            "ddpg\n",
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/ddpg\n",
            "[('a2c', <stable_baselines3.a2c.a2c.A2C object at 0x00000277B99490C0>), ('ddpg', <stable_baselines3.ddpg.ddpg.DDPG object at 0x00000277B99490F0>)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "# Automatically build models from list of model names\n",
        "agent = DRLAgent(training_environment)\n",
        "models=[]\n",
        "def log_model(model_name):\n",
        "    print(model_name)\n",
        "    model = agent.get_model(f\"{model_name}\")\n",
        "    model.set_logger(configure(RESULTS_DIR + f'/{model_name}', [\"stdout\", \"csv\", \"tensorboard\"]))\n",
        "    models.append((model_name, model))\n",
        "\n",
        "model_names=['a2c'\n",
        "            ,'ddpg'\n",
        "            # ,'ppo'\n",
        "            # ,'sac'\n",
        "            ]\n",
        "for model_name in model_names:\n",
        "    log_model(model_name)\n",
        "print(models)\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 1, 'ent_coef': 0.0755882482216129, 'learning_rate': 2.637065887731285e-05, 'gamma': 0.9048260592925886, 'gae_lambda': 0.9717236074963396}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 137         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 0           |\n",
            "|    total_timesteps    | 100         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.11       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -0.904      |\n",
            "|    reward             | -0.13941592 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.00852     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 155         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 200         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.12       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 1.16        |\n",
            "|    reward             | 0.122342244 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.0455      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 167          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 300          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.13        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.245        |\n",
            "|    reward             | 0.0056214696 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.00202      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 174          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 400          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.14        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.231       |\n",
            "|    reward             | -0.032506187 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.00142      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.15      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -0.214     |\n",
            "|    reward             | 0.02255406 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.00113    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 179        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 600        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.16      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 0.184      |\n",
            "|    reward             | 0.12258537 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.000854   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 700         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.17       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.699       |\n",
            "|    reward             | -0.12699892 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0121      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 800        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.17      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -2.1       |\n",
            "|    reward             | -0.1518403 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.134      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 900         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.18       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 0.0689      |\n",
            "|    reward             | -0.29079592 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.000115    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.19      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 4.93       |\n",
            "|    reward             | 0.53143233 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.584      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1100       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.19      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -1.61      |\n",
            "|    reward             | 0.02222794 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0449     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 185        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 1200       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.2       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -0.864     |\n",
            "|    reward             | 0.10605338 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0111     |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 185           |\n",
            "|    iterations         | 1300          |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 1300          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -7.2          |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 1299          |\n",
            "|    policy_loss        | 0.854         |\n",
            "|    reward             | -0.0017583166 |\n",
            "|    std                | 1.02          |\n",
            "|    value_loss         | 0.0123        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 185         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 1400        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.21       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -1.59       |\n",
            "|    reward             | -0.47611624 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0463      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 185        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.21      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 6.08       |\n",
            "|    reward             | 0.22877756 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.29       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 185        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 1600       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.22      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -1.13      |\n",
            "|    reward             | 0.09134366 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0288     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 185        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1700       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.22      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 5.49       |\n",
            "|    reward             | -1.2861941 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.529      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 186        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1800       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.22      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -3.24      |\n",
            "|    reward             | 0.27930373 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.342      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 185        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 1900       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.22      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 11.1       |\n",
            "|    reward             | -1.7037894 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.75       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.23      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 8.34       |\n",
            "|    reward             | 0.23840317 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.97       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 2100      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.23     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 3         |\n",
            "|    reward             | 1.8636159 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.17      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 2200         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.24        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.0251      |\n",
            "|    reward             | -0.024298187 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 1.19e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 2300        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.25       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 2299        |\n",
            "|    policy_loss        | -0.421      |\n",
            "|    reward             | 0.018826732 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.00556     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 2400       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.26      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 1.48       |\n",
            "|    reward             | 0.01278383 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.0247     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 185         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.27       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 1.15        |\n",
            "|    reward             | -0.17103663 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0373      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 186        |\n",
            "|    iterations         | 2600       |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 2600       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.27      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 2599       |\n",
            "|    policy_loss        | 0.643      |\n",
            "|    reward             | 0.07429432 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.00689    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 185        |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 2700       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.28      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 0.489      |\n",
            "|    reward             | 0.20373276 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.00909    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 184          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 2800         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.29        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.605        |\n",
            "|    reward             | -0.056729216 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.00593      |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 2900      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.29     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | -1.35     |\n",
            "|    reward             | -0.482249 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.0211    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.3       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | -0.0577    |\n",
            "|    reward             | 0.30094683 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 9.06e-05   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 16          |\n",
            "|    total_timesteps    | 3100        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.31       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | 0.471       |\n",
            "|    reward             | -0.06548397 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.00325     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 3200        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.31       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | 0.534       |\n",
            "|    reward             | -0.18481094 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.00767     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 3300        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.32       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | -0.647      |\n",
            "|    reward             | -0.03665195 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0162      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 18         |\n",
            "|    total_timesteps    | 3400       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.32      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | 0.394      |\n",
            "|    reward             | 0.09262006 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.00106    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.33       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 4.45        |\n",
            "|    reward             | -0.09895403 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.561       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 3600       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.34      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | 2.36       |\n",
            "|    reward             | -0.1844315 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.0693     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 3700        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.34       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | 1.79        |\n",
            "|    reward             | -0.58022547 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0977      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 3800        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.34       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | -6.7        |\n",
            "|    reward             | -0.12068346 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.928       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 3900       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.34      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | 37.4       |\n",
            "|    reward             | 0.02789789 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 18.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.35      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | 3.18       |\n",
            "|    reward             | -1.8548723 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.176      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 4100       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.35      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 9.04       |\n",
            "|    reward             | 0.44230205 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.33       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 4200      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.35     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | -68.8     |\n",
            "|    reward             | 5.6181984 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 134       |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 184          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 4300         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.35        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -0.109       |\n",
            "|    reward             | -0.024577351 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.000287     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 4400       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.36      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -1.06      |\n",
            "|    reward             | 0.37554848 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.0201     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.37       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 2.47        |\n",
            "|    reward             | -0.19265546 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.0362      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 4600      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.38     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 6.78      |\n",
            "|    reward             | 0.5623099 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 1.28      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 4700       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.38      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | -1.09      |\n",
            "|    reward             | 0.10897477 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.0228     |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 4800     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.38    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | -4.87    |\n",
            "|    reward             | 1.428753 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.208    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 4900      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.39     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | -1.62     |\n",
            "|    reward             | 0.5329607 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.0567    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.39      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -3.86      |\n",
            "|    reward             | 0.96612436 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.429      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 5100       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.39      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | -0.956     |\n",
            "|    reward             | -1.2866441 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.0282     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 5200       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.39      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | 11.7       |\n",
            "|    reward             | -1.7150549 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.41       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 5300       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.39      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 5.64       |\n",
            "|    reward             | -2.5037348 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.343      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 5400       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.4       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | 13.4       |\n",
            "|    reward             | -6.0251126 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.79       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.4       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 8.78       |\n",
            "|    reward             | 0.50487214 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.869      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 5600         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.4         |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | 9.87         |\n",
            "|    reward             | -0.062177014 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 1.66         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 5700       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.41      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -0.444     |\n",
            "|    reward             | 0.92280155 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.00485    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 5800       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.41      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 8.05       |\n",
            "|    reward             | -2.6340098 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.33       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 5900        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.41       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -52.2       |\n",
            "|    reward             | -0.17474046 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 47.6        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.41     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -37       |\n",
            "|    reward             | -5.881993 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 28.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 6100       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.41      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 2.9        |\n",
            "|    reward             | -0.7328211 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.219      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 6200      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.41     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | 15.4      |\n",
            "|    reward             | 3.7994285 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 4.93      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 6300        |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 6300        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.41       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 6299        |\n",
            "|    policy_loss        | -25.6       |\n",
            "|    reward             | 0.060421556 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 16.9        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 6400     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.41    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 3.08     |\n",
            "|    reward             | 8.689192 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.328    |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 180         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.42       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | -0.266      |\n",
            "|    reward             | -0.04551997 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.00183     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 180            |\n",
            "|    iterations         | 6600           |\n",
            "|    time_elapsed       | 36             |\n",
            "|    total_timesteps    | 6600           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -7.43          |\n",
            "|    explained_variance | nan            |\n",
            "|    learning_rate      | 2.64e-05       |\n",
            "|    n_updates          | 6599           |\n",
            "|    policy_loss        | -1.47          |\n",
            "|    reward             | -0.00090763107 |\n",
            "|    std                | 1.07           |\n",
            "|    value_loss         | 0.013          |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 180         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 6700        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.44       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | 5.19        |\n",
            "|    reward             | 0.029494124 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.474       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 179        |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 6800       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.44      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | 1.28       |\n",
            "|    reward             | -0.2083649 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0351     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 179         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 6900        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.45       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | -4.49       |\n",
            "|    reward             | 0.106096365 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.555       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 179        |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.45      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 6999       |\n",
            "|    policy_loss        | 4.51       |\n",
            "|    reward             | 0.28812394 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.412      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 7100       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.45      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -4.54      |\n",
            "|    reward             | -0.7689967 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.413      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 7200      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.46     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 7199      |\n",
            "|    policy_loss        | -3.26     |\n",
            "|    reward             | 0.9394186 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.229     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 178         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 7300        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.46       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 4.12        |\n",
            "|    reward             | -0.60673684 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.193       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 7400       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.46      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 7399       |\n",
            "|    policy_loss        | -12        |\n",
            "|    reward             | -1.8534174 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 2.59       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 7500       |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.46      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 7499       |\n",
            "|    policy_loss        | 1.83       |\n",
            "|    reward             | -1.6957585 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.048      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 7600       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.47      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 0.297      |\n",
            "|    reward             | -1.2322619 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.00128    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 7700       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.47      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | 6.87       |\n",
            "|    reward             | -0.8566921 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 1.07       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 7800      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.47     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | 3.57      |\n",
            "|    reward             | 0.9997864 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.152     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 7900      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.47     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | 23.8      |\n",
            "|    reward             | 0.4081428 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 12.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.48      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | 15.5       |\n",
            "|    reward             | -1.8518842 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 2.55       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 177      |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 8100     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | 23.2     |\n",
            "|    reward             | 4.689102 |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 12.4     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 8200       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.48      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | 33         |\n",
            "|    reward             | 0.55137724 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 21.7       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 178         |\n",
            "|    iterations         | 8300        |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 8300        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.48       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 8299        |\n",
            "|    policy_loss        | -3.98       |\n",
            "|    reward             | -0.70960665 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.499       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 177         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 8400        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.48       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -4.88       |\n",
            "|    reward             | -0.49032488 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.239       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.48     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 7.54      |\n",
            "|    reward             | 2.8498695 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.05      |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 177           |\n",
            "|    iterations         | 8600          |\n",
            "|    time_elapsed       | 48            |\n",
            "|    total_timesteps    | 8600          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -7.49         |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 8599          |\n",
            "|    policy_loss        | -0.042        |\n",
            "|    reward             | -0.0054324227 |\n",
            "|    std                | 1.08          |\n",
            "|    value_loss         | 2.72e-05      |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 8700      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.5      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -0.012    |\n",
            "|    reward             | 0.2559877 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.66e-06  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 177         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 8800        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.5        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | 1.78        |\n",
            "|    reward             | 0.119414754 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.062       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 177          |\n",
            "|    iterations         | 8900         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 8900         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.51        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 8899         |\n",
            "|    policy_loss        | 0.61         |\n",
            "|    reward             | -0.005676078 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.00835      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.51      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 7.06       |\n",
            "|    reward             | 0.18721442 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.561      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 9100       |\n",
            "|    time_elapsed       | 51         |\n",
            "|    total_timesteps    | 9100       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.52      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 9099       |\n",
            "|    policy_loss        | -1.4       |\n",
            "|    reward             | 0.25972107 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.0399     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 9200      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.52     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | -0.698    |\n",
            "|    reward             | 0.4913956 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.0144    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 52         |\n",
            "|    total_timesteps    | 9300       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.52      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | -3.53      |\n",
            "|    reward             | -1.1197768 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.371      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 53         |\n",
            "|    total_timesteps    | 9400       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | -5.73      |\n",
            "|    reward             | -0.8738473 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.76       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 53         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | -0.374     |\n",
            "|    reward             | 0.26111218 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.00309    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 9600      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.53     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 9599      |\n",
            "|    policy_loss        | 0.178     |\n",
            "|    reward             | -0.687449 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.000692  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 54         |\n",
            "|    total_timesteps    | 9700       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | -6.96      |\n",
            "|    reward             | -0.8468341 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.829      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 55         |\n",
            "|    total_timesteps    | 9800       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | -7.26      |\n",
            "|    reward             | 0.33757046 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.74       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 176         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 56          |\n",
            "|    total_timesteps    | 9900        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.54       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | -31.8       |\n",
            "|    reward             | -0.00620626 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 8.44        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.54     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | -0.181    |\n",
            "|    reward             | 1.5661947 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.000732  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 10100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.54     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 38.2      |\n",
            "|    reward             | 3.1248064 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 30.4      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 176         |\n",
            "|    iterations         | 10200       |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 10200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.54       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 10199       |\n",
            "|    policy_loss        | 19.4        |\n",
            "|    reward             | -0.36595607 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 4.89        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 10300      |\n",
            "|    time_elapsed       | 58         |\n",
            "|    total_timesteps    | 10300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.54      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 10299      |\n",
            "|    policy_loss        | -1.79      |\n",
            "|    reward             | -2.4195707 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.0475     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 176         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 58          |\n",
            "|    total_timesteps    | 10400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.54       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 15.4        |\n",
            "|    reward             | -0.17077415 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 7.69        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 59         |\n",
            "|    total_timesteps    | 10500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.54      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 7.81       |\n",
            "|    reward             | -1.0312457 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.94       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 10600     |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 10600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.54     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 10599     |\n",
            "|    policy_loss        | 12.7      |\n",
            "|    reward             | 5.0083914 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.15      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 176         |\n",
            "|    iterations         | 10700       |\n",
            "|    time_elapsed       | 60          |\n",
            "|    total_timesteps    | 10700       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.55       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 10699       |\n",
            "|    policy_loss        | -0.24       |\n",
            "|    reward             | 0.109779395 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.00119     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 10800      |\n",
            "|    time_elapsed       | 61         |\n",
            "|    total_timesteps    | 10800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.56      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 10799      |\n",
            "|    policy_loss        | 1.43       |\n",
            "|    reward             | -0.0358739 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.0412     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 176        |\n",
            "|    iterations         | 10900      |\n",
            "|    time_elapsed       | 61         |\n",
            "|    total_timesteps    | 10900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.56      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 10899      |\n",
            "|    policy_loss        | -2.35      |\n",
            "|    reward             | 0.29395238 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.14       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 176         |\n",
            "|    iterations         | 11000       |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.57       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 10999       |\n",
            "|    policy_loss        | -0.196      |\n",
            "|    reward             | -0.14834808 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.000714    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 176         |\n",
            "|    iterations         | 11100       |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 11100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.58       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 11099       |\n",
            "|    policy_loss        | -3.37       |\n",
            "|    reward             | -0.11672091 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.24        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 177         |\n",
            "|    iterations         | 11200       |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 11200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.58       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 11199       |\n",
            "|    policy_loss        | -2.49       |\n",
            "|    reward             | -0.57650197 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.225       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 177         |\n",
            "|    iterations         | 11300       |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 11300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.58       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 11299       |\n",
            "|    policy_loss        | 1.04        |\n",
            "|    reward             | 0.030884497 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.00808     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 177        |\n",
            "|    iterations         | 11400      |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 11400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.59      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 11399      |\n",
            "|    policy_loss        | -8.67      |\n",
            "|    reward             | 0.67829096 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 177         |\n",
            "|    iterations         | 11500       |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.59       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 11499       |\n",
            "|    policy_loss        | -8.46       |\n",
            "|    reward             | -0.44912603 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 1.86        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 11600     |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 11600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.59     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 11599     |\n",
            "|    policy_loss        | -13.4     |\n",
            "|    reward             | -2.359052 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 3.37      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 11700      |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 11700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.59      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 11699      |\n",
            "|    policy_loss        | 12.9       |\n",
            "|    reward             | -1.9783893 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 2.08       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 11800      |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 11800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.6       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 11799      |\n",
            "|    policy_loss        | 9.37       |\n",
            "|    reward             | -0.8846784 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.62       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 11900      |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 11900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.6       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 11899      |\n",
            "|    policy_loss        | 8.89       |\n",
            "|    reward             | -0.4742043 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.44       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 179         |\n",
            "|    iterations         | 12000       |\n",
            "|    time_elapsed       | 67          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.6        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 11999       |\n",
            "|    policy_loss        | 5.48        |\n",
            "|    reward             | -0.68788123 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.266       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 179        |\n",
            "|    iterations         | 12100      |\n",
            "|    time_elapsed       | 67         |\n",
            "|    total_timesteps    | 12100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.61      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12099      |\n",
            "|    policy_loss        | 7.83       |\n",
            "|    reward             | -1.3269804 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.784      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 179        |\n",
            "|    iterations         | 12200      |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 12200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.61      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12199      |\n",
            "|    policy_loss        | 3.51       |\n",
            "|    reward             | -0.6654217 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.17       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 179        |\n",
            "|    iterations         | 12300      |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 12300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.61      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12299      |\n",
            "|    policy_loss        | -10.2      |\n",
            "|    reward             | 0.62492716 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.66       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 12400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.61     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | -67       |\n",
            "|    reward             | 3.9901674 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 65.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 180        |\n",
            "|    iterations         | 12500      |\n",
            "|    time_elapsed       | 69         |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.61      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12499      |\n",
            "|    policy_loss        | 16.7       |\n",
            "|    reward             | -5.4520574 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.94       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 180        |\n",
            "|    iterations         | 12600      |\n",
            "|    time_elapsed       | 69         |\n",
            "|    total_timesteps    | 12600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.61      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12599      |\n",
            "|    policy_loss        | 19.2       |\n",
            "|    reward             | -4.9551954 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 6.06       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 180        |\n",
            "|    iterations         | 12700      |\n",
            "|    time_elapsed       | 70         |\n",
            "|    total_timesteps    | 12700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.62      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12699      |\n",
            "|    policy_loss        | -0.829     |\n",
            "|    reward             | -2.4072244 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.015      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 180        |\n",
            "|    iterations         | 12800      |\n",
            "|    time_elapsed       | 70         |\n",
            "|    total_timesteps    | 12800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.62      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 12799      |\n",
            "|    policy_loss        | -3.5       |\n",
            "|    reward             | 0.44294664 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.286      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 180          |\n",
            "|    iterations         | 12900        |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 12900        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.63        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 12899        |\n",
            "|    policy_loss        | -0.0144      |\n",
            "|    reward             | -0.024163222 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 3.79e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 180          |\n",
            "|    iterations         | 13000        |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.64        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 12999        |\n",
            "|    policy_loss        | 1.26         |\n",
            "|    reward             | -0.072923824 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 0.0509       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 13100      |\n",
            "|    time_elapsed       | 72         |\n",
            "|    total_timesteps    | 13100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.65      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 13099      |\n",
            "|    policy_loss        | -0.149     |\n",
            "|    reward             | 0.11253611 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.00049    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 13200      |\n",
            "|    time_elapsed       | 72         |\n",
            "|    total_timesteps    | 13200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.65      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 13199      |\n",
            "|    policy_loss        | 0.757      |\n",
            "|    reward             | 0.21831098 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.00698    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 13300       |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 13300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.66       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 13299       |\n",
            "|    policy_loss        | 2.93        |\n",
            "|    reward             | -0.03519129 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.184       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 13400       |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 13400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.66       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 13399       |\n",
            "|    policy_loss        | 3.5         |\n",
            "|    reward             | -0.15777965 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.191       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 13500      |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.67      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 13499      |\n",
            "|    policy_loss        | -4.41      |\n",
            "|    reward             | -0.1513417 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.137      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 13600      |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 13600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.67      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 13599      |\n",
            "|    policy_loss        | 11.2       |\n",
            "|    reward             | -0.2291428 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 1.14       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 13700       |\n",
            "|    time_elapsed       | 75          |\n",
            "|    total_timesteps    | 13700       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.68       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 13699       |\n",
            "|    policy_loss        | -2.86       |\n",
            "|    reward             | -0.54308456 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.121       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 13800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.68     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -1.33     |\n",
            "|    reward             | 1.2321347 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.0494    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 13900      |\n",
            "|    time_elapsed       | 76         |\n",
            "|    total_timesteps    | 13900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.68      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 13899      |\n",
            "|    policy_loss        | 2.65       |\n",
            "|    reward             | 0.21485451 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.0958     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 77          |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.68       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | 9.77        |\n",
            "|    reward             | -0.27584314 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 2.81        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 14100       |\n",
            "|    time_elapsed       | 77          |\n",
            "|    total_timesteps    | 14100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.68       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 14099       |\n",
            "|    policy_loss        | -10.6       |\n",
            "|    reward             | -0.88608974 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 1.77        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 181          |\n",
            "|    iterations         | 14200        |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 14200        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.69        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 14199        |\n",
            "|    policy_loss        | 4.37         |\n",
            "|    reward             | -0.088818856 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 0.221        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 14300      |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 14300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.69      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 14299      |\n",
            "|    policy_loss        | 15.1       |\n",
            "|    reward             | -3.8259845 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 2.31       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14400     |\n",
            "|    time_elapsed       | 79        |\n",
            "|    total_timesteps    | 14400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.69     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 14399     |\n",
            "|    policy_loss        | -13.5     |\n",
            "|    reward             | 4.0948486 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 3.2       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14500     |\n",
            "|    time_elapsed       | 79        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.7      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 14499     |\n",
            "|    policy_loss        | -0.538    |\n",
            "|    reward             | -1.019389 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 0.00438   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14600     |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 14600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.7      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 14599     |\n",
            "|    policy_loss        | -138      |\n",
            "|    reward             | 1.4161141 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 178       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 14700      |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 14700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.7       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 14699      |\n",
            "|    policy_loss        | 24.2       |\n",
            "|    reward             | 0.28231114 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 12.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 14800      |\n",
            "|    time_elapsed       | 81         |\n",
            "|    total_timesteps    | 14800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.7       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 14799      |\n",
            "|    policy_loss        | -0.598     |\n",
            "|    reward             | -1.3816265 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.00785    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 14900     |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 14900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.7      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 14899     |\n",
            "|    policy_loss        | 70.6      |\n",
            "|    reward             | 0.7688438 |\n",
            "|    std                | 1.13      |\n",
            "|    value_loss         | 116       |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 15000        |\n",
            "|    time_elapsed       | 82           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.71        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 14999        |\n",
            "|    policy_loss        | -0.0298      |\n",
            "|    reward             | -0.014153728 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 1.65e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 15100       |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 15100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.72       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 15099       |\n",
            "|    policy_loss        | -0.169      |\n",
            "|    reward             | 0.046284817 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 0.000588    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 15200      |\n",
            "|    time_elapsed       | 83         |\n",
            "|    total_timesteps    | 15200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.72      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 15199      |\n",
            "|    policy_loss        | 0.531      |\n",
            "|    reward             | 0.10162723 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.00331    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 15300       |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 15300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.74       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 15299       |\n",
            "|    policy_loss        | -0.097      |\n",
            "|    reward             | 0.042356435 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.000216    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 15400       |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 15400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.74       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 15399       |\n",
            "|    policy_loss        | -0.399      |\n",
            "|    reward             | 0.063124366 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.00255     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 15500      |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.75      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 15499      |\n",
            "|    policy_loss        | 0.239      |\n",
            "|    reward             | 0.21279728 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 0.00101    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 15600       |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 15600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.75       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 15599       |\n",
            "|    policy_loss        | -0.418      |\n",
            "|    reward             | -0.48634726 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.00297     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 15700      |\n",
            "|    time_elapsed       | 86         |\n",
            "|    total_timesteps    | 15700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.76      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 15699      |\n",
            "|    policy_loss        | 0.0582     |\n",
            "|    reward             | -0.8839737 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 7.62e-05   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 15800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.76     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | -0.0869   |\n",
            "|    reward             | 0.9870124 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 8.56e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 15900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.77     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 2.35      |\n",
            "|    reward             | 1.0798628 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 0.0991    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 16000      |\n",
            "|    time_elapsed       | 87         |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.77      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 15999      |\n",
            "|    policy_loss        | -16.2      |\n",
            "|    reward             | 0.18268724 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 3.9        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 16100       |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 16100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.77       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 16099       |\n",
            "|    policy_loss        | 2.58        |\n",
            "|    reward             | 0.068957955 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.167       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 16200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.77     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | 4.81      |\n",
            "|    reward             | 2.9376032 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 0.471     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 16300       |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 16300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.77       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 16299       |\n",
            "|    policy_loss        | -3.7        |\n",
            "|    reward             | -0.10076089 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.349       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 16400       |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 16400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.77       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 16399       |\n",
            "|    policy_loss        | -0.195      |\n",
            "|    reward             | -0.71691614 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.000827    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 16500      |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.78      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 16499      |\n",
            "|    policy_loss        | 29.1       |\n",
            "|    reward             | -3.8741078 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 8.2        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 16600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.78     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | -40.3     |\n",
            "|    reward             | 3.8020744 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 19.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 16700    |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 16700    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.78    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 16699    |\n",
            "|    policy_loss        | 62.2     |\n",
            "|    reward             | 4.063818 |\n",
            "|    std                | 1.15     |\n",
            "|    value_loss         | 35.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 16800     |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 16800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.78     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 16799     |\n",
            "|    policy_loss        | -2.11     |\n",
            "|    reward             | 0.8042142 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.0825    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 92        |\n",
            "|    total_timesteps    | 16900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.78     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -0.181    |\n",
            "|    reward             | -3.104004 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.000944  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 17000       |\n",
            "|    time_elapsed       | 92          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.78       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 16999       |\n",
            "|    policy_loss        | 28.9        |\n",
            "|    reward             | -0.39289454 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 18          |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 183           |\n",
            "|    iterations         | 17100         |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 17100         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -7.78         |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 17099         |\n",
            "|    policy_loss        | -0.214        |\n",
            "|    reward             | -0.0040025334 |\n",
            "|    std                | 1.15          |\n",
            "|    value_loss         | 0.00113       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 17200       |\n",
            "|    time_elapsed       | 93          |\n",
            "|    total_timesteps    | 17200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.79       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 17199       |\n",
            "|    policy_loss        | -1.71       |\n",
            "|    reward             | -0.27387455 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.0866      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 17300       |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 17300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.8        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 17299       |\n",
            "|    policy_loss        | 0.859       |\n",
            "|    reward             | -0.24067593 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.0101      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 17400       |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 17400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.81       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 17399       |\n",
            "|    policy_loss        | -2.26       |\n",
            "|    reward             | -0.08861864 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.0813      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 184           |\n",
            "|    iterations         | 17500         |\n",
            "|    time_elapsed       | 95            |\n",
            "|    total_timesteps    | 17500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -7.82         |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 17499         |\n",
            "|    policy_loss        | 2.27          |\n",
            "|    reward             | -0.0034721347 |\n",
            "|    std                | 1.16          |\n",
            "|    value_loss         | 0.145         |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 17600       |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 17600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.82       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 17599       |\n",
            "|    policy_loss        | -0.594      |\n",
            "|    reward             | -0.41949376 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.00711     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 17700      |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 17700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.83      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 17699      |\n",
            "|    policy_loss        | 2.31       |\n",
            "|    reward             | -0.4045995 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.121      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 17800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.83     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | -2.55     |\n",
            "|    reward             | 1.0957649 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.119     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 17900       |\n",
            "|    time_elapsed       | 97          |\n",
            "|    total_timesteps    | 17900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.84       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 17899       |\n",
            "|    policy_loss        | 3.24        |\n",
            "|    reward             | -0.90975004 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.268       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 18000       |\n",
            "|    time_elapsed       | 97          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.84       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 17999       |\n",
            "|    policy_loss        | 0.0416      |\n",
            "|    reward             | -0.09630162 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 2.81e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 18100      |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 18100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.84      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 18099      |\n",
            "|    policy_loss        | 4.53       |\n",
            "|    reward             | -0.5361939 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.552      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 18200     |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 18200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.84     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 18199     |\n",
            "|    policy_loss        | 2.24      |\n",
            "|    reward             | 1.1521958 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.0543    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 18300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.84      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -5.84      |\n",
            "|    reward             | 0.77280015 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.4        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 18400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.85     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | -15       |\n",
            "|    reward             | 0.9806572 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 3.79      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 18500       |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.85       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 18499       |\n",
            "|    policy_loss        | -7.25       |\n",
            "|    reward             | -0.14028268 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.806       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 18600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.85     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | 11.9      |\n",
            "|    reward             | 0.9328991 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 2.96      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 18700    |\n",
            "|    time_elapsed       | 101      |\n",
            "|    total_timesteps    | 18700    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.85    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 18699    |\n",
            "|    policy_loss        | -3.96    |\n",
            "|    reward             | 1.866689 |\n",
            "|    std                | 1.16     |\n",
            "|    value_loss         | 0.385    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 102       |\n",
            "|    total_timesteps    | 18800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.85     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | -25.8     |\n",
            "|    reward             | -8.213731 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 12.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 18900      |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 18900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.86      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 18899      |\n",
            "|    policy_loss        | -18.2      |\n",
            "|    reward             | -2.5925868 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 6          |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 19000      |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.86      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 18999      |\n",
            "|    policy_loss        | 9.29       |\n",
            "|    reward             | -1.7904091 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 1.72       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 19100      |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 19100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.86      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 19099      |\n",
            "|    policy_loss        | 4.38       |\n",
            "|    reward             | -1.3886701 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.319      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 19200    |\n",
            "|    time_elapsed       | 104      |\n",
            "|    total_timesteps    | 19200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.86    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 19199    |\n",
            "|    policy_loss        | -12.3    |\n",
            "|    reward             | 2.040376 |\n",
            "|    std                | 1.17     |\n",
            "|    value_loss         | 2.62     |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 19300        |\n",
            "|    time_elapsed       | 105          |\n",
            "|    total_timesteps    | 19300        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.87        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 19299        |\n",
            "|    policy_loss        | -0.168       |\n",
            "|    reward             | -0.085289426 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 0.000394     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 19400       |\n",
            "|    time_elapsed       | 105         |\n",
            "|    total_timesteps    | 19400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.88       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 19399       |\n",
            "|    policy_loss        | 0.0302      |\n",
            "|    reward             | -0.18610612 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 2.56e-05    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.89     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | -0.854    |\n",
            "|    reward             | 0.2954772 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 0.0173    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 19600       |\n",
            "|    time_elapsed       | 106         |\n",
            "|    total_timesteps    | 19600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.89       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 19599       |\n",
            "|    policy_loss        | -1.08       |\n",
            "|    reward             | -0.36151677 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.0138      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 19700        |\n",
            "|    time_elapsed       | 107          |\n",
            "|    total_timesteps    | 19700        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.9         |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 19699        |\n",
            "|    policy_loss        | 1.83         |\n",
            "|    reward             | -0.052580178 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 0.0483       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 19800      |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 19800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.91      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 19799      |\n",
            "|    policy_loss        | -3.22      |\n",
            "|    reward             | -0.4147694 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.133      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 19900        |\n",
            "|    time_elapsed       | 108          |\n",
            "|    total_timesteps    | 19900        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.91        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 19899        |\n",
            "|    policy_loss        | 1.01         |\n",
            "|    reward             | -0.008155256 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 0.0174       |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 20000     |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.92     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 19999     |\n",
            "|    policy_loss        | 3.35      |\n",
            "|    reward             | 1.0514889 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 0.0793    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 20100      |\n",
            "|    time_elapsed       | 109        |\n",
            "|    total_timesteps    | 20100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.92      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20099      |\n",
            "|    policy_loss        | -3.9       |\n",
            "|    reward             | 0.09942733 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.311      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 20200       |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 20200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.93       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 20199       |\n",
            "|    policy_loss        | 0.786       |\n",
            "|    reward             | -0.09217337 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.00993     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 20300      |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 20300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.93      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20299      |\n",
            "|    policy_loss        | 1.03       |\n",
            "|    reward             | 0.38975984 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.0152     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 20400      |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 20400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.93      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20399      |\n",
            "|    policy_loss        | -1.25      |\n",
            "|    reward             | 0.42172372 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.0262     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 20500       |\n",
            "|    time_elapsed       | 111         |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.93       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 20499       |\n",
            "|    policy_loss        | 2.91        |\n",
            "|    reward             | -0.67420655 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.124       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 20600      |\n",
            "|    time_elapsed       | 112        |\n",
            "|    total_timesteps    | 20600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.94      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20599      |\n",
            "|    policy_loss        | 3.51       |\n",
            "|    reward             | -0.8275216 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.265      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 20700      |\n",
            "|    time_elapsed       | 112        |\n",
            "|    total_timesteps    | 20700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.94      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20699      |\n",
            "|    policy_loss        | -9.1       |\n",
            "|    reward             | -1.1415527 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 1.16       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 20800      |\n",
            "|    time_elapsed       | 113        |\n",
            "|    total_timesteps    | 20800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.94      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20799      |\n",
            "|    policy_loss        | 65.8       |\n",
            "|    reward             | -5.4726896 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 72.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 20900     |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 20900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.94     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 20899     |\n",
            "|    policy_loss        | 20.6      |\n",
            "|    reward             | 2.0447586 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 8.45      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 21000      |\n",
            "|    time_elapsed       | 114        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.94      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 20999      |\n",
            "|    policy_loss        | 6.94       |\n",
            "|    reward             | -1.3361988 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 1.31       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 21100     |\n",
            "|    time_elapsed       | 114       |\n",
            "|    total_timesteps    | 21100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.94     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 21099     |\n",
            "|    policy_loss        | 29.3      |\n",
            "|    reward             | 2.1048872 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 6.87      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 21200     |\n",
            "|    time_elapsed       | 115       |\n",
            "|    total_timesteps    | 21200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.94     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 21199     |\n",
            "|    policy_loss        | 34.8      |\n",
            "|    reward             | 3.7333713 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 22.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 21300      |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 21300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.95      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 21299      |\n",
            "|    policy_loss        | -88.9      |\n",
            "|    reward             | -3.7990463 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 99.9       |\n",
            "--------------------------------------\n",
            "day: 2136, episode: 3630\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3043333.93\n",
            "total_reward: 2043333.93\n",
            "total_cost: 34662.22\n",
            "total_trades: 9989\n",
            "Sharpe: 0.808\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 21400        |\n",
            "|    time_elapsed       | 116          |\n",
            "|    total_timesteps    | 21400        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.95        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 21399        |\n",
            "|    policy_loss        | -0.275       |\n",
            "|    reward             | -0.048570525 |\n",
            "|    std                | 1.19         |\n",
            "|    value_loss         | 0.00112      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 21500       |\n",
            "|    time_elapsed       | 116         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.96       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 21499       |\n",
            "|    policy_loss        | -2.19       |\n",
            "|    reward             | -0.35511532 |\n",
            "|    std                | 1.19        |\n",
            "|    value_loss         | 0.0531      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 21600       |\n",
            "|    time_elapsed       | 117         |\n",
            "|    total_timesteps    | 21600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.96       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 21599       |\n",
            "|    policy_loss        | -3.5        |\n",
            "|    reward             | -0.22374845 |\n",
            "|    std                | 1.19        |\n",
            "|    value_loss         | 0.152       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 21700      |\n",
            "|    time_elapsed       | 117        |\n",
            "|    total_timesteps    | 21700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.97      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 21699      |\n",
            "|    policy_loss        | 0.0229     |\n",
            "|    reward             | 0.22178388 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 5.64e-06   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 184           |\n",
            "|    iterations         | 21800         |\n",
            "|    time_elapsed       | 118           |\n",
            "|    total_timesteps    | 21800         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -7.97         |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 21799         |\n",
            "|    policy_loss        | 2.16          |\n",
            "|    reward             | 0.00022995018 |\n",
            "|    std                | 1.19          |\n",
            "|    value_loss         | 0.148         |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 21900     |\n",
            "|    time_elapsed       | 118       |\n",
            "|    total_timesteps    | 21900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.98     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 21899     |\n",
            "|    policy_loss        | 1.91      |\n",
            "|    reward             | 0.5078769 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 0.0995    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 22000      |\n",
            "|    time_elapsed       | 119        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.98      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 21999      |\n",
            "|    policy_loss        | -2.4       |\n",
            "|    reward             | -0.4195947 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 0.133      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 22100       |\n",
            "|    time_elapsed       | 120         |\n",
            "|    total_timesteps    | 22100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.99       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 22099       |\n",
            "|    policy_loss        | 0.27        |\n",
            "|    reward             | -0.11389089 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 0.00123     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 22200      |\n",
            "|    time_elapsed       | 120        |\n",
            "|    total_timesteps    | 22200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.99      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 22199      |\n",
            "|    policy_loss        | 4.84       |\n",
            "|    reward             | 0.08088783 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.331      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 22300     |\n",
            "|    time_elapsed       | 121       |\n",
            "|    total_timesteps    | 22300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.99     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 22299     |\n",
            "|    policy_loss        | -0.768    |\n",
            "|    reward             | 1.4312407 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 0.00408   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 22400      |\n",
            "|    time_elapsed       | 121        |\n",
            "|    total_timesteps    | 22400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8         |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 22399      |\n",
            "|    policy_loss        | -5.37      |\n",
            "|    reward             | -1.3855059 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.474      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 22500     |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8        |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 22499     |\n",
            "|    policy_loss        | 12        |\n",
            "|    reward             | 1.4978151 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 3.61      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 22600      |\n",
            "|    time_elapsed       | 122        |\n",
            "|    total_timesteps    | 22600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8         |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 22599      |\n",
            "|    policy_loss        | -6.55      |\n",
            "|    reward             | 0.78159714 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.48       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 22700      |\n",
            "|    time_elapsed       | 123        |\n",
            "|    total_timesteps    | 22700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8         |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 22699      |\n",
            "|    policy_loss        | 8.97       |\n",
            "|    reward             | 0.17582814 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 1.42       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 22800       |\n",
            "|    time_elapsed       | 123         |\n",
            "|    total_timesteps    | 22800       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.01       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 22799       |\n",
            "|    policy_loss        | 9.4         |\n",
            "|    reward             | -0.20005055 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 1.4         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 184        |\n",
            "|    iterations         | 22900      |\n",
            "|    time_elapsed       | 124        |\n",
            "|    total_timesteps    | 22900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.01      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 22899      |\n",
            "|    policy_loss        | 4.02       |\n",
            "|    reward             | -1.0019635 |\n",
            "|    std                | 1.2        |\n",
            "|    value_loss         | 0.268      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 23000       |\n",
            "|    time_elapsed       | 124         |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.01       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 22999       |\n",
            "|    policy_loss        | -36.6       |\n",
            "|    reward             | -0.45205143 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 20.2        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 184      |\n",
            "|    iterations         | 23100    |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 23100    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.01    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 23099    |\n",
            "|    policy_loss        | -15.6    |\n",
            "|    reward             | 4.802259 |\n",
            "|    std                | 1.2      |\n",
            "|    value_loss         | 5.07     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 184      |\n",
            "|    iterations         | 23200    |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 23200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.01    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 23199    |\n",
            "|    policy_loss        | 8.26     |\n",
            "|    reward             | 2.43685  |\n",
            "|    std                | 1.2      |\n",
            "|    value_loss         | 0.924    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 23300     |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 23300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.01     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 23299     |\n",
            "|    policy_loss        | 32.6      |\n",
            "|    reward             | 4.9110117 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 10.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 23400     |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 23400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.02     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 23399     |\n",
            "|    policy_loss        | 12.6      |\n",
            "|    reward             | 1.3435715 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 4.1       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 23500     |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.02     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 23499     |\n",
            "|    policy_loss        | -8.52     |\n",
            "|    reward             | 3.4381773 |\n",
            "|    std                | 1.2       |\n",
            "|    value_loss         | 1.59      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 23600        |\n",
            "|    time_elapsed       | 128          |\n",
            "|    total_timesteps    | 23600        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.03        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 23599        |\n",
            "|    policy_loss        | -0.426       |\n",
            "|    reward             | -0.033828296 |\n",
            "|    std                | 1.21         |\n",
            "|    value_loss         | 0.00185      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 23700        |\n",
            "|    time_elapsed       | 128          |\n",
            "|    total_timesteps    | 23700        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.04        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 23699        |\n",
            "|    policy_loss        | -0.928       |\n",
            "|    reward             | -0.026998404 |\n",
            "|    std                | 1.21         |\n",
            "|    value_loss         | 0.0128       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 23800       |\n",
            "|    time_elapsed       | 129         |\n",
            "|    total_timesteps    | 23800       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.05       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 23799       |\n",
            "|    policy_loss        | 0.828       |\n",
            "|    reward             | -0.09570833 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 0.0136      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 23900      |\n",
            "|    time_elapsed       | 130        |\n",
            "|    total_timesteps    | 23900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.05      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 23899      |\n",
            "|    policy_loss        | 0.661      |\n",
            "|    reward             | 0.16944295 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 0.00546    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24000      |\n",
            "|    time_elapsed       | 130        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.06      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 23999      |\n",
            "|    policy_loss        | -2.48      |\n",
            "|    reward             | 0.60515904 |\n",
            "|    std                | 1.21       |\n",
            "|    value_loss         | 0.08       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 24100       |\n",
            "|    time_elapsed       | 131         |\n",
            "|    total_timesteps    | 24100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.06       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 24099       |\n",
            "|    policy_loss        | 4.86        |\n",
            "|    reward             | -0.41317368 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 0.347       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 24200       |\n",
            "|    time_elapsed       | 131         |\n",
            "|    total_timesteps    | 24200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.07       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 24199       |\n",
            "|    policy_loss        | 1.9         |\n",
            "|    reward             | 0.041982666 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 0.0611      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24300      |\n",
            "|    time_elapsed       | 132        |\n",
            "|    total_timesteps    | 24300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.07      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24299      |\n",
            "|    policy_loss        | -2.41      |\n",
            "|    reward             | 0.20732239 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 0.131      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24400      |\n",
            "|    time_elapsed       | 133        |\n",
            "|    total_timesteps    | 24400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.08      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24399      |\n",
            "|    policy_loss        | -18.9      |\n",
            "|    reward             | -1.1012956 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 3.13       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24500      |\n",
            "|    time_elapsed       | 133        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.08      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24499      |\n",
            "|    policy_loss        | -9.91      |\n",
            "|    reward             | 0.96929544 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 1.48       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24600      |\n",
            "|    time_elapsed       | 134        |\n",
            "|    total_timesteps    | 24600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.08      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24599      |\n",
            "|    policy_loss        | 4.51       |\n",
            "|    reward             | -1.7992162 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 0.423      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24700      |\n",
            "|    time_elapsed       | 134        |\n",
            "|    total_timesteps    | 24700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.08      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24699      |\n",
            "|    policy_loss        | 22.1       |\n",
            "|    reward             | 0.14615634 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 6.4        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24800      |\n",
            "|    time_elapsed       | 135        |\n",
            "|    total_timesteps    | 24800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.09      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24799      |\n",
            "|    policy_loss        | 0.352      |\n",
            "|    reward             | -1.7544711 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 0.00248    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 24900      |\n",
            "|    time_elapsed       | 135        |\n",
            "|    total_timesteps    | 24900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.09      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 24899      |\n",
            "|    policy_loss        | 4.12       |\n",
            "|    reward             | -0.7450834 |\n",
            "|    std                | 1.22       |\n",
            "|    value_loss         | 0.161      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 25000     |\n",
            "|    time_elapsed       | 136       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.09     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 24999     |\n",
            "|    policy_loss        | 10.3      |\n",
            "|    reward             | 1.9669459 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 1.23      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 25100     |\n",
            "|    time_elapsed       | 137       |\n",
            "|    total_timesteps    | 25100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.09     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 25099     |\n",
            "|    policy_loss        | -10.3     |\n",
            "|    reward             | 0.2531272 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 2.86      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 25200       |\n",
            "|    time_elapsed       | 137         |\n",
            "|    total_timesteps    | 25200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.09       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 25199       |\n",
            "|    policy_loss        | -13.9       |\n",
            "|    reward             | -0.08400391 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 3.86        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 25300     |\n",
            "|    time_elapsed       | 138       |\n",
            "|    total_timesteps    | 25300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.1      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 25299     |\n",
            "|    policy_loss        | -5.59     |\n",
            "|    reward             | 3.5867262 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 0.275     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 25400     |\n",
            "|    time_elapsed       | 138       |\n",
            "|    total_timesteps    | 25400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.1      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 25399     |\n",
            "|    policy_loss        | 28.3      |\n",
            "|    reward             | 1.1100734 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 16.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 25500     |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.1      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 25499     |\n",
            "|    policy_loss        | -19.5     |\n",
            "|    reward             | 0.5064259 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 8.16      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 25600     |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 25600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.1      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 25599     |\n",
            "|    policy_loss        | -22.7     |\n",
            "|    reward             | 10.026844 |\n",
            "|    std                | 1.22      |\n",
            "|    value_loss         | 10.6      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 25700        |\n",
            "|    time_elapsed       | 140          |\n",
            "|    total_timesteps    | 25700        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.11        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 25699        |\n",
            "|    policy_loss        | -0.409       |\n",
            "|    reward             | -0.017304104 |\n",
            "|    std                | 1.22         |\n",
            "|    value_loss         | 0.00392      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 25800        |\n",
            "|    time_elapsed       | 140          |\n",
            "|    total_timesteps    | 25800        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.12        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 25799        |\n",
            "|    policy_loss        | -0.44        |\n",
            "|    reward             | -0.014493515 |\n",
            "|    std                | 1.23         |\n",
            "|    value_loss         | 0.00273      |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 25900     |\n",
            "|    time_elapsed       | 141       |\n",
            "|    total_timesteps    | 25900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.12     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 25899     |\n",
            "|    policy_loss        | 0.867     |\n",
            "|    reward             | 0.0644009 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.00795   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 26000      |\n",
            "|    time_elapsed       | 142        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.13      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 25999      |\n",
            "|    policy_loss        | -2.02      |\n",
            "|    reward             | -0.5972768 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.0602     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 26100      |\n",
            "|    time_elapsed       | 142        |\n",
            "|    total_timesteps    | 26100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.13      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 26099      |\n",
            "|    policy_loss        | 2.15       |\n",
            "|    reward             | 0.74153996 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.0976     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 26200      |\n",
            "|    time_elapsed       | 143        |\n",
            "|    total_timesteps    | 26200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.14      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 26199      |\n",
            "|    policy_loss        | 3.71       |\n",
            "|    reward             | 0.15817362 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.276      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 26300     |\n",
            "|    time_elapsed       | 143       |\n",
            "|    total_timesteps    | 26300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.14     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 26299     |\n",
            "|    policy_loss        | 0.432     |\n",
            "|    reward             | 0.7612155 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.00212   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 26400      |\n",
            "|    time_elapsed       | 144        |\n",
            "|    total_timesteps    | 26400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.14      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 26399      |\n",
            "|    policy_loss        | -23.4      |\n",
            "|    reward             | -0.7438066 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 10.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 26500     |\n",
            "|    time_elapsed       | 144       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.15     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 26499     |\n",
            "|    policy_loss        | -5.94     |\n",
            "|    reward             | 0.3358036 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 0.651     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 26600       |\n",
            "|    time_elapsed       | 145         |\n",
            "|    total_timesteps    | 26600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.15       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 26599       |\n",
            "|    policy_loss        | 8.48        |\n",
            "|    reward             | -0.82379586 |\n",
            "|    std                | 1.23        |\n",
            "|    value_loss         | 1.25        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 26700     |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 26700     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.15     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 26699     |\n",
            "|    policy_loss        | -0.0632   |\n",
            "|    reward             | 2.1186523 |\n",
            "|    std                | 1.23      |\n",
            "|    value_loss         | 5.44e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 26800     |\n",
            "|    time_elapsed       | 146       |\n",
            "|    total_timesteps    | 26800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.15     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 26799     |\n",
            "|    policy_loss        | 3.08      |\n",
            "|    reward             | 0.8402339 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 0.192     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 26900      |\n",
            "|    time_elapsed       | 147        |\n",
            "|    total_timesteps    | 26900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.16      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 26899      |\n",
            "|    policy_loss        | -21.3      |\n",
            "|    reward             | 0.05156756 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 2.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 27000      |\n",
            "|    time_elapsed       | 147        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.16      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 26999      |\n",
            "|    policy_loss        | 10.2       |\n",
            "|    reward             | 0.33870134 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 2.14       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 27100      |\n",
            "|    time_elapsed       | 148        |\n",
            "|    total_timesteps    | 27100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.16      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 27099      |\n",
            "|    policy_loss        | 10.4       |\n",
            "|    reward             | 0.86168236 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 0.819      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 27200      |\n",
            "|    time_elapsed       | 148        |\n",
            "|    total_timesteps    | 27200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.16      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 27199      |\n",
            "|    policy_loss        | 47         |\n",
            "|    reward             | -3.2990277 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 33         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 27300      |\n",
            "|    time_elapsed       | 149        |\n",
            "|    total_timesteps    | 27300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.16      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 27299      |\n",
            "|    policy_loss        | -42.1      |\n",
            "|    reward             | 0.47775388 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 31.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 27400     |\n",
            "|    time_elapsed       | 149       |\n",
            "|    total_timesteps    | 27400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.16     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 27399     |\n",
            "|    policy_loss        | -47.6     |\n",
            "|    reward             | 12.394828 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 39.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 27500     |\n",
            "|    time_elapsed       | 150       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.16     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 27499     |\n",
            "|    policy_loss        | -14.3     |\n",
            "|    reward             | 3.2720864 |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 4.03      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 27600    |\n",
            "|    time_elapsed       | 151      |\n",
            "|    total_timesteps    | 27600    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.16    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 27599    |\n",
            "|    policy_loss        | 27.4     |\n",
            "|    reward             | 6.566808 |\n",
            "|    std                | 1.24     |\n",
            "|    value_loss         | 14       |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 27700      |\n",
            "|    time_elapsed       | 151        |\n",
            "|    total_timesteps    | 27700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.17      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 27699      |\n",
            "|    policy_loss        | -65.3      |\n",
            "|    reward             | -4.1444116 |\n",
            "|    std                | 1.24       |\n",
            "|    value_loss         | 83.6       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 27800        |\n",
            "|    time_elapsed       | 152          |\n",
            "|    total_timesteps    | 27800        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.17        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 27799        |\n",
            "|    policy_loss        | -0.346       |\n",
            "|    reward             | -0.040658534 |\n",
            "|    std                | 1.24         |\n",
            "|    value_loss         | 0.0017       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 27900       |\n",
            "|    time_elapsed       | 153         |\n",
            "|    total_timesteps    | 27900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.18       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 27899       |\n",
            "|    policy_loss        | -3.11       |\n",
            "|    reward             | 0.045768082 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 0.129       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 181          |\n",
            "|    iterations         | 28000        |\n",
            "|    time_elapsed       | 154          |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.19        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 27999        |\n",
            "|    policy_loss        | -7.82        |\n",
            "|    reward             | 0.0055516935 |\n",
            "|    std                | 1.24         |\n",
            "|    value_loss         | 0.316        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 28100      |\n",
            "|    time_elapsed       | 154        |\n",
            "|    total_timesteps    | 28100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.19      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 28099      |\n",
            "|    policy_loss        | -4.25      |\n",
            "|    reward             | -0.2962781 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 0.394      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 28200      |\n",
            "|    time_elapsed       | 155        |\n",
            "|    total_timesteps    | 28200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.2       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 28199      |\n",
            "|    policy_loss        | -3.46      |\n",
            "|    reward             | 0.34164843 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 0.142      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 28300     |\n",
            "|    time_elapsed       | 155       |\n",
            "|    total_timesteps    | 28300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.2      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 28299     |\n",
            "|    policy_loss        | 23.1      |\n",
            "|    reward             | 0.8547702 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 7.08      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 28400     |\n",
            "|    time_elapsed       | 156       |\n",
            "|    total_timesteps    | 28400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.2      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 28399     |\n",
            "|    policy_loss        | -3.01     |\n",
            "|    reward             | 1.4599423 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 0.139     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 28500      |\n",
            "|    time_elapsed       | 156        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.2       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 28499      |\n",
            "|    policy_loss        | 3.72       |\n",
            "|    reward             | 0.23003072 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 0.273      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 28600       |\n",
            "|    time_elapsed       | 157         |\n",
            "|    total_timesteps    | 28600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.21       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 28599       |\n",
            "|    policy_loss        | -5.58       |\n",
            "|    reward             | 0.039191138 |\n",
            "|    std                | 1.25        |\n",
            "|    value_loss         | 0.589       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 28700      |\n",
            "|    time_elapsed       | 158        |\n",
            "|    total_timesteps    | 28700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.21      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 28699      |\n",
            "|    policy_loss        | 16.7       |\n",
            "|    reward             | 0.19748157 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 5.68       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 28800     |\n",
            "|    time_elapsed       | 158       |\n",
            "|    total_timesteps    | 28800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.21     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 28799     |\n",
            "|    policy_loss        | 4.79      |\n",
            "|    reward             | 2.3593638 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 0.489     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 28900       |\n",
            "|    time_elapsed       | 159         |\n",
            "|    total_timesteps    | 28900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.21       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 28899       |\n",
            "|    policy_loss        | -6.88       |\n",
            "|    reward             | 0.078237765 |\n",
            "|    std                | 1.25        |\n",
            "|    value_loss         | 0.722       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 29000     |\n",
            "|    time_elapsed       | 159       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.22     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 28999     |\n",
            "|    policy_loss        | -1.68     |\n",
            "|    reward             | 0.4718694 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 0.0655    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 29100      |\n",
            "|    time_elapsed       | 160        |\n",
            "|    total_timesteps    | 29100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.22      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 29099      |\n",
            "|    policy_loss        | -2.65      |\n",
            "|    reward             | -0.2790023 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 0.0873     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 29200      |\n",
            "|    time_elapsed       | 160        |\n",
            "|    total_timesteps    | 29200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.22      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 29199      |\n",
            "|    policy_loss        | 19.6       |\n",
            "|    reward             | -1.3406165 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 5.7        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 29300     |\n",
            "|    time_elapsed       | 161       |\n",
            "|    total_timesteps    | 29300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.22     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 29299     |\n",
            "|    policy_loss        | -18.5     |\n",
            "|    reward             | 0.7086442 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 3.88      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 29400      |\n",
            "|    time_elapsed       | 162        |\n",
            "|    total_timesteps    | 29400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.23      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 29399      |\n",
            "|    policy_loss        | -3.89      |\n",
            "|    reward             | 0.45724407 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 0.273      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 29500     |\n",
            "|    time_elapsed       | 162       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.23     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 29499     |\n",
            "|    policy_loss        | 27.3      |\n",
            "|    reward             | 6.0012703 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 8.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 29600     |\n",
            "|    time_elapsed       | 163       |\n",
            "|    total_timesteps    | 29600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.23     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 29599     |\n",
            "|    policy_loss        | -17.4     |\n",
            "|    reward             | 1.1303413 |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 5.67      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 29700      |\n",
            "|    time_elapsed       | 163        |\n",
            "|    total_timesteps    | 29700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.23      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 29699      |\n",
            "|    policy_loss        | 18.9       |\n",
            "|    reward             | -1.6529261 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 8.06       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 29800     |\n",
            "|    time_elapsed       | 164       |\n",
            "|    total_timesteps    | 29800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.23     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 29799     |\n",
            "|    policy_loss        | -28       |\n",
            "|    reward             | 2.5189254 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 7.54      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 29900    |\n",
            "|    time_elapsed       | 164      |\n",
            "|    total_timesteps    | 29900    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.23    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 29899    |\n",
            "|    policy_loss        | -5.94    |\n",
            "|    reward             | 9.503875 |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.403    |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 30000       |\n",
            "|    time_elapsed       | 165         |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.24       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 29999       |\n",
            "|    policy_loss        | -0.466      |\n",
            "|    reward             | -0.06919665 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 0.00489     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 30100      |\n",
            "|    time_elapsed       | 165        |\n",
            "|    total_timesteps    | 30100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.25      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 30099      |\n",
            "|    policy_loss        | -2.69      |\n",
            "|    reward             | -0.1305721 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 0.0617     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 181          |\n",
            "|    iterations         | 30200        |\n",
            "|    time_elapsed       | 166          |\n",
            "|    total_timesteps    | 30200        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.26        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 30199        |\n",
            "|    policy_loss        | -0.66        |\n",
            "|    reward             | -0.060544085 |\n",
            "|    std                | 1.26         |\n",
            "|    value_loss         | 0.00509      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 30300      |\n",
            "|    time_elapsed       | 166        |\n",
            "|    total_timesteps    | 30300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.26      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 30299      |\n",
            "|    policy_loss        | 5.57       |\n",
            "|    reward             | 0.15524752 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 0.65       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 30400      |\n",
            "|    time_elapsed       | 167        |\n",
            "|    total_timesteps    | 30400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.27      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 30399      |\n",
            "|    policy_loss        | -1.14      |\n",
            "|    reward             | -0.1987944 |\n",
            "|    std                | 1.26       |\n",
            "|    value_loss         | 0.0237     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 30500     |\n",
            "|    time_elapsed       | 167       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.27     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 30499     |\n",
            "|    policy_loss        | -2.07     |\n",
            "|    reward             | 0.7524502 |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 0.0696    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 30600      |\n",
            "|    time_elapsed       | 168        |\n",
            "|    total_timesteps    | 30600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.27      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 30599      |\n",
            "|    policy_loss        | 0.436      |\n",
            "|    reward             | -0.9338158 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 0.00214    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 30700      |\n",
            "|    time_elapsed       | 169        |\n",
            "|    total_timesteps    | 30700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.28      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 30699      |\n",
            "|    policy_loss        | -14.2      |\n",
            "|    reward             | 0.72383666 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 1.07       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 30800     |\n",
            "|    time_elapsed       | 169       |\n",
            "|    total_timesteps    | 30800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.28     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 30799     |\n",
            "|    policy_loss        | 7.54      |\n",
            "|    reward             | -1.944762 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 0.917     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 30900       |\n",
            "|    time_elapsed       | 170         |\n",
            "|    total_timesteps    | 30900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.28       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 30899       |\n",
            "|    policy_loss        | 0.949       |\n",
            "|    reward             | 0.055448636 |\n",
            "|    std                | 1.27        |\n",
            "|    value_loss         | 0.0155      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 31000      |\n",
            "|    time_elapsed       | 170        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.28      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 30999      |\n",
            "|    policy_loss        | 2.21       |\n",
            "|    reward             | -3.4515219 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 0.111      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 31100       |\n",
            "|    time_elapsed       | 171         |\n",
            "|    total_timesteps    | 31100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.28       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 31099       |\n",
            "|    policy_loss        | -15.9       |\n",
            "|    reward             | 0.080280855 |\n",
            "|    std                | 1.27        |\n",
            "|    value_loss         | 2.6         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 181        |\n",
            "|    iterations         | 31200      |\n",
            "|    time_elapsed       | 171        |\n",
            "|    total_timesteps    | 31200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.29      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 31199      |\n",
            "|    policy_loss        | -3.53      |\n",
            "|    reward             | 0.03306753 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 0.146      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 31300    |\n",
            "|    time_elapsed       | 172      |\n",
            "|    total_timesteps    | 31300    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.29    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 31299    |\n",
            "|    policy_loss        | -16      |\n",
            "|    reward             | 4.699279 |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 3.18     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 31400     |\n",
            "|    time_elapsed       | 172       |\n",
            "|    total_timesteps    | 31400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.29     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 31399     |\n",
            "|    policy_loss        | 9.05      |\n",
            "|    reward             | 1.6853441 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 0.887     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 31500     |\n",
            "|    time_elapsed       | 173       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.29     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 31499     |\n",
            "|    policy_loss        | 20.3      |\n",
            "|    reward             | 1.3193097 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 6.14      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 31600     |\n",
            "|    time_elapsed       | 173       |\n",
            "|    total_timesteps    | 31600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.3      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 31599     |\n",
            "|    policy_loss        | -8.03     |\n",
            "|    reward             | 2.0240142 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 0.913     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 31700    |\n",
            "|    time_elapsed       | 174      |\n",
            "|    total_timesteps    | 31700    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.3     |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 31699    |\n",
            "|    policy_loss        | -31.9    |\n",
            "|    reward             | 3.018443 |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 12.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 31800     |\n",
            "|    time_elapsed       | 174       |\n",
            "|    total_timesteps    | 31800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.3      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 31799     |\n",
            "|    policy_loss        | 13.4      |\n",
            "|    reward             | 0.5931855 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 1.8       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 31900      |\n",
            "|    time_elapsed       | 175        |\n",
            "|    total_timesteps    | 31900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.3       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 31899      |\n",
            "|    policy_loss        | 31.7       |\n",
            "|    reward             | -0.8051139 |\n",
            "|    std                | 1.27       |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 32000     |\n",
            "|    time_elapsed       | 175       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.3      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 31999     |\n",
            "|    policy_loss        | -54.8     |\n",
            "|    reward             | 10.575008 |\n",
            "|    std                | 1.27      |\n",
            "|    value_loss         | 70.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 32100       |\n",
            "|    time_elapsed       | 176         |\n",
            "|    total_timesteps    | 32100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.31       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 32099       |\n",
            "|    policy_loss        | 0.763       |\n",
            "|    reward             | 0.097133555 |\n",
            "|    std                | 1.27        |\n",
            "|    value_loss         | 0.0109      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 32200       |\n",
            "|    time_elapsed       | 176         |\n",
            "|    total_timesteps    | 32200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.31       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 32199       |\n",
            "|    policy_loss        | -1.21       |\n",
            "|    reward             | -0.32014287 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 0.0188      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 32300       |\n",
            "|    time_elapsed       | 177         |\n",
            "|    total_timesteps    | 32300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.32       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 32299       |\n",
            "|    policy_loss        | -1.2        |\n",
            "|    reward             | -0.18380626 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 0.022       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 32400      |\n",
            "|    time_elapsed       | 177        |\n",
            "|    total_timesteps    | 32400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.33      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 32399      |\n",
            "|    policy_loss        | 5.74       |\n",
            "|    reward             | 0.28254485 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 0.358      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 32500    |\n",
            "|    time_elapsed       | 178      |\n",
            "|    total_timesteps    | 32500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.33    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 32499    |\n",
            "|    policy_loss        | 2.29     |\n",
            "|    reward             | 0.816752 |\n",
            "|    std                | 1.28     |\n",
            "|    value_loss         | 0.0881   |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 32600      |\n",
            "|    time_elapsed       | 178        |\n",
            "|    total_timesteps    | 32600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.33      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 32599      |\n",
            "|    policy_loss        | -6.8       |\n",
            "|    reward             | 0.78246087 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 0.474      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 32700      |\n",
            "|    time_elapsed       | 179        |\n",
            "|    total_timesteps    | 32700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.34      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 32699      |\n",
            "|    policy_loss        | -10.6      |\n",
            "|    reward             | 0.30985782 |\n",
            "|    std                | 1.28       |\n",
            "|    value_loss         | 0.973      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 32800     |\n",
            "|    time_elapsed       | 179       |\n",
            "|    total_timesteps    | 32800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.34     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 32799     |\n",
            "|    policy_loss        | 5.44      |\n",
            "|    reward             | 3.0113964 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 0.434     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 32900     |\n",
            "|    time_elapsed       | 180       |\n",
            "|    total_timesteps    | 32900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.34     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 32899     |\n",
            "|    policy_loss        | 2.29      |\n",
            "|    reward             | 1.1343002 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 0.0586    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33000     |\n",
            "|    time_elapsed       | 180       |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.34     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 32999     |\n",
            "|    policy_loss        | 38.7      |\n",
            "|    reward             | 1.3468394 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 10.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33100     |\n",
            "|    time_elapsed       | 181       |\n",
            "|    total_timesteps    | 33100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.35     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33099     |\n",
            "|    policy_loss        | 2.47      |\n",
            "|    reward             | 2.7022443 |\n",
            "|    std                | 1.28      |\n",
            "|    value_loss         | 0.1       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33200     |\n",
            "|    time_elapsed       | 181       |\n",
            "|    total_timesteps    | 33200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.35     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33199     |\n",
            "|    policy_loss        | -0.375    |\n",
            "|    reward             | 0.2524221 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 0.00207   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33300     |\n",
            "|    time_elapsed       | 182       |\n",
            "|    total_timesteps    | 33300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.35     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33299     |\n",
            "|    policy_loss        | -8.63     |\n",
            "|    reward             | 1.5093362 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 0.642     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 33400        |\n",
            "|    time_elapsed       | 182          |\n",
            "|    total_timesteps    | 33400        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.35        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 33399        |\n",
            "|    policy_loss        | -3.03        |\n",
            "|    reward             | 0.0051350053 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 0.175        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33500     |\n",
            "|    time_elapsed       | 183       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.36     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33499     |\n",
            "|    policy_loss        | 0.851     |\n",
            "|    reward             | 0.0938773 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 0.0109    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33600     |\n",
            "|    time_elapsed       | 183       |\n",
            "|    total_timesteps    | 33600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.36     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33599     |\n",
            "|    policy_loss        | 23.9      |\n",
            "|    reward             | 5.0898223 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 10.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33700     |\n",
            "|    time_elapsed       | 184       |\n",
            "|    total_timesteps    | 33700     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.36     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33699     |\n",
            "|    policy_loss        | 10.1      |\n",
            "|    reward             | 1.2898878 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 1.89      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 33800     |\n",
            "|    time_elapsed       | 184       |\n",
            "|    total_timesteps    | 33800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.36     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 33799     |\n",
            "|    policy_loss        | -78.6     |\n",
            "|    reward             | 2.1950598 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 62.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 33900    |\n",
            "|    time_elapsed       | 185      |\n",
            "|    total_timesteps    | 33900    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.36    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 33899    |\n",
            "|    policy_loss        | 47.9     |\n",
            "|    reward             | -2.71806 |\n",
            "|    std                | 1.29     |\n",
            "|    value_loss         | 34.1     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 34000       |\n",
            "|    time_elapsed       | 186         |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.36       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 33999       |\n",
            "|    policy_loss        | 12.3        |\n",
            "|    reward             | -0.09201228 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 3.81        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 34100     |\n",
            "|    time_elapsed       | 186       |\n",
            "|    total_timesteps    | 34100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.36     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 34099     |\n",
            "|    policy_loss        | 4.35      |\n",
            "|    reward             | -2.058872 |\n",
            "|    std                | 1.29      |\n",
            "|    value_loss         | 0.305     |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 182           |\n",
            "|    iterations         | 34200         |\n",
            "|    time_elapsed       | 187           |\n",
            "|    total_timesteps    | 34200         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -8.36         |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 34199         |\n",
            "|    policy_loss        | 0.0916        |\n",
            "|    reward             | 0.00019888804 |\n",
            "|    std                | 1.29          |\n",
            "|    value_loss         | 0.000121      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 34300       |\n",
            "|    time_elapsed       | 187         |\n",
            "|    total_timesteps    | 34300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.38       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 34299       |\n",
            "|    policy_loss        | 3.03        |\n",
            "|    reward             | 0.045574497 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.146       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 34400      |\n",
            "|    time_elapsed       | 188        |\n",
            "|    total_timesteps    | 34400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.38      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 34399      |\n",
            "|    policy_loss        | 2.33       |\n",
            "|    reward             | 0.21866718 |\n",
            "|    std                | 1.29       |\n",
            "|    value_loss         | 0.0754     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 34500       |\n",
            "|    time_elapsed       | 188         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.38       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 34499       |\n",
            "|    policy_loss        | 0.982       |\n",
            "|    reward             | -0.08328878 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.0176      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 34600      |\n",
            "|    time_elapsed       | 189        |\n",
            "|    total_timesteps    | 34600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.39      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 34599      |\n",
            "|    policy_loss        | -3.25      |\n",
            "|    reward             | -0.5580885 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.152      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 34700      |\n",
            "|    time_elapsed       | 189        |\n",
            "|    total_timesteps    | 34700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.39      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 34699      |\n",
            "|    policy_loss        | 2.16       |\n",
            "|    reward             | 0.64707565 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.0487     |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 34800    |\n",
            "|    time_elapsed       | 190      |\n",
            "|    total_timesteps    | 34800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.4     |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 34799    |\n",
            "|    policy_loss        | -0.553   |\n",
            "|    reward             | 2.128548 |\n",
            "|    std                | 1.3      |\n",
            "|    value_loss         | 0.00546  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 34900      |\n",
            "|    time_elapsed       | 190        |\n",
            "|    total_timesteps    | 34900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.4       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 34899      |\n",
            "|    policy_loss        | 7.61       |\n",
            "|    reward             | -0.7381392 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.378      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 35000       |\n",
            "|    time_elapsed       | 191         |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.4        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 34999       |\n",
            "|    policy_loss        | 15.5        |\n",
            "|    reward             | -0.17071113 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 2.46        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 35100      |\n",
            "|    time_elapsed       | 191        |\n",
            "|    total_timesteps    | 35100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.4       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 35099      |\n",
            "|    policy_loss        | 3.07       |\n",
            "|    reward             | -0.9729886 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.116      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 35200      |\n",
            "|    time_elapsed       | 192        |\n",
            "|    total_timesteps    | 35200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.41      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 35199      |\n",
            "|    policy_loss        | -1.56      |\n",
            "|    reward             | -1.6222363 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.0375     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 35300      |\n",
            "|    time_elapsed       | 192        |\n",
            "|    total_timesteps    | 35300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.41      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 35299      |\n",
            "|    policy_loss        | -0.74      |\n",
            "|    reward             | 0.66569936 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.00567    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 35400       |\n",
            "|    time_elapsed       | 193         |\n",
            "|    total_timesteps    | 35400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.41       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 35399       |\n",
            "|    policy_loss        | 3.87        |\n",
            "|    reward             | -0.77215713 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 0.329       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 35500       |\n",
            "|    time_elapsed       | 194         |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.41       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 35499       |\n",
            "|    policy_loss        | 15.9        |\n",
            "|    reward             | -0.60059553 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 2.58        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 35600        |\n",
            "|    time_elapsed       | 194          |\n",
            "|    total_timesteps    | 35600        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.41        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 35599        |\n",
            "|    policy_loss        | 0.155        |\n",
            "|    reward             | -0.027057454 |\n",
            "|    std                | 1.3          |\n",
            "|    value_loss         | 0.000457     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 35700      |\n",
            "|    time_elapsed       | 195        |\n",
            "|    total_timesteps    | 35700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.42      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 35699      |\n",
            "|    policy_loss        | 6.98       |\n",
            "|    reward             | -0.9851255 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.486      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 35800      |\n",
            "|    time_elapsed       | 195        |\n",
            "|    total_timesteps    | 35800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.42      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 35799      |\n",
            "|    policy_loss        | 18.5       |\n",
            "|    reward             | -0.3055958 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 4.78       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 35900    |\n",
            "|    time_elapsed       | 196      |\n",
            "|    total_timesteps    | 35900    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.42    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 35899    |\n",
            "|    policy_loss        | -14.6    |\n",
            "|    reward             | 4.575115 |\n",
            "|    std                | 1.3      |\n",
            "|    value_loss         | 2.76     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 36000     |\n",
            "|    time_elapsed       | 196       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.42     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 35999     |\n",
            "|    policy_loss        | 0.604     |\n",
            "|    reward             | 1.6925563 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 0.00303   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 36100      |\n",
            "|    time_elapsed       | 197        |\n",
            "|    total_timesteps    | 36100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.42      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 36099      |\n",
            "|    policy_loss        | -19.4      |\n",
            "|    reward             | -6.6457944 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 9.25       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 36200     |\n",
            "|    time_elapsed       | 197       |\n",
            "|    total_timesteps    | 36200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.42     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 36199     |\n",
            "|    policy_loss        | -4.48     |\n",
            "|    reward             | 1.8889616 |\n",
            "|    std                | 1.3       |\n",
            "|    value_loss         | 0.391     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 36300     |\n",
            "|    time_elapsed       | 198       |\n",
            "|    total_timesteps    | 36300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.43     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 36299     |\n",
            "|    policy_loss        | -31.6     |\n",
            "|    reward             | 5.4246874 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 18.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 36400       |\n",
            "|    time_elapsed       | 198         |\n",
            "|    total_timesteps    | 36400       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.44       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 36399       |\n",
            "|    policy_loss        | -0.363      |\n",
            "|    reward             | 0.015673049 |\n",
            "|    std                | 1.31        |\n",
            "|    value_loss         | 0.00169     |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 36500    |\n",
            "|    time_elapsed       | 199      |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.45    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 36499    |\n",
            "|    policy_loss        | 0.152    |\n",
            "|    reward             | 0.415914 |\n",
            "|    std                | 1.31     |\n",
            "|    value_loss         | 0.000157 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 36600     |\n",
            "|    time_elapsed       | 199       |\n",
            "|    total_timesteps    | 36600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.45     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 36599     |\n",
            "|    policy_loss        | -1.48     |\n",
            "|    reward             | 0.4785655 |\n",
            "|    std                | 1.31      |\n",
            "|    value_loss         | 0.04      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 36700      |\n",
            "|    time_elapsed       | 200        |\n",
            "|    total_timesteps    | 36700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.46      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 36699      |\n",
            "|    policy_loss        | 2.8        |\n",
            "|    reward             | 0.19960327 |\n",
            "|    std                | 1.31       |\n",
            "|    value_loss         | 0.153      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 36800        |\n",
            "|    time_elapsed       | 200          |\n",
            "|    total_timesteps    | 36800        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.46        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 36799        |\n",
            "|    policy_loss        | -2.73        |\n",
            "|    reward             | -0.032489236 |\n",
            "|    std                | 1.31         |\n",
            "|    value_loss         | 0.0646       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 36900       |\n",
            "|    time_elapsed       | 201         |\n",
            "|    total_timesteps    | 36900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.46       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 36899       |\n",
            "|    policy_loss        | -9.11       |\n",
            "|    reward             | -0.78765833 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 1.85        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 37000    |\n",
            "|    time_elapsed       | 201      |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 36999    |\n",
            "|    policy_loss        | -7.05    |\n",
            "|    reward             | 0.556453 |\n",
            "|    std                | 1.32     |\n",
            "|    value_loss         | 0.833    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 37100      |\n",
            "|    time_elapsed       | 202        |\n",
            "|    total_timesteps    | 37100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.47      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 37099      |\n",
            "|    policy_loss        | -71.4      |\n",
            "|    reward             | -0.8620876 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 76         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 37200     |\n",
            "|    time_elapsed       | 202       |\n",
            "|    total_timesteps    | 37200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.47     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 37199     |\n",
            "|    policy_loss        | -3.84     |\n",
            "|    reward             | 0.7393993 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 0.262     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 37300       |\n",
            "|    time_elapsed       | 203         |\n",
            "|    total_timesteps    | 37300       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.47       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 37299       |\n",
            "|    policy_loss        | -0.387      |\n",
            "|    reward             | -0.39693132 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 0.00339     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 37400      |\n",
            "|    time_elapsed       | 204        |\n",
            "|    total_timesteps    | 37400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.48      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 37399      |\n",
            "|    policy_loss        | 1.34       |\n",
            "|    reward             | -1.4088389 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 0.0472     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 37500     |\n",
            "|    time_elapsed       | 204       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.48     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 37499     |\n",
            "|    policy_loss        | -4.84     |\n",
            "|    reward             | 0.4377077 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 0.383     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 37600      |\n",
            "|    time_elapsed       | 205        |\n",
            "|    total_timesteps    | 37600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.48      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 37599      |\n",
            "|    policy_loss        | 20.2       |\n",
            "|    reward             | 0.03172926 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 2.44       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 37700    |\n",
            "|    time_elapsed       | 205      |\n",
            "|    total_timesteps    | 37700    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 37699    |\n",
            "|    policy_loss        | -11.9    |\n",
            "|    reward             | 1.237313 |\n",
            "|    std                | 1.32     |\n",
            "|    value_loss         | 1.07     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 37800     |\n",
            "|    time_elapsed       | 206       |\n",
            "|    total_timesteps    | 37800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.48     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 37799     |\n",
            "|    policy_loss        | -0.43     |\n",
            "|    reward             | 1.2051888 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 0.00324   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 37900    |\n",
            "|    time_elapsed       | 206      |\n",
            "|    total_timesteps    | 37900    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 37899    |\n",
            "|    policy_loss        | -44.6    |\n",
            "|    reward             | 2.077004 |\n",
            "|    std                | 1.32     |\n",
            "|    value_loss         | 31.6     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 38000     |\n",
            "|    time_elapsed       | 207       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.49     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 37999     |\n",
            "|    policy_loss        | 1.91      |\n",
            "|    reward             | -2.031094 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 0.0559    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 38100     |\n",
            "|    time_elapsed       | 207       |\n",
            "|    total_timesteps    | 38100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.49     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 38099     |\n",
            "|    policy_loss        | 8.02      |\n",
            "|    reward             | 2.9654405 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 1.38      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 38200      |\n",
            "|    time_elapsed       | 208        |\n",
            "|    total_timesteps    | 38200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.49      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 38199      |\n",
            "|    policy_loss        | 3.9        |\n",
            "|    reward             | -0.7473426 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 0.235      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 38300     |\n",
            "|    time_elapsed       | 208       |\n",
            "|    total_timesteps    | 38300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.49     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 38299     |\n",
            "|    policy_loss        | -21.2     |\n",
            "|    reward             | 5.3677993 |\n",
            "|    std                | 1.32      |\n",
            "|    value_loss         | 11        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 38400      |\n",
            "|    time_elapsed       | 209        |\n",
            "|    total_timesteps    | 38400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.49      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 38399      |\n",
            "|    policy_loss        | 87.6       |\n",
            "|    reward             | -10.395057 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 190        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 38500       |\n",
            "|    time_elapsed       | 209         |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.5        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 38499       |\n",
            "|    policy_loss        | 0.343       |\n",
            "|    reward             | 0.043104474 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 0.00214     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 38600       |\n",
            "|    time_elapsed       | 210         |\n",
            "|    total_timesteps    | 38600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.51       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 38599       |\n",
            "|    policy_loss        | 3.33        |\n",
            "|    reward             | -0.07852642 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 0.175       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 38700      |\n",
            "|    time_elapsed       | 210        |\n",
            "|    total_timesteps    | 38700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.51      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 38699      |\n",
            "|    policy_loss        | 0.734      |\n",
            "|    reward             | 0.14446697 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.00546    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 38800     |\n",
            "|    time_elapsed       | 211       |\n",
            "|    total_timesteps    | 38800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.52     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 38799     |\n",
            "|    policy_loss        | 5.21      |\n",
            "|    reward             | 1.5913703 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 0.68      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 38900       |\n",
            "|    time_elapsed       | 211         |\n",
            "|    total_timesteps    | 38900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.52       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 38899       |\n",
            "|    policy_loss        | -1.16       |\n",
            "|    reward             | -0.48205316 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 0.032       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 39000       |\n",
            "|    time_elapsed       | 212         |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.52       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 38999       |\n",
            "|    policy_loss        | 0.998       |\n",
            "|    reward             | -0.28894845 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 0.0102      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 39100      |\n",
            "|    time_elapsed       | 212        |\n",
            "|    total_timesteps    | 39100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39099      |\n",
            "|    policy_loss        | 11.7       |\n",
            "|    reward             | 0.21809481 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.839      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 39200      |\n",
            "|    time_elapsed       | 213        |\n",
            "|    total_timesteps    | 39200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39199      |\n",
            "|    policy_loss        | 4.25       |\n",
            "|    reward             | 0.21557404 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.14       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 39300      |\n",
            "|    time_elapsed       | 213        |\n",
            "|    total_timesteps    | 39300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39299      |\n",
            "|    policy_loss        | 14.1       |\n",
            "|    reward             | 0.94163954 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 2.3        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 39400      |\n",
            "|    time_elapsed       | 214        |\n",
            "|    total_timesteps    | 39400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.53      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39399      |\n",
            "|    policy_loss        | -21.1      |\n",
            "|    reward             | 0.88208276 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 7.67       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 39500     |\n",
            "|    time_elapsed       | 214       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.53     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 39499     |\n",
            "|    policy_loss        | -6.88     |\n",
            "|    reward             | 2.2756467 |\n",
            "|    std                | 1.33      |\n",
            "|    value_loss         | 0.504     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 39600      |\n",
            "|    time_elapsed       | 215        |\n",
            "|    total_timesteps    | 39600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.54      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39599      |\n",
            "|    policy_loss        | 2.89       |\n",
            "|    reward             | 0.19199264 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.158      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 39700      |\n",
            "|    time_elapsed       | 215        |\n",
            "|    total_timesteps    | 39700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.54      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39699      |\n",
            "|    policy_loss        | -2.09      |\n",
            "|    reward             | -0.6223008 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 0.102      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 39800     |\n",
            "|    time_elapsed       | 216       |\n",
            "|    total_timesteps    | 39800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.54     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 39799     |\n",
            "|    policy_loss        | 4         |\n",
            "|    reward             | 3.2512846 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 0.19      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 39900       |\n",
            "|    time_elapsed       | 216         |\n",
            "|    total_timesteps    | 39900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.54       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 39899       |\n",
            "|    policy_loss        | -1.1        |\n",
            "|    reward             | 0.075848356 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 0.0138      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 40000      |\n",
            "|    time_elapsed       | 217        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.55      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 39999      |\n",
            "|    policy_loss        | 57.7       |\n",
            "|    reward             | -3.7159514 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 68.4       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 40100    |\n",
            "|    time_elapsed       | 218      |\n",
            "|    total_timesteps    | 40100    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.55    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 40099    |\n",
            "|    policy_loss        | -3.1     |\n",
            "|    reward             | 2.129176 |\n",
            "|    std                | 1.34     |\n",
            "|    value_loss         | 0.108    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 40200     |\n",
            "|    time_elapsed       | 218       |\n",
            "|    total_timesteps    | 40200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.55     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 40199     |\n",
            "|    policy_loss        | -51.9     |\n",
            "|    reward             | 2.9947155 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 39.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 40300     |\n",
            "|    time_elapsed       | 219       |\n",
            "|    total_timesteps    | 40300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.55     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 40299     |\n",
            "|    policy_loss        | 11.6      |\n",
            "|    reward             | 3.2058752 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 2.36      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 40400     |\n",
            "|    time_elapsed       | 219       |\n",
            "|    total_timesteps    | 40400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.55     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 40399     |\n",
            "|    policy_loss        | -1.67     |\n",
            "|    reward             | 1.9667337 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 0.0248    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 40500     |\n",
            "|    time_elapsed       | 220       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.55     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 40499     |\n",
            "|    policy_loss        | 27.7      |\n",
            "|    reward             | 10.486711 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 14        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 40600     |\n",
            "|    time_elapsed       | 220       |\n",
            "|    total_timesteps    | 40600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.55     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 40599     |\n",
            "|    policy_loss        | 42.1      |\n",
            "|    reward             | -7.566286 |\n",
            "|    std                | 1.34      |\n",
            "|    value_loss         | 26.8      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 40700       |\n",
            "|    time_elapsed       | 221         |\n",
            "|    total_timesteps    | 40700       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.56       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 40699       |\n",
            "|    policy_loss        | 5.11        |\n",
            "|    reward             | -0.05408698 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 0.281       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 40800       |\n",
            "|    time_elapsed       | 221         |\n",
            "|    total_timesteps    | 40800       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.57       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 40799       |\n",
            "|    policy_loss        | -1.56       |\n",
            "|    reward             | 0.028503442 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 0.0209      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 40900      |\n",
            "|    time_elapsed       | 222        |\n",
            "|    total_timesteps    | 40900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.57      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 40899      |\n",
            "|    policy_loss        | 2.83       |\n",
            "|    reward             | -0.7009672 |\n",
            "|    std                | 1.34       |\n",
            "|    value_loss         | 0.0712     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 41000       |\n",
            "|    time_elapsed       | 223         |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.58       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 40999       |\n",
            "|    policy_loss        | 8.55        |\n",
            "|    reward             | 0.048473388 |\n",
            "|    std                | 1.35        |\n",
            "|    value_loss         | 0.874       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 41100      |\n",
            "|    time_elapsed       | 223        |\n",
            "|    total_timesteps    | 41100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.58      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 41099      |\n",
            "|    policy_loss        | 6.8        |\n",
            "|    reward             | 0.95071596 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 0.34       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 41200     |\n",
            "|    time_elapsed       | 224       |\n",
            "|    total_timesteps    | 41200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.58     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 41199     |\n",
            "|    policy_loss        | -2.01     |\n",
            "|    reward             | -3.219481 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 0.0659    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 41300      |\n",
            "|    time_elapsed       | 224        |\n",
            "|    total_timesteps    | 41300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.59      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 41299      |\n",
            "|    policy_loss        | -21        |\n",
            "|    reward             | -1.3422956 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 11.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 41400      |\n",
            "|    time_elapsed       | 225        |\n",
            "|    total_timesteps    | 41400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.59      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 41399      |\n",
            "|    policy_loss        | -2.55      |\n",
            "|    reward             | -1.7532293 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 0.122      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 41500      |\n",
            "|    time_elapsed       | 226        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.59      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 41499      |\n",
            "|    policy_loss        | 13.7       |\n",
            "|    reward             | 0.38777667 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 3.42       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 41600      |\n",
            "|    time_elapsed       | 226        |\n",
            "|    total_timesteps    | 41600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.59      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 41599      |\n",
            "|    policy_loss        | -20        |\n",
            "|    reward             | -1.1133987 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 8.62       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 41700     |\n",
            "|    time_elapsed       | 227       |\n",
            "|    total_timesteps    | 41700     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.59     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 41699     |\n",
            "|    policy_loss        | -2.26     |\n",
            "|    reward             | -1.748225 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 0.0577    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 41800    |\n",
            "|    time_elapsed       | 228      |\n",
            "|    total_timesteps    | 41800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.6     |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 41799    |\n",
            "|    policy_loss        | -8.87    |\n",
            "|    reward             | 2.053142 |\n",
            "|    std                | 1.35     |\n",
            "|    value_loss         | 1.04     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 41900     |\n",
            "|    time_elapsed       | 228       |\n",
            "|    total_timesteps    | 41900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.6      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 41899     |\n",
            "|    policy_loss        | -11       |\n",
            "|    reward             | 2.5133858 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 1.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 42000     |\n",
            "|    time_elapsed       | 229       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.6      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 41999     |\n",
            "|    policy_loss        | -7.68     |\n",
            "|    reward             | 1.4447569 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 1.37      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 42100     |\n",
            "|    time_elapsed       | 230       |\n",
            "|    total_timesteps    | 42100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.6      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 42099     |\n",
            "|    policy_loss        | -2.54     |\n",
            "|    reward             | 4.8193192 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 0.127     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 42200     |\n",
            "|    time_elapsed       | 230       |\n",
            "|    total_timesteps    | 42200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.6      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 42199     |\n",
            "|    policy_loss        | -5.1      |\n",
            "|    reward             | 3.3704426 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 0.171     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 42300    |\n",
            "|    time_elapsed       | 231      |\n",
            "|    total_timesteps    | 42300    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.61    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 42299    |\n",
            "|    policy_loss        | 1.98     |\n",
            "|    reward             | 0.77972  |\n",
            "|    std                | 1.35     |\n",
            "|    value_loss         | 0.0405   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 42400    |\n",
            "|    time_elapsed       | 231      |\n",
            "|    total_timesteps    | 42400    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.61    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 42399    |\n",
            "|    policy_loss        | 22.3     |\n",
            "|    reward             | -2.59287 |\n",
            "|    std                | 1.35     |\n",
            "|    value_loss         | 6.62     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 42500    |\n",
            "|    time_elapsed       | 232      |\n",
            "|    total_timesteps    | 42500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.61    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 42499    |\n",
            "|    policy_loss        | -9.41    |\n",
            "|    reward             | 2.168397 |\n",
            "|    std                | 1.35     |\n",
            "|    value_loss         | 0.475    |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 42600       |\n",
            "|    time_elapsed       | 232         |\n",
            "|    total_timesteps    | 42600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.61       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 42599       |\n",
            "|    policy_loss        | -4.54       |\n",
            "|    reward             | -0.18433666 |\n",
            "|    std                | 1.35        |\n",
            "|    value_loss         | 0.472       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 42700     |\n",
            "|    time_elapsed       | 233       |\n",
            "|    total_timesteps    | 42700     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.61     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 42699     |\n",
            "|    policy_loss        | 6.75      |\n",
            "|    reward             | 2.8794394 |\n",
            "|    std                | 1.35      |\n",
            "|    value_loss         | 0.907     |\n",
            "-------------------------------------\n",
            "day: 2136, episode: 3640\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3052467.74\n",
            "total_reward: 2052467.74\n",
            "total_cost: 36940.58\n",
            "total_trades: 9975\n",
            "Sharpe: 0.725\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 42800      |\n",
            "|    time_elapsed       | 233        |\n",
            "|    total_timesteps    | 42800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.62      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 42799      |\n",
            "|    policy_loss        | -2.82      |\n",
            "|    reward             | 0.09349735 |\n",
            "|    std                | 1.36       |\n",
            "|    value_loss         | 0.0671     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 42900        |\n",
            "|    time_elapsed       | 234          |\n",
            "|    total_timesteps    | 42900        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.62        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 42899        |\n",
            "|    policy_loss        | 0.781        |\n",
            "|    reward             | -0.035028253 |\n",
            "|    std                | 1.36         |\n",
            "|    value_loss         | 0.00747      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 43000       |\n",
            "|    time_elapsed       | 234         |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.63       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 42999       |\n",
            "|    policy_loss        | 4.74        |\n",
            "|    reward             | -0.19318883 |\n",
            "|    std                | 1.36        |\n",
            "|    value_loss         | 0.325       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 43100       |\n",
            "|    time_elapsed       | 235         |\n",
            "|    total_timesteps    | 43100       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.63       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 43099       |\n",
            "|    policy_loss        | -3.67       |\n",
            "|    reward             | -0.62219846 |\n",
            "|    std                | 1.36        |\n",
            "|    value_loss         | 0.194       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 43200       |\n",
            "|    time_elapsed       | 236         |\n",
            "|    total_timesteps    | 43200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.64       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 43199       |\n",
            "|    policy_loss        | -7.68       |\n",
            "|    reward             | -0.27166748 |\n",
            "|    std                | 1.36        |\n",
            "|    value_loss         | 0.86        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 43300      |\n",
            "|    time_elapsed       | 236        |\n",
            "|    total_timesteps    | 43300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.64      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 43299      |\n",
            "|    policy_loss        | -4.72      |\n",
            "|    reward             | 0.29689878 |\n",
            "|    std                | 1.36       |\n",
            "|    value_loss         | 0.388      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 43400     |\n",
            "|    time_elapsed       | 237       |\n",
            "|    total_timesteps    | 43400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.64     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 43399     |\n",
            "|    policy_loss        | 16        |\n",
            "|    reward             | 0.5799496 |\n",
            "|    std                | 1.36      |\n",
            "|    value_loss         | 2.59      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 43500       |\n",
            "|    time_elapsed       | 237         |\n",
            "|    total_timesteps    | 43500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.64       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 43499       |\n",
            "|    policy_loss        | -10         |\n",
            "|    reward             | -0.99874157 |\n",
            "|    std                | 1.36        |\n",
            "|    value_loss         | 1.35        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 43600      |\n",
            "|    time_elapsed       | 238        |\n",
            "|    total_timesteps    | 43600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.65      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 43599      |\n",
            "|    policy_loss        | -12.5      |\n",
            "|    reward             | 0.30973372 |\n",
            "|    std                | 1.36       |\n",
            "|    value_loss         | 1.71       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 43700      |\n",
            "|    time_elapsed       | 238        |\n",
            "|    total_timesteps    | 43700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.65      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 43699      |\n",
            "|    policy_loss        | 6.35       |\n",
            "|    reward             | -1.5147815 |\n",
            "|    std                | 1.36       |\n",
            "|    value_loss         | 0.873      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 43800        |\n",
            "|    time_elapsed       | 239          |\n",
            "|    total_timesteps    | 43800        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.65        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 43799        |\n",
            "|    policy_loss        | 5.47         |\n",
            "|    reward             | -0.056159075 |\n",
            "|    std                | 1.37         |\n",
            "|    value_loss         | 0.491        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 43900      |\n",
            "|    time_elapsed       | 239        |\n",
            "|    total_timesteps    | 43900      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.65      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 43899      |\n",
            "|    policy_loss        | 6.09       |\n",
            "|    reward             | -0.5896579 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 0.572      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 44000       |\n",
            "|    time_elapsed       | 240         |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.66       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 43999       |\n",
            "|    policy_loss        | -5.25       |\n",
            "|    reward             | -0.53143525 |\n",
            "|    std                | 1.37        |\n",
            "|    value_loss         | 0.551       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 44100      |\n",
            "|    time_elapsed       | 240        |\n",
            "|    total_timesteps    | 44100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.66      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 44099      |\n",
            "|    policy_loss        | 2.47       |\n",
            "|    reward             | -0.6025605 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 0.102      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 44200     |\n",
            "|    time_elapsed       | 241       |\n",
            "|    total_timesteps    | 44200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.66     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 44199     |\n",
            "|    policy_loss        | 3.34      |\n",
            "|    reward             | 1.5104638 |\n",
            "|    std                | 1.37      |\n",
            "|    value_loss         | 0.195     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 44300    |\n",
            "|    time_elapsed       | 242      |\n",
            "|    total_timesteps    | 44300    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.66    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 44299    |\n",
            "|    policy_loss        | 15.5     |\n",
            "|    reward             | 2.204335 |\n",
            "|    std                | 1.37     |\n",
            "|    value_loss         | 3.61     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 44400      |\n",
            "|    time_elapsed       | 242        |\n",
            "|    total_timesteps    | 44400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.66      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 44399      |\n",
            "|    policy_loss        | 40.8       |\n",
            "|    reward             | -2.4653604 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 15.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 44500      |\n",
            "|    time_elapsed       | 243        |\n",
            "|    total_timesteps    | 44500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.66      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 44499      |\n",
            "|    policy_loss        | 21.4       |\n",
            "|    reward             | -1.1289413 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 6.32       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 44600      |\n",
            "|    time_elapsed       | 243        |\n",
            "|    total_timesteps    | 44600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.67      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 44599      |\n",
            "|    policy_loss        | 4.59       |\n",
            "|    reward             | -1.5789231 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 0.317      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 44700     |\n",
            "|    time_elapsed       | 244       |\n",
            "|    total_timesteps    | 44700     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.67     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 44699     |\n",
            "|    policy_loss        | -20.8     |\n",
            "|    reward             | 1.7231891 |\n",
            "|    std                | 1.37      |\n",
            "|    value_loss         | 5.37      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 183        |\n",
            "|    iterations         | 44800      |\n",
            "|    time_elapsed       | 244        |\n",
            "|    total_timesteps    | 44800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.67      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 44799      |\n",
            "|    policy_loss        | -91.5      |\n",
            "|    reward             | -21.780294 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 170        |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 183           |\n",
            "|    iterations         | 44900         |\n",
            "|    time_elapsed       | 245           |\n",
            "|    total_timesteps    | 44900         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -8.67         |\n",
            "|    explained_variance | nan           |\n",
            "|    learning_rate      | 2.64e-05      |\n",
            "|    n_updates          | 44899         |\n",
            "|    policy_loss        | 1.43          |\n",
            "|    reward             | 8.2535356e-05 |\n",
            "|    std                | 1.37          |\n",
            "|    value_loss         | 0.0224        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 183         |\n",
            "|    iterations         | 45000       |\n",
            "|    time_elapsed       | 245         |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.68       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 44999       |\n",
            "|    policy_loss        | -0.74       |\n",
            "|    reward             | 0.018458406 |\n",
            "|    std                | 1.37        |\n",
            "|    value_loss         | 0.00593     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 45100        |\n",
            "|    time_elapsed       | 246          |\n",
            "|    total_timesteps    | 45100        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.69        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 45099        |\n",
            "|    policy_loss        | -0.92        |\n",
            "|    reward             | -0.044325765 |\n",
            "|    std                | 1.38         |\n",
            "|    value_loss         | 0.0149       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 45200       |\n",
            "|    time_elapsed       | 247         |\n",
            "|    total_timesteps    | 45200       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.69       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 45199       |\n",
            "|    policy_loss        | -5.08       |\n",
            "|    reward             | -0.37108716 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 0.553       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 45300     |\n",
            "|    time_elapsed       | 247       |\n",
            "|    total_timesteps    | 45300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.69     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 45299     |\n",
            "|    policy_loss        | 13.6      |\n",
            "|    reward             | 1.4108076 |\n",
            "|    std                | 1.38      |\n",
            "|    value_loss         | 3.67      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 45400      |\n",
            "|    time_elapsed       | 248        |\n",
            "|    total_timesteps    | 45400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.7       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 45399      |\n",
            "|    policy_loss        | 6.63       |\n",
            "|    reward             | -2.2566912 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 0.924      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 45500       |\n",
            "|    time_elapsed       | 248         |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.7        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 45499       |\n",
            "|    policy_loss        | 5.83        |\n",
            "|    reward             | -0.12601675 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 0.673       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 45600      |\n",
            "|    time_elapsed       | 249        |\n",
            "|    total_timesteps    | 45600      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.7       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 45599      |\n",
            "|    policy_loss        | 1.54       |\n",
            "|    reward             | 0.24440713 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 0.0301     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 45700      |\n",
            "|    time_elapsed       | 249        |\n",
            "|    total_timesteps    | 45700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.7       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 45699      |\n",
            "|    policy_loss        | -9.47      |\n",
            "|    reward             | 0.66128427 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 0.997      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 45800      |\n",
            "|    time_elapsed       | 250        |\n",
            "|    total_timesteps    | 45800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.7       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 45799      |\n",
            "|    policy_loss        | 16.6       |\n",
            "|    reward             | -1.3855577 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 4.63       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 45900    |\n",
            "|    time_elapsed       | 251      |\n",
            "|    total_timesteps    | 45900    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.71    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 45899    |\n",
            "|    policy_loss        | -10.8    |\n",
            "|    reward             | 3.275738 |\n",
            "|    std                | 1.38     |\n",
            "|    value_loss         | 2.82     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 46000     |\n",
            "|    time_elapsed       | 251       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.71     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 45999     |\n",
            "|    policy_loss        | 2.09      |\n",
            "|    reward             | 0.9448686 |\n",
            "|    std                | 1.38      |\n",
            "|    value_loss         | 0.068     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 46100    |\n",
            "|    time_elapsed       | 252      |\n",
            "|    total_timesteps    | 46100    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.71    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 46099    |\n",
            "|    policy_loss        | 54.5     |\n",
            "|    reward             | 0.846909 |\n",
            "|    std                | 1.38     |\n",
            "|    value_loss         | 33.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 46200     |\n",
            "|    time_elapsed       | 252       |\n",
            "|    total_timesteps    | 46200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.71     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 46199     |\n",
            "|    policy_loss        | -3.15     |\n",
            "|    reward             | 1.5982995 |\n",
            "|    std                | 1.38      |\n",
            "|    value_loss         | 0.209     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 46300    |\n",
            "|    time_elapsed       | 253      |\n",
            "|    total_timesteps    | 46300    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.72    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 46299    |\n",
            "|    policy_loss        | 0.752    |\n",
            "|    reward             | 1.13805  |\n",
            "|    std                | 1.38     |\n",
            "|    value_loss         | 0.00681  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 46400      |\n",
            "|    time_elapsed       | 253        |\n",
            "|    total_timesteps    | 46400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.72      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 46399      |\n",
            "|    policy_loss        | 17         |\n",
            "|    reward             | -1.3254356 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 2.02       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 46500      |\n",
            "|    time_elapsed       | 254        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.72      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 46499      |\n",
            "|    policy_loss        | -13.5      |\n",
            "|    reward             | -4.1412134 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 2.25       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 46600     |\n",
            "|    time_elapsed       | 254       |\n",
            "|    total_timesteps    | 46600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.72     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 46599     |\n",
            "|    policy_loss        | 9.08      |\n",
            "|    reward             | 3.2233179 |\n",
            "|    std                | 1.38      |\n",
            "|    value_loss         | 1.65      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 46700       |\n",
            "|    time_elapsed       | 255         |\n",
            "|    total_timesteps    | 46700       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.72       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 46699       |\n",
            "|    policy_loss        | -2.1        |\n",
            "|    reward             | -0.47501913 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 0.0323      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 46800     |\n",
            "|    time_elapsed       | 255       |\n",
            "|    total_timesteps    | 46800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.72     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 46799     |\n",
            "|    policy_loss        | -113      |\n",
            "|    reward             | 1.8929613 |\n",
            "|    std                | 1.38      |\n",
            "|    value_loss         | 55.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 46900     |\n",
            "|    time_elapsed       | 256       |\n",
            "|    total_timesteps    | 46900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.72     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 46899     |\n",
            "|    policy_loss        | 31        |\n",
            "|    reward             | 1.7332617 |\n",
            "|    std                | 1.38      |\n",
            "|    value_loss         | 18.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 47000      |\n",
            "|    time_elapsed       | 257        |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.72      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 46999      |\n",
            "|    policy_loss        | 32.5       |\n",
            "|    reward             | -19.571192 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 17.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 47100      |\n",
            "|    time_elapsed       | 257        |\n",
            "|    total_timesteps    | 47100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.73      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 47099      |\n",
            "|    policy_loss        | -3.82      |\n",
            "|    reward             | -0.2502447 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 0.305      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 47200        |\n",
            "|    time_elapsed       | 258          |\n",
            "|    total_timesteps    | 47200        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.74        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 47199        |\n",
            "|    policy_loss        | -0.501       |\n",
            "|    reward             | 0.0048047863 |\n",
            "|    std                | 1.39         |\n",
            "|    value_loss         | 0.00323      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 47300      |\n",
            "|    time_elapsed       | 258        |\n",
            "|    total_timesteps    | 47300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.74      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 47299      |\n",
            "|    policy_loss        | 0.856      |\n",
            "|    reward             | -1.1777442 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 0.00614    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 47400      |\n",
            "|    time_elapsed       | 259        |\n",
            "|    total_timesteps    | 47400      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.75      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 47399      |\n",
            "|    policy_loss        | -15.8      |\n",
            "|    reward             | -0.3677385 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 1.49       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 47500     |\n",
            "|    time_elapsed       | 259       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.75     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 47499     |\n",
            "|    policy_loss        | 7.89      |\n",
            "|    reward             | 0.6753676 |\n",
            "|    std                | 1.39      |\n",
            "|    value_loss         | 1.07      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 47600       |\n",
            "|    time_elapsed       | 260         |\n",
            "|    total_timesteps    | 47600       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.75       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 47599       |\n",
            "|    policy_loss        | -3.95       |\n",
            "|    reward             | -0.54869264 |\n",
            "|    std                | 1.39        |\n",
            "|    value_loss         | 0.291       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 47700     |\n",
            "|    time_elapsed       | 261       |\n",
            "|    total_timesteps    | 47700     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.75     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 47699     |\n",
            "|    policy_loss        | 10.3      |\n",
            "|    reward             | -2.241263 |\n",
            "|    std                | 1.39      |\n",
            "|    value_loss         | 1.77      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 47800      |\n",
            "|    time_elapsed       | 261        |\n",
            "|    total_timesteps    | 47800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.76      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 47799      |\n",
            "|    policy_loss        | -6.94      |\n",
            "|    reward             | -1.3840451 |\n",
            "|    std                | 1.39       |\n",
            "|    value_loss         | 0.536      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 47900     |\n",
            "|    time_elapsed       | 262       |\n",
            "|    total_timesteps    | 47900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.76     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 47899     |\n",
            "|    policy_loss        | 12.9      |\n",
            "|    reward             | 0.8084713 |\n",
            "|    std                | 1.39      |\n",
            "|    value_loss         | 3.88      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 48000      |\n",
            "|    time_elapsed       | 263        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.76      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 47999      |\n",
            "|    policy_loss        | -5.65      |\n",
            "|    reward             | -1.9311326 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 0.467      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 48100      |\n",
            "|    time_elapsed       | 263        |\n",
            "|    total_timesteps    | 48100      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.76      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 48099      |\n",
            "|    policy_loss        | 1.6        |\n",
            "|    reward             | -1.5598317 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 0.0518     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 48200      |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 48200      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.77      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 48199      |\n",
            "|    policy_loss        | -3.06      |\n",
            "|    reward             | -0.2511226 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 0.126      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 48300     |\n",
            "|    time_elapsed       | 264       |\n",
            "|    total_timesteps    | 48300     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.77     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 48299     |\n",
            "|    policy_loss        | 13.4      |\n",
            "|    reward             | 2.4431763 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 3.74      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 48400     |\n",
            "|    time_elapsed       | 265       |\n",
            "|    total_timesteps    | 48400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.77     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 48399     |\n",
            "|    policy_loss        | -13.6     |\n",
            "|    reward             | 1.0908539 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 2.47      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 48500    |\n",
            "|    time_elapsed       | 265      |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.77    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 48499    |\n",
            "|    policy_loss        | -2.51    |\n",
            "|    reward             | 2.196391 |\n",
            "|    std                | 1.4      |\n",
            "|    value_loss         | 0.118    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 48600    |\n",
            "|    time_elapsed       | 266      |\n",
            "|    total_timesteps    | 48600    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.77    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 2.64e-05 |\n",
            "|    n_updates          | 48599    |\n",
            "|    policy_loss        | 5.14     |\n",
            "|    reward             | -9.95441 |\n",
            "|    std                | 1.4      |\n",
            "|    value_loss         | 0.504    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 48700      |\n",
            "|    time_elapsed       | 266        |\n",
            "|    total_timesteps    | 48700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.77      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 48699      |\n",
            "|    policy_loss        | 20.1       |\n",
            "|    reward             | -0.3757567 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 4.6        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 48800      |\n",
            "|    time_elapsed       | 267        |\n",
            "|    total_timesteps    | 48800      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.77      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 48799      |\n",
            "|    policy_loss        | -20.6      |\n",
            "|    reward             | 0.11671428 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 6.51       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 48900     |\n",
            "|    time_elapsed       | 267       |\n",
            "|    total_timesteps    | 48900     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.77     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 48899     |\n",
            "|    policy_loss        | -2.61     |\n",
            "|    reward             | 0.6331358 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 0.0455    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 49000     |\n",
            "|    time_elapsed       | 268       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.78     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 48999     |\n",
            "|    policy_loss        | 9.83      |\n",
            "|    reward             | 0.6507437 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 2.24      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 49100     |\n",
            "|    time_elapsed       | 268       |\n",
            "|    total_timesteps    | 49100     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.78     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 49099     |\n",
            "|    policy_loss        | 44.5      |\n",
            "|    reward             | -4.588564 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 22.2      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 182          |\n",
            "|    iterations         | 49200        |\n",
            "|    time_elapsed       | 269          |\n",
            "|    total_timesteps    | 49200        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -8.78        |\n",
            "|    explained_variance | nan          |\n",
            "|    learning_rate      | 2.64e-05     |\n",
            "|    n_updates          | 49199        |\n",
            "|    policy_loss        | 2.54         |\n",
            "|    reward             | -0.013204686 |\n",
            "|    std                | 1.4          |\n",
            "|    value_loss         | 0.0911       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 49300      |\n",
            "|    time_elapsed       | 269        |\n",
            "|    total_timesteps    | 49300      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.79      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 49299      |\n",
            "|    policy_loss        | 5.6        |\n",
            "|    reward             | 0.40330005 |\n",
            "|    std                | 1.4        |\n",
            "|    value_loss         | 0.473      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 49400     |\n",
            "|    time_elapsed       | 270       |\n",
            "|    total_timesteps    | 49400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.79     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 49399     |\n",
            "|    policy_loss        | -5.59     |\n",
            "|    reward             | 1.4372746 |\n",
            "|    std                | 1.4       |\n",
            "|    value_loss         | 0.459     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 49500       |\n",
            "|    time_elapsed       | 271         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.8        |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 49499       |\n",
            "|    policy_loss        | -6.06       |\n",
            "|    reward             | -0.39606988 |\n",
            "|    std                | 1.41        |\n",
            "|    value_loss         | 0.688       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 49600     |\n",
            "|    time_elapsed       | 271       |\n",
            "|    total_timesteps    | 49600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.8      |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 49599     |\n",
            "|    policy_loss        | -3.32     |\n",
            "|    reward             | 0.6323634 |\n",
            "|    std                | 1.41      |\n",
            "|    value_loss         | 0.135     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 49700      |\n",
            "|    time_elapsed       | 272        |\n",
            "|    total_timesteps    | 49700      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.8       |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 49699      |\n",
            "|    policy_loss        | 0.302      |\n",
            "|    reward             | 0.19019744 |\n",
            "|    std                | 1.41       |\n",
            "|    value_loss         | 0.00157    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 49800     |\n",
            "|    time_elapsed       | 272       |\n",
            "|    total_timesteps    | 49800     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.81     |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 2.64e-05  |\n",
            "|    n_updates          | 49799     |\n",
            "|    policy_loss        | -1.9      |\n",
            "|    reward             | 1.4318684 |\n",
            "|    std                | 1.41      |\n",
            "|    value_loss         | 0.0595    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 49900       |\n",
            "|    time_elapsed       | 273         |\n",
            "|    total_timesteps    | 49900       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -8.81       |\n",
            "|    explained_variance | nan         |\n",
            "|    learning_rate      | 2.64e-05    |\n",
            "|    n_updates          | 49899       |\n",
            "|    policy_loss        | 8.33        |\n",
            "|    reward             | -0.06737827 |\n",
            "|    std                | 1.41        |\n",
            "|    value_loss         | 0.783       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 50000      |\n",
            "|    time_elapsed       | 274        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -8.81      |\n",
            "|    explained_variance | nan        |\n",
            "|    learning_rate      | 2.64e-05   |\n",
            "|    n_updates          | 49999      |\n",
            "|    policy_loss        | -7.66      |\n",
            "|    reward             | 0.63720113 |\n",
            "|    std                | 1.41       |\n",
            "|    value_loss         | 1.11       |\n",
            "--------------------------------------\n"
          ]
        }
      ],
      "source": [
        "a2c_params = {\n",
        "    \"n_steps\": 5,\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 7e-4,\n",
        "    \"gamma\": 0.99,\n",
        "    \"gae_lambda\": 0.95\n",
        "}\n",
        "a2c_tuned_params = {\n",
        "    \"n_steps\": 1,\n",
        "    \"ent_coef\": 0.0755882482216129,\n",
        "    \"learning_rate\": 2.637065887731285e-05,\n",
        "    \"gamma\": 0.9048260592925886,\n",
        "    \"gae_lambda\": 0.9717236074963396\n",
        "}\n",
        "\n",
        "agent = DRLAgent(training_environment)\n",
        "a2c_model = agent.get_model(\"a2c\", model_kwargs=a2c_tuned_params)\n",
        "tmp_path = RESULTS_DIR + '/a2c'\n",
        "new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "a2c_model.set_logger(new_logger_a2c)\n",
        "trained_a2c = DRLAgent(training_environment).train_model(model=a2c_model,\n",
        "                             tb_log_name='a2c',\n",
        "                             total_timesteps=50000) \n",
        "\n",
        "\n",
        "# A2C HYPERPARAMS MOST IMPORTANT\n",
        "# learning_rate: The learning rate determines how quickly the model learns from new experiences. This is one of the most important to get right. Too small and it will learn slowly. Too large and it may have issues converging.\n",
        "# n_steps: The number of steps collected before each update. More steps allows more efficient batch updates but delays learning from recent experiences. Finding a good balance is important.\n",
        "# gamma: The discount factor determines how much the agent values future rewards. Higher values make it value long-term rewards more.\n",
        "# gae_lambda: The GAE lambda controls the bias-variance tradeoff for estimating returns. Values closer to 1 have lower variance but higher bias.\n",
        "# ent_coef: The entropy coefficient controls how much the agent is encouraged to explore randomly. Higher values result in more random actions.\n",
        "# max_grad_norm: Gradient clipping limit to improve stability. You generally don't need to tune this much.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 232, 'ent_coef': 0.08005421293955037, 'learning_rate': 0.0002058992300570136, 'batch_size': 238}\n",
            "Using cpu device\n",
            "Logging to results/ppo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning:\n",
            "\n",
            "You have specified a mini-batch size of 238, but because the `RolloutBuffer` is of size `n_steps * n_envs = 232`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 232\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=232 and n_envs=1)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 495          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 0            |\n",
            "|    total_timesteps | 232          |\n",
            "| train/             |              |\n",
            "|    reward          | -0.035142787 |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 484          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 0            |\n",
            "|    total_timesteps      | 464          |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062470096 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.1         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | -0.566       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00406     |\n",
            "|    reward               | 0.027647948  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0179       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 487         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 696         |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006016956 |\n",
            "|    clip_fraction        | 0.0138      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.11       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.563      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00441    |\n",
            "|    reward               | -0.696803   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.0345      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 485          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 1            |\n",
            "|    total_timesteps      | 928          |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037174737 |\n",
            "|    clip_fraction        | 0.00172      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.12        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | -0.395       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    reward               | 0.37487835   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.361        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 488          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 1160         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023541087 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.13        |\n",
            "|    explained_variance   | 0.0126       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.699        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | -0.3070335   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 2.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 490          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 1392         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005727307 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.13        |\n",
            "|    explained_variance   | 0.0396       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 4.58         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | 0.000992     |\n",
            "|    reward               | 0.118275054  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 490           |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 3             |\n",
            "|    total_timesteps      | 1624          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.8567988e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.13         |\n",
            "|    explained_variance   | -0.0289       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 3.85          |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.000544     |\n",
            "|    reward               | -1.1084675    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 9.25          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 492           |\n",
            "|    iterations           | 8             |\n",
            "|    time_elapsed         | 3             |\n",
            "|    total_timesteps      | 1856          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.3700297e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.13         |\n",
            "|    explained_variance   | -0.0143       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 20.2          |\n",
            "|    n_updates            | 70            |\n",
            "|    policy_gradient_loss | -0.000253     |\n",
            "|    reward               | 2.885563      |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 42.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 484           |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 4             |\n",
            "|    total_timesteps      | 2088          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.2252829e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.13         |\n",
            "|    explained_variance   | -0.00611      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 27            |\n",
            "|    n_updates            | 80            |\n",
            "|    policy_gradient_loss | -0.000765     |\n",
            "|    reward               | 2.1982017     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 55.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 10            |\n",
            "|    time_elapsed         | 4             |\n",
            "|    total_timesteps      | 2320          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.8020128e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.13         |\n",
            "|    explained_variance   | 0.0194        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 57.1          |\n",
            "|    n_updates            | 90            |\n",
            "|    policy_gradient_loss | -0.000669     |\n",
            "|    reward               | -0.27996475   |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 116           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 11            |\n",
            "|    time_elapsed         | 5             |\n",
            "|    total_timesteps      | 2552          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011143088 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.13         |\n",
            "|    explained_variance   | 0.131         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.82          |\n",
            "|    n_updates            | 100           |\n",
            "|    policy_gradient_loss | -0.00188      |\n",
            "|    reward               | -0.1335244    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 19.1          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 2784         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034019419 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.13        |\n",
            "|    explained_variance   | -0.0273      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.154        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0023      |\n",
            "|    reward               | -2.8142369   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.47         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 465         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 3016        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005191958 |\n",
            "|    clip_fraction        | 0.0103      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.14       |\n",
            "|    explained_variance   | -0.134      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 2.69        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00369    |\n",
            "|    reward               | 0.4178074   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.86        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 466           |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 6             |\n",
            "|    total_timesteps      | 3248          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00041238888 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | 0.0457        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 7.38          |\n",
            "|    n_updates            | 130           |\n",
            "|    policy_gradient_loss | -0.00179      |\n",
            "|    reward               | 1.5190002     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 16            |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 467           |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 7             |\n",
            "|    total_timesteps      | 3480          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00017200668 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | 0.00303       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 7.88          |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.000155     |\n",
            "|    reward               | 0.33720678    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 17            |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 470           |\n",
            "|    iterations           | 16            |\n",
            "|    time_elapsed         | 7             |\n",
            "|    total_timesteps      | 3712          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00018443527 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | 0.0227        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.11          |\n",
            "|    n_updates            | 150           |\n",
            "|    policy_gradient_loss | -0.00226      |\n",
            "|    reward               | 0.16462776    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 13.8          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 472           |\n",
            "|    iterations           | 17            |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 3944          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00017573145 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | -0.0637       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 32.6          |\n",
            "|    n_updates            | 160           |\n",
            "|    policy_gradient_loss | 9.39e-05      |\n",
            "|    reward               | -0.7809422    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 67.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 18            |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 4176          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 9.5098956e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | -0.0202       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 38.5          |\n",
            "|    n_updates            | 170           |\n",
            "|    policy_gradient_loss | -0.00123      |\n",
            "|    reward               | 2.2173345     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 78.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 19            |\n",
            "|    time_elapsed         | 9             |\n",
            "|    total_timesteps      | 4408          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020778898 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | -0.0142       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 33.5          |\n",
            "|    n_updates            | 180           |\n",
            "|    policy_gradient_loss | -0.00149      |\n",
            "|    reward               | -0.17867795   |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 68.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 9             |\n",
            "|    total_timesteps      | 4640          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011191312 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.14         |\n",
            "|    explained_variance   | 0.00976       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 41.7          |\n",
            "|    n_updates            | 190           |\n",
            "|    policy_gradient_loss | -0.00068      |\n",
            "|    reward               | -0.27316114   |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 84.6          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 478         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 4872        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011008939 |\n",
            "|    clip_fraction        | 0.0315      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.15       |\n",
            "|    explained_variance   | 0.00274     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.337       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00952    |\n",
            "|    reward               | 1.455944    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 1.87        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 479          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 5104         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00528813   |\n",
            "|    clip_fraction        | 0.0172       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.15        |\n",
            "|    explained_variance   | 0.139        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 2.25         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00843     |\n",
            "|    reward               | -0.054209854 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 5.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 478          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 5336         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012266934 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.16        |\n",
            "|    explained_variance   | -0.0444      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 8.38         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    reward               | 1.8738205    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 18           |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 478           |\n",
            "|    iterations           | 24            |\n",
            "|    time_elapsed         | 11            |\n",
            "|    total_timesteps      | 5568          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00019316992 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.16         |\n",
            "|    explained_variance   | -0.0191       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.78          |\n",
            "|    n_updates            | 230           |\n",
            "|    policy_gradient_loss | -0.000664     |\n",
            "|    reward               | -0.07455114   |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 19            |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 478          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 5800         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.736661e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.16        |\n",
            "|    explained_variance   | 0.00179      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 6.72         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.000972    |\n",
            "|    reward               | -2.8608906   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 14.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 478          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 6032         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.308987e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.16        |\n",
            "|    explained_variance   | -0.00757     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 30.1         |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00076     |\n",
            "|    reward               | -1.3728404   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 63.3         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 480           |\n",
            "|    iterations           | 27            |\n",
            "|    time_elapsed         | 13            |\n",
            "|    total_timesteps      | 6264          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014573155 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.16         |\n",
            "|    explained_variance   | -0.00287      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 42.3          |\n",
            "|    n_updates            | 260           |\n",
            "|    policy_gradient_loss | -0.00115      |\n",
            "|    reward               | -1.219135     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 85.7          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 480          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 6496         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.765326e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.16        |\n",
            "|    explained_variance   | -0.00964     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 30.7         |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    reward               | -0.20500857  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 63           |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 481           |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 13            |\n",
            "|    total_timesteps      | 6728          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.8720594e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.16         |\n",
            "|    explained_variance   | -0.00368      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 53.3          |\n",
            "|    n_updates            | 280           |\n",
            "|    policy_gradient_loss | -0.000777     |\n",
            "|    reward               | 0.35976344    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 108           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 481         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 6960        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004860422 |\n",
            "|    clip_fraction        | 0.00603     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.16       |\n",
            "|    explained_variance   | -0.00137    |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.126      |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00576    |\n",
            "|    reward               | -0.01259674 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.971       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 481         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 7192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00647341  |\n",
            "|    clip_fraction        | 0.0177      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.16       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.647       |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00686    |\n",
            "|    reward               | -0.34536391 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 2.61        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 482         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 7424        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001954784 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.17       |\n",
            "|    explained_variance   | -0.044      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 8.11        |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | 0.000942    |\n",
            "|    reward               | -1.0743185  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 17.4        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 482           |\n",
            "|    iterations           | 33            |\n",
            "|    time_elapsed         | 15            |\n",
            "|    total_timesteps      | 7656          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015818354 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.17         |\n",
            "|    explained_variance   | 0.0209        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.75          |\n",
            "|    n_updates            | 320           |\n",
            "|    policy_gradient_loss | -0.001        |\n",
            "|    reward               | 1.2219543     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 15.1          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 482           |\n",
            "|    iterations           | 34            |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 7888          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015128661 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.17         |\n",
            "|    explained_variance   | -0.0249       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 9.02          |\n",
            "|    n_updates            | 330           |\n",
            "|    policy_gradient_loss | -0.00105      |\n",
            "|    reward               | 1.1246511     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 19.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 482           |\n",
            "|    iterations           | 35            |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 8120          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011076881 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.17         |\n",
            "|    explained_variance   | -0.0335       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 12.3          |\n",
            "|    n_updates            | 340           |\n",
            "|    policy_gradient_loss | -0.000769     |\n",
            "|    reward               | -3.0592632    |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 26.7          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 482          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 8352         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.746376e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.17        |\n",
            "|    explained_variance   | -0.00526     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 36.2         |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000865    |\n",
            "|    reward               | -2.7119794   |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 73.6         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 481           |\n",
            "|    iterations           | 37            |\n",
            "|    time_elapsed         | 17            |\n",
            "|    total_timesteps      | 8584          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.0652095e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.17         |\n",
            "|    explained_variance   | -0.0105       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 29.2          |\n",
            "|    n_updates            | 360           |\n",
            "|    policy_gradient_loss | -0.000629     |\n",
            "|    reward               | 0.004585109   |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 59.7          |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 481            |\n",
            "|    iterations           | 38             |\n",
            "|    time_elapsed         | 18             |\n",
            "|    total_timesteps      | 8816           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000121152094 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -7.17          |\n",
            "|    explained_variance   | -0.0147        |\n",
            "|    learning_rate        | 0.000206       |\n",
            "|    loss                 | 65.7           |\n",
            "|    n_updates            | 370            |\n",
            "|    policy_gradient_loss | -0.00156       |\n",
            "|    reward               | 0.36822623     |\n",
            "|    std                  | 1.02           |\n",
            "|    value_loss           | 133            |\n",
            "--------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 481         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 9048        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006561259 |\n",
            "|    clip_fraction        | 0.0108      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.17       |\n",
            "|    explained_variance   | 0.0728      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.432      |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00488    |\n",
            "|    reward               | -0.08957392 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.33        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 480         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 9280        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024730863 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.18       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.107       |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.00834    |\n",
            "|    reward               | -1.9822276  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 1.41        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 480          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 9512         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022403898 |\n",
            "|    clip_fraction        | 0.000431     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.18        |\n",
            "|    explained_variance   | 0.0822       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 2.49         |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00347     |\n",
            "|    reward               | 1.5729927    |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 6.41         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 479           |\n",
            "|    iterations           | 42            |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 9744          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00049461884 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.19         |\n",
            "|    explained_variance   | -0.0165       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.39          |\n",
            "|    n_updates            | 410           |\n",
            "|    policy_gradient_loss | -0.00107      |\n",
            "|    reward               | -0.5503522    |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 14            |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 478           |\n",
            "|    iterations           | 43            |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 9976          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020147064 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.19         |\n",
            "|    explained_variance   | -0.0584       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.73          |\n",
            "|    n_updates            | 420           |\n",
            "|    policy_gradient_loss | 0.000125      |\n",
            "|    reward               | -1.2557836    |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 18.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 44            |\n",
            "|    time_elapsed         | 21            |\n",
            "|    total_timesteps      | 10208         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.5065957e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.19         |\n",
            "|    explained_variance   | 0.0182        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.58          |\n",
            "|    n_updates            | 430           |\n",
            "|    policy_gradient_loss | -0.000304     |\n",
            "|    reward               | -2.5591676    |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 15.2          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 10440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.20887e-05 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.19       |\n",
            "|    explained_variance   | -0.0208     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 28.2        |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.000965   |\n",
            "|    reward               | 4.512819    |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 58.1        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 46            |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 10672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021088586 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.19         |\n",
            "|    explained_variance   | 0.002         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 40.7          |\n",
            "|    n_updates            | 450           |\n",
            "|    policy_gradient_loss | -0.002        |\n",
            "|    reward               | 2.847092      |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 82.6          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 47            |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 10904         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.9111622e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.2          |\n",
            "|    explained_variance   | -0.00309      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 93.3          |\n",
            "|    n_updates            | 460           |\n",
            "|    policy_gradient_loss | -0.000517     |\n",
            "|    reward               | -0.08064893   |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 188           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 48            |\n",
            "|    time_elapsed         | 23            |\n",
            "|    total_timesteps      | 11136         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00086924614 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.2          |\n",
            "|    explained_variance   | 0.126         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 0.45          |\n",
            "|    n_updates            | 470           |\n",
            "|    policy_gradient_loss | -0.00273      |\n",
            "|    reward               | 0.6365502     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 2.27          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 11368        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015625982 |\n",
            "|    clip_fraction        | 0.000431     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.2         |\n",
            "|    explained_variance   | 0.103        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | -0.0381      |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00134     |\n",
            "|    reward               | -0.92984843  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 1.1          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 11600       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009182604 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.2        |\n",
            "|    explained_variance   | -0.00246    |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.409       |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.0113     |\n",
            "|    reward               | -3.2910326  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 2.38        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 11832        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011135599 |\n",
            "|    clip_fraction        | 0.000431     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.2         |\n",
            "|    explained_variance   | -0.0683      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 6.98         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    reward               | 2.2061648    |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 15.2         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 52            |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 12064         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00042602958 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.21         |\n",
            "|    explained_variance   | 0.0104        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.2           |\n",
            "|    n_updates            | 510           |\n",
            "|    policy_gradient_loss | -0.00264      |\n",
            "|    reward               | -1.3827207    |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 17.6          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 53            |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 12296         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00059294084 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.21         |\n",
            "|    explained_variance   | 0.069         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 4.11          |\n",
            "|    n_updates            | 520           |\n",
            "|    policy_gradient_loss | -0.00104      |\n",
            "|    reward               | 1.1612527     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 9.9           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 12528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002372532 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.21        |\n",
            "|    explained_variance   | 0.0245       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 22.3         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    reward               | -3.3521948   |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 47.2         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 55            |\n",
            "|    time_elapsed         | 26            |\n",
            "|    total_timesteps      | 12760         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00017524998 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.21         |\n",
            "|    explained_variance   | 0.0181        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 40.9          |\n",
            "|    n_updates            | 540           |\n",
            "|    policy_gradient_loss | -0.00222      |\n",
            "|    reward               | 7.4027534     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 83.1          |\n",
            "-------------------------------------------\n",
            "day: 2136, episode: 3650\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2817902.21\n",
            "total_reward: 1817902.21\n",
            "total_cost: 28588.52\n",
            "total_trades: 9929\n",
            "Sharpe: 0.704\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 12992        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.374236e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.21        |\n",
            "|    explained_variance   | 0.00543      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 92.3         |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.000422    |\n",
            "|    reward               | -0.07591486  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 186          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 57            |\n",
            "|    time_elapsed         | 27            |\n",
            "|    total_timesteps      | 13224         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.0157087e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.21         |\n",
            "|    explained_variance   | 0.123         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 22.1          |\n",
            "|    n_updates            | 560           |\n",
            "|    policy_gradient_loss | -0.000834     |\n",
            "|    reward               | -0.11920102   |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 45.9          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 58            |\n",
            "|    time_elapsed         | 28            |\n",
            "|    total_timesteps      | 13456         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00043965824 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.21         |\n",
            "|    explained_variance   | 0.133         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | -0.208        |\n",
            "|    n_updates            | 570           |\n",
            "|    policy_gradient_loss | -0.00145      |\n",
            "|    reward               | 0.35125062    |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.824         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 59            |\n",
            "|    time_elapsed         | 28            |\n",
            "|    total_timesteps      | 13688         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00057425944 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.21         |\n",
            "|    explained_variance   | 0.0575        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 0.474         |\n",
            "|    n_updates            | 580           |\n",
            "|    policy_gradient_loss | -2.68e-05     |\n",
            "|    reward               | -0.6353671    |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 2.21          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 13920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025566441 |\n",
            "|    clip_fraction        | 0.00129      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.21        |\n",
            "|    explained_variance   | 0.0845       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 4.12         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00465     |\n",
            "|    reward               | 1.7784492    |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 9.5          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 14152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005484103 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.22        |\n",
            "|    explained_variance   | 0.00781      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 10.5         |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.000796    |\n",
            "|    reward               | 0.06056799   |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 22.5         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 62            |\n",
            "|    time_elapsed         | 30            |\n",
            "|    total_timesteps      | 14384         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00033583594 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.22         |\n",
            "|    explained_variance   | -0.0529       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 4.41          |\n",
            "|    n_updates            | 610           |\n",
            "|    policy_gradient_loss | -0.00172      |\n",
            "|    reward               | 1.7804843     |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 10.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 63            |\n",
            "|    time_elapsed         | 30            |\n",
            "|    total_timesteps      | 14616         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015306345 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.22         |\n",
            "|    explained_variance   | -0.0227       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 21.7          |\n",
            "|    n_updates            | 620           |\n",
            "|    policy_gradient_loss | -0.000712     |\n",
            "|    reward               | -1.6817334    |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 45.6          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 14848        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002094831 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.22        |\n",
            "|    explained_variance   | -0.0164      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 39.8         |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00196     |\n",
            "|    reward               | 0.56408536   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 80.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 15080        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001740805 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.22        |\n",
            "|    explained_variance   | -0.0115      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 38.8         |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | -0.014508791 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 79           |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 66            |\n",
            "|    time_elapsed         | 32            |\n",
            "|    total_timesteps      | 15312         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021510752 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.22         |\n",
            "|    explained_variance   | 0.0443        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 65.9          |\n",
            "|    n_updates            | 650           |\n",
            "|    policy_gradient_loss | -0.00273      |\n",
            "|    reward               | -0.530695     |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 133           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 15544        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.012131446  |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.22        |\n",
            "|    explained_variance   | -0.00638     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.776        |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00575     |\n",
            "|    reward               | -0.057723023 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 2.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 15776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011398618 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.23        |\n",
            "|    explained_variance   | 0.53         |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 1.61         |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    reward               | 1.619383     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 4.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 16008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000218859 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.23       |\n",
            "|    explained_variance   | 0.0428      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 6.26        |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.000743   |\n",
            "|    reward               | 1.6868715   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 70            |\n",
            "|    time_elapsed         | 34            |\n",
            "|    total_timesteps      | 16240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014018525 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.24         |\n",
            "|    explained_variance   | -0.0249       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 10.1          |\n",
            "|    n_updates            | 690           |\n",
            "|    policy_gradient_loss | -0.00143      |\n",
            "|    reward               | -0.25464934   |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 21.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 71            |\n",
            "|    time_elapsed         | 34            |\n",
            "|    total_timesteps      | 16472         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020925213 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.24         |\n",
            "|    explained_variance   | 0.00199       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 5.61          |\n",
            "|    n_updates            | 700           |\n",
            "|    policy_gradient_loss | -0.00126      |\n",
            "|    reward               | 4.748399      |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 12.5          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 16704        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.174219e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.24        |\n",
            "|    explained_variance   | -0.0597      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 26           |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -2.78e-05    |\n",
            "|    reward               | 0.40817374   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 55.1         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 476            |\n",
            "|    iterations           | 73             |\n",
            "|    time_elapsed         | 35             |\n",
            "|    total_timesteps      | 16936          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000121508434 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -7.24          |\n",
            "|    explained_variance   | -0.0155        |\n",
            "|    learning_rate        | 0.000206       |\n",
            "|    loss                 | 45.7           |\n",
            "|    n_updates            | 720            |\n",
            "|    policy_gradient_loss | -0.00138       |\n",
            "|    reward               | -0.5925591     |\n",
            "|    std                  | 1.03           |\n",
            "|    value_loss           | 92.5           |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 74            |\n",
            "|    time_elapsed         | 36            |\n",
            "|    total_timesteps      | 17168         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00023743536 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.24         |\n",
            "|    explained_variance   | 0.00341       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 43.2          |\n",
            "|    n_updates            | 730           |\n",
            "|    policy_gradient_loss | -0.002        |\n",
            "|    reward               | 0.39274484    |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 87.8          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 75            |\n",
            "|    time_elapsed         | 36            |\n",
            "|    total_timesteps      | 17400         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013054548 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.24         |\n",
            "|    explained_variance   | -0.00563      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 69.2          |\n",
            "|    n_updates            | 740           |\n",
            "|    policy_gradient_loss | -0.00122      |\n",
            "|    reward               | -0.32401973   |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 140           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 17632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011327429 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.24        |\n",
            "|    explained_variance   | -0.054       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.637        |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    reward               | 0.18121912   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 2.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 17864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032658577 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.24        |\n",
            "|    explained_variance   | 0.197        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.991        |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.00454     |\n",
            "|    reward               | -1.0819732   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 3.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 18096        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018716259 |\n",
            "|    clip_fraction        | 0.00172      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.24        |\n",
            "|    explained_variance   | 0.0607       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 5.7          |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00709     |\n",
            "|    reward               | 1.937564     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 12.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 18328        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028948577 |\n",
            "|    clip_fraction        | 0.00603      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.25        |\n",
            "|    explained_variance   | -0.0236      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 5.63         |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    reward               | 2.212855     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 12.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 18560       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000361506 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.25       |\n",
            "|    explained_variance   | 0.0221      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 8.23        |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | 0.000102    |\n",
            "|    reward               | 0.0747421   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 17.7        |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 475            |\n",
            "|    iterations           | 81             |\n",
            "|    time_elapsed         | 39             |\n",
            "|    total_timesteps      | 18792          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000100850804 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -7.25          |\n",
            "|    explained_variance   | -0.00998       |\n",
            "|    learning_rate        | 0.000206       |\n",
            "|    loss                 | 9.13           |\n",
            "|    n_updates            | 800            |\n",
            "|    policy_gradient_loss | -0.000883      |\n",
            "|    reward               | 0.3623515      |\n",
            "|    std                  | 1.03           |\n",
            "|    value_loss           | 20.1           |\n",
            "--------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 475            |\n",
            "|    iterations           | 82             |\n",
            "|    time_elapsed         | 39             |\n",
            "|    total_timesteps      | 19024          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000112341906 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -7.25          |\n",
            "|    explained_variance   | -0.0246        |\n",
            "|    learning_rate        | 0.000206       |\n",
            "|    loss                 | 30.8           |\n",
            "|    n_updates            | 810            |\n",
            "|    policy_gradient_loss | -0.00167       |\n",
            "|    reward               | -2.4671035     |\n",
            "|    std                  | 1.03           |\n",
            "|    value_loss           | 63.2           |\n",
            "--------------------------------------------\n",
            "---------------------------------------------\n",
            "| time/                   |                 |\n",
            "|    fps                  | 476             |\n",
            "|    iterations           | 83              |\n",
            "|    time_elapsed         | 40              |\n",
            "|    total_timesteps      | 19256           |\n",
            "| train/                  |                 |\n",
            "|    approx_kl            | 6.0974267e-05   |\n",
            "|    clip_fraction        | 0               |\n",
            "|    clip_range           | 0.2             |\n",
            "|    entropy_loss         | -7.25           |\n",
            "|    explained_variance   | -0.00519        |\n",
            "|    learning_rate        | 0.000206        |\n",
            "|    loss                 | 45.4            |\n",
            "|    n_updates            | 820             |\n",
            "|    policy_gradient_loss | -0.00123        |\n",
            "|    reward               | -0.000109260865 |\n",
            "|    std                  | 1.03            |\n",
            "|    value_loss           | 92.2            |\n",
            "---------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 19488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.984618e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.25        |\n",
            "|    explained_variance   | 0.00344      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 63.4         |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.000649    |\n",
            "|    reward               | 0.047921203  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 128          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 19720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004568953 |\n",
            "|    clip_fraction        | 0.00259     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.25       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.0703     |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | -0.00296    |\n",
            "|    reward               | -0.2657138  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 1.1         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 19952       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022524143 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.26       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.152      |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -0.00722    |\n",
            "|    reward               | 0.08846707  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.887       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 20184       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005004706 |\n",
            "|    clip_fraction        | 0.0159      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.28       |\n",
            "|    explained_variance   | 0.000188    |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.853       |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | 0.00276     |\n",
            "|    reward               | 0.0262437   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 3.25        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 88            |\n",
            "|    time_elapsed         | 42            |\n",
            "|    total_timesteps      | 20416         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00033344972 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.29         |\n",
            "|    explained_variance   | -0.104        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.43          |\n",
            "|    n_updates            | 870           |\n",
            "|    policy_gradient_loss | -0.000421     |\n",
            "|    reward               | 1.7831529     |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 14.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 89            |\n",
            "|    time_elapsed         | 43            |\n",
            "|    total_timesteps      | 20648         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00024132713 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.29         |\n",
            "|    explained_variance   | 0.0216        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 7.04          |\n",
            "|    n_updates            | 880           |\n",
            "|    policy_gradient_loss | -0.000561     |\n",
            "|    reward               | -3.025116     |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 15.4          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 90            |\n",
            "|    time_elapsed         | 43            |\n",
            "|    total_timesteps      | 20880         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00025101827 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.29         |\n",
            "|    explained_variance   | 0.0815        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 2.77          |\n",
            "|    n_updates            | 890           |\n",
            "|    policy_gradient_loss | -0.00118      |\n",
            "|    reward               | 0.4175185     |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 7.18          |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 475            |\n",
            "|    iterations           | 91             |\n",
            "|    time_elapsed         | 44             |\n",
            "|    total_timesteps      | 21112          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000116548916 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -7.29          |\n",
            "|    explained_variance   | 0.067          |\n",
            "|    learning_rate        | 0.000206       |\n",
            "|    loss                 | 20.9           |\n",
            "|    n_updates            | 900            |\n",
            "|    policy_gradient_loss | -0.000799      |\n",
            "|    reward               | 1.2937102      |\n",
            "|    std                  | 1.04           |\n",
            "|    value_loss           | 44             |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 92            |\n",
            "|    time_elapsed         | 45            |\n",
            "|    total_timesteps      | 21344         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 8.2413695e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.29         |\n",
            "|    explained_variance   | 0.0699        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 35.2          |\n",
            "|    n_updates            | 910           |\n",
            "|    policy_gradient_loss | -0.00211      |\n",
            "|    reward               | 0.02036293    |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 72.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 93            |\n",
            "|    time_elapsed         | 45            |\n",
            "|    total_timesteps      | 21576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014439713 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.29         |\n",
            "|    explained_variance   | -0.0126       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 99.9          |\n",
            "|    n_updates            | 920           |\n",
            "|    policy_gradient_loss | -0.00141      |\n",
            "|    reward               | 0.006751982   |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 201           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 94            |\n",
            "|    time_elapsed         | 46            |\n",
            "|    total_timesteps      | 21808         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016355592 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.29         |\n",
            "|    explained_variance   | 0.168         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.29          |\n",
            "|    n_updates            | 930           |\n",
            "|    policy_gradient_loss | -0.00242      |\n",
            "|    reward               | 0.32480827    |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 18.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 22040        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035678018 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.29        |\n",
            "|    explained_variance   | 0.0162       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | -0.378       |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    reward               | -0.6336788   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.473        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 22272        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069458503 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.3         |\n",
            "|    explained_variance   | 0.0119       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.235        |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | 0.00103      |\n",
            "|    reward               | 0.32586476   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 1.86         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 97            |\n",
            "|    time_elapsed         | 47            |\n",
            "|    total_timesteps      | 22504         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00035887546 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.3          |\n",
            "|    explained_variance   | -0.0638       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.7           |\n",
            "|    n_updates            | 960           |\n",
            "|    policy_gradient_loss | -0.00234      |\n",
            "|    reward               | 0.17819384    |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 14.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 98            |\n",
            "|    time_elapsed         | 48            |\n",
            "|    total_timesteps      | 22736         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00088309677 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.31         |\n",
            "|    explained_variance   | -0.0439       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 7.79          |\n",
            "|    n_updates            | 970           |\n",
            "|    policy_gradient_loss | -0.00282      |\n",
            "|    reward               | 0.70692676    |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 16.8          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 22968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004572085 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.31        |\n",
            "|    explained_variance   | -0.0523      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 4.89         |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    reward               | 2.163557     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 11.5         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 100           |\n",
            "|    time_elapsed         | 49            |\n",
            "|    total_timesteps      | 23200         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00027386408 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.31         |\n",
            "|    explained_variance   | 0.0379        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 25.2          |\n",
            "|    n_updates            | 990           |\n",
            "|    policy_gradient_loss | 0.00025       |\n",
            "|    reward               | 2.5396407     |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 52.8          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 101          |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 23432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005598333 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.31        |\n",
            "|    explained_variance   | 0.00439      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 33.4         |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | -0.00367     |\n",
            "|    reward               | -33.242306   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 68.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 23664        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004523345 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.31        |\n",
            "|    explained_variance   | 0.00364      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 137          |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | 0.00266      |\n",
            "|    reward               | 0.58791363   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 276          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 103           |\n",
            "|    time_elapsed         | 50            |\n",
            "|    total_timesteps      | 23896         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.5445825e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.31         |\n",
            "|    explained_variance   | 0.107         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 58.4          |\n",
            "|    n_updates            | 1020          |\n",
            "|    policy_gradient_loss | -5.89e-05     |\n",
            "|    reward               | -0.5418253    |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 119           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 104           |\n",
            "|    time_elapsed         | 50            |\n",
            "|    total_timesteps      | 24128         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014421908 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.31         |\n",
            "|    explained_variance   | 0.055         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 1.01          |\n",
            "|    n_updates            | 1030          |\n",
            "|    policy_gradient_loss | -0.000867     |\n",
            "|    reward               | -0.9458233    |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 3.26          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 105           |\n",
            "|    time_elapsed         | 51            |\n",
            "|    total_timesteps      | 24360         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032885835 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.32         |\n",
            "|    explained_variance   | 0.338         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 1.22          |\n",
            "|    n_updates            | 1040          |\n",
            "|    policy_gradient_loss | -0.00303      |\n",
            "|    reward               | 1.1887268     |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 3.74          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 24592       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001044779 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.32       |\n",
            "|    explained_variance   | -0.0133     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 8.05        |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.00322    |\n",
            "|    reward               | -0.16276914 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 17.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 24824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001103805 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.32       |\n",
            "|    explained_variance   | 0.00128     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 8.34        |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.000353   |\n",
            "|    reward               | 0.14706673  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 18          |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 108           |\n",
            "|    time_elapsed         | 52            |\n",
            "|    total_timesteps      | 25056         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00088138675 |\n",
            "|    clip_fraction        | 0.00172       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.32         |\n",
            "|    explained_variance   | -0.00949      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 4.38          |\n",
            "|    n_updates            | 1070          |\n",
            "|    policy_gradient_loss | -0.00123      |\n",
            "|    reward               | -4.511527     |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 10.1          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 109           |\n",
            "|    time_elapsed         | 53            |\n",
            "|    total_timesteps      | 25288         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00028043755 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.32         |\n",
            "|    explained_variance   | 0.00488       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 22.4          |\n",
            "|    n_updates            | 1080          |\n",
            "|    policy_gradient_loss | 0.00168       |\n",
            "|    reward               | -3.7986932    |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 47            |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 110           |\n",
            "|    time_elapsed         | 53            |\n",
            "|    total_timesteps      | 25520         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020566968 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.32         |\n",
            "|    explained_variance   | -0.015        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 32.7          |\n",
            "|    n_updates            | 1090          |\n",
            "|    policy_gradient_loss | -0.00112      |\n",
            "|    reward               | -4.1523805    |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 66.5          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 25752        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003451325 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.32        |\n",
            "|    explained_variance   | -0.00898     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 35.1         |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    reward               | 0.07168017   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 72.1         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 112           |\n",
            "|    time_elapsed         | 54            |\n",
            "|    total_timesteps      | 25984         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.1559265e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.33         |\n",
            "|    explained_variance   | 0.037         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 106           |\n",
            "|    n_updates            | 1110          |\n",
            "|    policy_gradient_loss | -0.000195     |\n",
            "|    reward               | -0.1419115    |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 214           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 55           |\n",
            "|    total_timesteps      | 26216        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012241196 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.33        |\n",
            "|    explained_variance   | 0.00262      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.275        |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    reward               | 1.1574949    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 1.82         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 55           |\n",
            "|    total_timesteps      | 26448        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049759704 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.33        |\n",
            "|    explained_variance   | 0.314        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 1.1          |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | 0.00193      |\n",
            "|    reward               | -1.2342135   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 3.42         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 115           |\n",
            "|    time_elapsed         | 56            |\n",
            "|    total_timesteps      | 26680         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029085652 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.34         |\n",
            "|    explained_variance   | -0.00888      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.44          |\n",
            "|    n_updates            | 1140          |\n",
            "|    policy_gradient_loss | -0.00171      |\n",
            "|    reward               | 2.863641      |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 18.4          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 26912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003772848 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.34        |\n",
            "|    explained_variance   | -0.0128      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 7.53         |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    reward               | 0.3830419    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 16.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 117           |\n",
            "|    time_elapsed         | 57            |\n",
            "|    total_timesteps      | 27144         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00037548356 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.34         |\n",
            "|    explained_variance   | 0.072         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 4.33          |\n",
            "|    n_updates            | 1160          |\n",
            "|    policy_gradient_loss | -0.000894     |\n",
            "|    reward               | 2.1336591     |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 9.93          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 118           |\n",
            "|    time_elapsed         | 57            |\n",
            "|    total_timesteps      | 27376         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00036230273 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.34         |\n",
            "|    explained_variance   | -0.0645       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 11.9          |\n",
            "|    n_updates            | 1170          |\n",
            "|    policy_gradient_loss | -0.00185      |\n",
            "|    reward               | -6.703113     |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 26            |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 119           |\n",
            "|    time_elapsed         | 57            |\n",
            "|    total_timesteps      | 27608         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032015837 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.35         |\n",
            "|    explained_variance   | -0.00838      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 29.9          |\n",
            "|    n_updates            | 1180          |\n",
            "|    policy_gradient_loss | -0.00221      |\n",
            "|    reward               | 1.7334847     |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 61.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 120           |\n",
            "|    time_elapsed         | 58            |\n",
            "|    total_timesteps      | 27840         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030905806 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.35         |\n",
            "|    explained_variance   | 0.000345      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 24.6          |\n",
            "|    n_updates            | 1190          |\n",
            "|    policy_gradient_loss | -0.00109      |\n",
            "|    reward               | -0.32577538   |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 50.6          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 28072        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001309311 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.35        |\n",
            "|    explained_variance   | 0.0365       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 88.1         |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.00066     |\n",
            "|    reward               | -0.46856996  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 178          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 122         |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 28304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004644088 |\n",
            "|    clip_fraction        | 0.00474     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.35       |\n",
            "|    explained_variance   | 0.0838      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.253      |\n",
            "|    n_updates            | 1210        |\n",
            "|    policy_gradient_loss | -0.00436    |\n",
            "|    reward               | -1.6666245  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.774       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 123         |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 28536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008545231 |\n",
            "|    clip_fraction        | 0.0349      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.35       |\n",
            "|    explained_variance   | 0.294       |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.166       |\n",
            "|    n_updates            | 1220        |\n",
            "|    policy_gradient_loss | 0.00164     |\n",
            "|    reward               | -4.710917   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 1.54        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 60           |\n",
            "|    total_timesteps      | 28768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012907746 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.36        |\n",
            "|    explained_variance   | -0.254       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 5.92         |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | 1.3296386    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 13.3         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 125           |\n",
            "|    time_elapsed         | 60            |\n",
            "|    total_timesteps      | 29000         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00037335142 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.36         |\n",
            "|    explained_variance   | -0.0535       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 5.74          |\n",
            "|    n_updates            | 1240          |\n",
            "|    policy_gradient_loss | -0.00114      |\n",
            "|    reward               | 0.62659776    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 12.9          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 126           |\n",
            "|    time_elapsed         | 61            |\n",
            "|    total_timesteps      | 29232         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00019859496 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.37         |\n",
            "|    explained_variance   | -0.0377       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.04          |\n",
            "|    n_updates            | 1250          |\n",
            "|    policy_gradient_loss | -0.000514     |\n",
            "|    reward               | 0.013216019   |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 13.5          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 127           |\n",
            "|    time_elapsed         | 61            |\n",
            "|    total_timesteps      | 29464         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011184709 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.37         |\n",
            "|    explained_variance   | -0.00716      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 4.27          |\n",
            "|    n_updates            | 1260          |\n",
            "|    policy_gradient_loss | -0.00112      |\n",
            "|    reward               | 0.19928348    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 10.1          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 128           |\n",
            "|    time_elapsed         | 62            |\n",
            "|    total_timesteps      | 29696         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014747422 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.37         |\n",
            "|    explained_variance   | -0.00506      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 24.1          |\n",
            "|    n_updates            | 1270          |\n",
            "|    policy_gradient_loss | -0.000856     |\n",
            "|    reward               | -6.7650695    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 49.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 129           |\n",
            "|    time_elapsed         | 62            |\n",
            "|    total_timesteps      | 29928         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00019380142 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.37         |\n",
            "|    explained_variance   | -7.55e-05     |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 42.5          |\n",
            "|    n_updates            | 1280          |\n",
            "|    policy_gradient_loss | -0.00179      |\n",
            "|    reward               | 0.049719058   |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 86.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 130           |\n",
            "|    time_elapsed         | 63            |\n",
            "|    total_timesteps      | 30160         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 9.8611774e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.37         |\n",
            "|    explained_variance   | -0.0135       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 62.9          |\n",
            "|    n_updates            | 1290          |\n",
            "|    policy_gradient_loss | -0.000419     |\n",
            "|    reward               | -0.0767965    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 127           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 30392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00098636  |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.37       |\n",
            "|    explained_variance   | 0.183       |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.456      |\n",
            "|    n_updates            | 1300        |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    reward               | -0.46390674 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.345       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 64           |\n",
            "|    total_timesteps      | 30624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014835658 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.37        |\n",
            "|    explained_variance   | 0.1          |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | -0.238       |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | 0.000456     |\n",
            "|    reward               | 3.1793406    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.8          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 64          |\n",
            "|    total_timesteps      | 30856       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005733241 |\n",
            "|    clip_fraction        | 0.0181      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.37       |\n",
            "|    explained_variance   | -0.11       |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 1.21        |\n",
            "|    n_updates            | 1320        |\n",
            "|    policy_gradient_loss | -0.000931   |\n",
            "|    reward               | 0.35025325  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 3.58        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 134           |\n",
            "|    time_elapsed         | 65            |\n",
            "|    total_timesteps      | 31088         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00022138398 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.38         |\n",
            "|    explained_variance   | 0.0313        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 5.85          |\n",
            "|    n_updates            | 1330          |\n",
            "|    policy_gradient_loss | -0.000765     |\n",
            "|    reward               | -0.07580214   |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 13.4          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 135           |\n",
            "|    time_elapsed         | 65            |\n",
            "|    total_timesteps      | 31320         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00039537175 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.38         |\n",
            "|    explained_variance   | -0.0218       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.05          |\n",
            "|    n_updates            | 1340          |\n",
            "|    policy_gradient_loss | -0.00133      |\n",
            "|    reward               | -0.2845843    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 17.4          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 136           |\n",
            "|    time_elapsed         | 66            |\n",
            "|    total_timesteps      | 31552         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00073497975 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.38         |\n",
            "|    explained_variance   | -0.0766       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 2.76          |\n",
            "|    n_updates            | 1350          |\n",
            "|    policy_gradient_loss | -0.00147      |\n",
            "|    reward               | 0.20028168    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 7.03          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 137           |\n",
            "|    time_elapsed         | 66            |\n",
            "|    total_timesteps      | 31784         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00027550987 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.38         |\n",
            "|    explained_variance   | 0.0103        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 22.7          |\n",
            "|    n_updates            | 1360          |\n",
            "|    policy_gradient_loss | -0.000511     |\n",
            "|    reward               | 3.980835      |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 47.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 138           |\n",
            "|    time_elapsed         | 67            |\n",
            "|    total_timesteps      | 32016         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 8.0303646e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.38         |\n",
            "|    explained_variance   | -0.00257      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 28.8          |\n",
            "|    n_updates            | 1370          |\n",
            "|    policy_gradient_loss | -0.000766     |\n",
            "|    reward               | -1.506682     |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 58.9          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 139           |\n",
            "|    time_elapsed         | 67            |\n",
            "|    total_timesteps      | 32248         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015538417 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.38         |\n",
            "|    explained_variance   | 0.00455       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 62            |\n",
            "|    n_updates            | 1380          |\n",
            "|    policy_gradient_loss | 0.000476      |\n",
            "|    reward               | -0.015331571  |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 125           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 32480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00024513  |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.38       |\n",
            "|    explained_variance   | 0.168       |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 6.29        |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | -0.00184    |\n",
            "|    reward               | -0.19112173 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 32712        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043753963 |\n",
            "|    clip_fraction        | 0.00603      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.39        |\n",
            "|    explained_variance   | -0.0463      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.214        |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.00661     |\n",
            "|    reward               | -0.27101174  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 1.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 69           |\n",
            "|    total_timesteps      | 32944        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027867164 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.39        |\n",
            "|    explained_variance   | -0.00337     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 1.91         |\n",
            "|    n_updates            | 1410         |\n",
            "|    policy_gradient_loss | -0.00768     |\n",
            "|    reward               | -0.60876924  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 5.44         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 69           |\n",
            "|    total_timesteps      | 33176        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010749346 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.39        |\n",
            "|    explained_variance   | 0.00372      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 6.21         |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    reward               | 0.81272364   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 13.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 144          |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 33408        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003246254 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.39        |\n",
            "|    explained_variance   | 0.00299      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 8.7          |\n",
            "|    n_updates            | 1430         |\n",
            "|    policy_gradient_loss | -0.000739    |\n",
            "|    reward               | 1.5256318    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 18.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 33640        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.235339e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.39        |\n",
            "|    explained_variance   | 0.0279       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 4.07         |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.000224    |\n",
            "|    reward               | 0.89184445   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 9.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 33872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002740768 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.4         |\n",
            "|    explained_variance   | -0.0147      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 23.2         |\n",
            "|    n_updates            | 1450         |\n",
            "|    policy_gradient_loss | 0.000572     |\n",
            "|    reward               | 1.4038965    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 48.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 147          |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 34104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.127321e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.4         |\n",
            "|    explained_variance   | -0.0177      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 29.2         |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.000345    |\n",
            "|    reward               | -1.8529654   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 59.8         |\n",
            "------------------------------------------\n",
            "day: 2136, episode: 3660\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2071542.44\n",
            "total_reward: 1071542.44\n",
            "total_cost: 28329.95\n",
            "total_trades: 9512\n",
            "Sharpe: 0.512\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 148           |\n",
            "|    time_elapsed         | 72            |\n",
            "|    total_timesteps      | 34336         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.6386216e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.4          |\n",
            "|    explained_variance   | -0.000811     |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 36.5          |\n",
            "|    n_updates            | 1470          |\n",
            "|    policy_gradient_loss | -0.000579     |\n",
            "|    reward               | 0.07084293    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 74.6          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 149           |\n",
            "|    time_elapsed         | 72            |\n",
            "|    total_timesteps      | 34568         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00025063084 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.4          |\n",
            "|    explained_variance   | 0.132         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 20            |\n",
            "|    n_updates            | 1480          |\n",
            "|    policy_gradient_loss | -0.00179      |\n",
            "|    reward               | 0.0032205973  |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 41.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 150          |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 34800        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024460757 |\n",
            "|    clip_fraction        | 0.000862     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.4         |\n",
            "|    explained_variance   | -0.02        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.0734       |\n",
            "|    n_updates            | 1490         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | 1.9131446    |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 1.38         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 475         |\n",
            "|    iterations           | 151         |\n",
            "|    time_elapsed         | 73          |\n",
            "|    total_timesteps      | 35032       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005998711 |\n",
            "|    clip_fraction        | 0.0121      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.42       |\n",
            "|    explained_variance   | 0.197       |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.663       |\n",
            "|    n_updates            | 1500        |\n",
            "|    policy_gradient_loss | -0.00688    |\n",
            "|    reward               | -0.6586039  |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 2.91        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 152         |\n",
            "|    time_elapsed         | 74          |\n",
            "|    total_timesteps      | 35264       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001109309 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.43       |\n",
            "|    explained_variance   | 0.0278      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 5.33        |\n",
            "|    n_updates            | 1510        |\n",
            "|    policy_gradient_loss | -0.000491   |\n",
            "|    reward               | 0.28135574  |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 153         |\n",
            "|    time_elapsed         | 74          |\n",
            "|    total_timesteps      | 35496       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000470953 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.43       |\n",
            "|    explained_variance   | -0.0367     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 9.16        |\n",
            "|    n_updates            | 1520        |\n",
            "|    policy_gradient_loss | -0.000498   |\n",
            "|    reward               | 0.9681777   |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 19.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 154          |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 35728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007834147 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.44        |\n",
            "|    explained_variance   | -0.0353      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 3.72         |\n",
            "|    n_updates            | 1530         |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    reward               | 3.669532     |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 8.81         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 155           |\n",
            "|    time_elapsed         | 75            |\n",
            "|    total_timesteps      | 35960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00061120815 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.44         |\n",
            "|    explained_variance   | -0.00378      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 15.5          |\n",
            "|    n_updates            | 1540          |\n",
            "|    policy_gradient_loss | -0.00062      |\n",
            "|    reward               | -1.0774093    |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 32.5          |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 477        |\n",
            "|    iterations           | 156        |\n",
            "|    time_elapsed         | 75         |\n",
            "|    total_timesteps      | 36192      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00089151 |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -7.44      |\n",
            "|    explained_variance   | 0.00131    |\n",
            "|    learning_rate        | 0.000206   |\n",
            "|    loss                 | 20.4       |\n",
            "|    n_updates            | 1550       |\n",
            "|    policy_gradient_loss | -0.0031    |\n",
            "|    reward               | -1.6380004 |\n",
            "|    std                  | 1.07       |\n",
            "|    value_loss           | 42.6       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 157         |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 36424       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001663087 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.44       |\n",
            "|    explained_variance   | -0.012      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 35.4        |\n",
            "|    n_updates            | 1560        |\n",
            "|    policy_gradient_loss | -0.00267    |\n",
            "|    reward               | 0.12719858  |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 72.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 158          |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 36656        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003432963 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.44        |\n",
            "|    explained_variance   | -0.000295    |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 45           |\n",
            "|    n_updates            | 1570         |\n",
            "|    policy_gradient_loss | -0.000401    |\n",
            "|    reward               | -0.50233537  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 91.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 159         |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 36888       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02435203  |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.45       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.822       |\n",
            "|    n_updates            | 1580        |\n",
            "|    policy_gradient_loss | -0.0101     |\n",
            "|    reward               | -0.66529566 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 2.86        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 160         |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 37120       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00264065  |\n",
            "|    clip_fraction        | 0.00216     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.46       |\n",
            "|    explained_variance   | 0.24        |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 1.11        |\n",
            "|    n_updates            | 1590        |\n",
            "|    policy_gradient_loss | -0.00411    |\n",
            "|    reward               | -0.49942893 |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 3.53        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 161          |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 37352        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006222252 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.47        |\n",
            "|    explained_variance   | -0.0236      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 6.12         |\n",
            "|    n_updates            | 1600         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | 1.4631182    |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 13.5         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 162           |\n",
            "|    time_elapsed         | 78            |\n",
            "|    total_timesteps      | 37584         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00086621963 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.47         |\n",
            "|    explained_variance   | 0.0757        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 7.54          |\n",
            "|    n_updates            | 1610          |\n",
            "|    policy_gradient_loss | -0.00171      |\n",
            "|    reward               | -1.4538594    |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 16.8          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 163          |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 37816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009830579 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.47        |\n",
            "|    explained_variance   | -0.000525    |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 5.64         |\n",
            "|    n_updates            | 1620         |\n",
            "|    policy_gradient_loss | -0.00319     |\n",
            "|    reward               | -1.1867656   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 12.6         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 164           |\n",
            "|    time_elapsed         | 79            |\n",
            "|    total_timesteps      | 38048         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00048895774 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.48         |\n",
            "|    explained_variance   | -0.0338       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.21          |\n",
            "|    n_updates            | 1630          |\n",
            "|    policy_gradient_loss | -0.000239     |\n",
            "|    reward               | 5.3157487     |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 14.6          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 165          |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 38280        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011817443 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.48        |\n",
            "|    explained_variance   | 0.00514      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 24.6         |\n",
            "|    n_updates            | 1640         |\n",
            "|    policy_gradient_loss | -0.00264     |\n",
            "|    reward               | 1.8516234    |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 50.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 166          |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 38512        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011280962 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.48        |\n",
            "|    explained_variance   | 0.00815      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 38.7         |\n",
            "|    n_updates            | 1650         |\n",
            "|    policy_gradient_loss | -0.000706    |\n",
            "|    reward               | 0.0039683594 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 78.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 167          |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 38744        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012151774 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.48        |\n",
            "|    explained_variance   | 0.00955      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 49.8         |\n",
            "|    n_updates            | 1660         |\n",
            "|    policy_gradient_loss | -0.00342     |\n",
            "|    reward               | 0.09974114   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 101          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 476         |\n",
            "|    iterations           | 168         |\n",
            "|    time_elapsed         | 81          |\n",
            "|    total_timesteps      | 38976       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015403817 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.49       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.28        |\n",
            "|    n_updates            | 1670        |\n",
            "|    policy_gradient_loss | -0.0066     |\n",
            "|    reward               | 0.76432884  |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.78        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 169          |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 39208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058364775 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.5         |\n",
            "|    explained_variance   | 0.339        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 0.666        |\n",
            "|    n_updates            | 1680         |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    reward               | -0.8646048   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 2.58         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 170           |\n",
            "|    time_elapsed         | 82            |\n",
            "|    total_timesteps      | 39440         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032893542 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.51         |\n",
            "|    explained_variance   | -0.0838       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.35          |\n",
            "|    n_updates            | 1690          |\n",
            "|    policy_gradient_loss | -0.000528     |\n",
            "|    reward               | 1.4582571     |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 14.1          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 171           |\n",
            "|    time_elapsed         | 83            |\n",
            "|    total_timesteps      | 39672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030068978 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.52         |\n",
            "|    explained_variance   | 0.00398       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.14          |\n",
            "|    n_updates            | 1700          |\n",
            "|    policy_gradient_loss | -0.000584     |\n",
            "|    reward               | 0.31881168    |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 13.8          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 172           |\n",
            "|    time_elapsed         | 83            |\n",
            "|    total_timesteps      | 39904         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00046387778 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.52         |\n",
            "|    explained_variance   | 0.0073        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 7.22          |\n",
            "|    n_updates            | 1710          |\n",
            "|    policy_gradient_loss | -0.0021       |\n",
            "|    reward               | 0.28202766    |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 15.7          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 173          |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 40136        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005022868 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.52        |\n",
            "|    explained_variance   | -0.0742      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 3.6          |\n",
            "|    n_updates            | 1720         |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    reward               | 0.33151403   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 8.89         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 174           |\n",
            "|    time_elapsed         | 84            |\n",
            "|    total_timesteps      | 40368         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00050119904 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.52         |\n",
            "|    explained_variance   | -0.0504       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 21.1          |\n",
            "|    n_updates            | 1730          |\n",
            "|    policy_gradient_loss | -0.00178      |\n",
            "|    reward               | -1.1436877    |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 44.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 175           |\n",
            "|    time_elapsed         | 85            |\n",
            "|    total_timesteps      | 40600         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00068230694 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.52         |\n",
            "|    explained_variance   | -0.00685      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 29.3          |\n",
            "|    n_updates            | 1740          |\n",
            "|    policy_gradient_loss | -0.00437      |\n",
            "|    reward               | 2.2970994     |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 60.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 176          |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 40832        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003304299 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.52        |\n",
            "|    explained_variance   | -0.0177      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 59.9         |\n",
            "|    n_updates            | 1750         |\n",
            "|    policy_gradient_loss | -0.000621    |\n",
            "|    reward               | -0.31707683  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 121          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 177         |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 41064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008856869 |\n",
            "|    clip_fraction        | 0.0224      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.52       |\n",
            "|    explained_variance   | 0.0829      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | -0.341      |\n",
            "|    n_updates            | 1760        |\n",
            "|    policy_gradient_loss | -0.0074     |\n",
            "|    reward               | 0.17113647  |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.707       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 178         |\n",
            "|    time_elapsed         | 87          |\n",
            "|    total_timesteps      | 41296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029154407 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.53       |\n",
            "|    explained_variance   | 0.0294      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.273       |\n",
            "|    n_updates            | 1770        |\n",
            "|    policy_gradient_loss | -0.00983    |\n",
            "|    reward               | 0.33284235  |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 1.76        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 179          |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 41528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009333186 |\n",
            "|    clip_fraction        | 0.00129      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.54        |\n",
            "|    explained_variance   | -0.237       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 3.99         |\n",
            "|    n_updates            | 1780         |\n",
            "|    policy_gradient_loss | 0.0011       |\n",
            "|    reward               | 1.9425474    |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 9.37         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 180           |\n",
            "|    time_elapsed         | 88            |\n",
            "|    total_timesteps      | 41760         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021318218 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.55         |\n",
            "|    explained_variance   | 0.0163        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.07          |\n",
            "|    n_updates            | 1790          |\n",
            "|    policy_gradient_loss | -0.000317     |\n",
            "|    reward               | -0.64054507   |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 17.5          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 181           |\n",
            "|    time_elapsed         | 88            |\n",
            "|    total_timesteps      | 41992         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011199122 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.55         |\n",
            "|    explained_variance   | -0.0188       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 8.31          |\n",
            "|    n_updates            | 1800          |\n",
            "|    policy_gradient_loss | -0.000863     |\n",
            "|    reward               | 0.71831965    |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 17.8          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 182          |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 42224        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003659977 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.55        |\n",
            "|    explained_variance   | -0.0152      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 2.86         |\n",
            "|    n_updates            | 1810         |\n",
            "|    policy_gradient_loss | -0.000975    |\n",
            "|    reward               | -2.1980815   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 7.07         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 183           |\n",
            "|    time_elapsed         | 89            |\n",
            "|    total_timesteps      | 42456         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00028964286 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.55         |\n",
            "|    explained_variance   | 0.00775       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 22.7          |\n",
            "|    n_updates            | 1820          |\n",
            "|    policy_gradient_loss | -1.48e-05     |\n",
            "|    reward               | 6.5676603     |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 47.3          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 184         |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 42688       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004367516 |\n",
            "|    clip_fraction        | 0.00991     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.55       |\n",
            "|    explained_variance   | -0.0147     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 30.4        |\n",
            "|    n_updates            | 1830        |\n",
            "|    policy_gradient_loss | -0.00687    |\n",
            "|    reward               | 5.016892    |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 62.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 185          |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 42920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024747145 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.56        |\n",
            "|    explained_variance   | 0.0108       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 60.6         |\n",
            "|    n_updates            | 1840         |\n",
            "|    policy_gradient_loss | 0.00131      |\n",
            "|    reward               | 0.28212586   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 123          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 186           |\n",
            "|    time_elapsed         | 91            |\n",
            "|    total_timesteps      | 43152         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032112518 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.56         |\n",
            "|    explained_variance   | 0.277         |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.63          |\n",
            "|    n_updates            | 1850          |\n",
            "|    policy_gradient_loss | -0.00208      |\n",
            "|    reward               | -0.2844761    |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 14.7          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 187         |\n",
            "|    time_elapsed         | 91          |\n",
            "|    total_timesteps      | 43384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022990458 |\n",
            "|    clip_fraction        | 0.0983      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.56       |\n",
            "|    explained_variance   | -0.0395     |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 0.436       |\n",
            "|    n_updates            | 1860        |\n",
            "|    policy_gradient_loss | -0.00719    |\n",
            "|    reward               | -0.59663445 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 2.11        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 188          |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 43616        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009616824 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.57        |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 1.93         |\n",
            "|    n_updates            | 1870         |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    reward               | -2.2868645   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 5.15         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 189          |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 43848        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010129416 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.57        |\n",
            "|    explained_variance   | 0.0244       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 6.62         |\n",
            "|    n_updates            | 1880         |\n",
            "|    policy_gradient_loss | -0.00345     |\n",
            "|    reward               | 0.64853215   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 14.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 190          |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 44080        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009084164 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.58        |\n",
            "|    explained_variance   | -0.0101      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 9.13         |\n",
            "|    n_updates            | 1890         |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | 0.20060834   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 19.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 191         |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 44312       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000342514 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.58       |\n",
            "|    explained_variance   | 0.0397      |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 3.65        |\n",
            "|    n_updates            | 1900        |\n",
            "|    policy_gradient_loss | -0.00151    |\n",
            "|    reward               | 0.4529796   |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 8.7         |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 192           |\n",
            "|    time_elapsed         | 93            |\n",
            "|    total_timesteps      | 44544         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00051748496 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.58         |\n",
            "|    explained_variance   | -0.0211       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 20.2          |\n",
            "|    n_updates            | 1910          |\n",
            "|    policy_gradient_loss | -0.00123      |\n",
            "|    reward               | -2.1683319    |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 42.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 193          |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 44776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006808374 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.58        |\n",
            "|    explained_variance   | 0.00152      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 26.6         |\n",
            "|    n_updates            | 1920         |\n",
            "|    policy_gradient_loss | -0.00349     |\n",
            "|    reward               | 0.6468129    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 54.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 45008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009537704 |\n",
            "|    clip_fraction        | 0.00129      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.58        |\n",
            "|    explained_variance   | 0.00194      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 31.2         |\n",
            "|    n_updates            | 1930         |\n",
            "|    policy_gradient_loss | -0.00175     |\n",
            "|    reward               | -0.25483322  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 63.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 195          |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 45240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005308557 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.58        |\n",
            "|    explained_variance   | 0.0742       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 39.7         |\n",
            "|    n_updates            | 1940         |\n",
            "|    policy_gradient_loss | -0.00381     |\n",
            "|    reward               | -1.3228726   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 80.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 196          |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 45472        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045599164 |\n",
            "|    clip_fraction        | 0.00905      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.58        |\n",
            "|    explained_variance   | 0.0225       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 2.9          |\n",
            "|    n_updates            | 1950         |\n",
            "|    policy_gradient_loss | -0.00718     |\n",
            "|    reward               | 1.1134263    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 7.14         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 197          |\n",
            "|    time_elapsed         | 96           |\n",
            "|    total_timesteps      | 45704        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025186515 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.59        |\n",
            "|    explained_variance   | 0.0384       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 2.09         |\n",
            "|    n_updates            | 1960         |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    reward               | 1.8256986    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 5.47         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 198           |\n",
            "|    time_elapsed         | 96            |\n",
            "|    total_timesteps      | 45936         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015288129 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.59         |\n",
            "|    explained_variance   | 0.0121        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.98          |\n",
            "|    n_updates            | 1970          |\n",
            "|    policy_gradient_loss | 0.000385      |\n",
            "|    reward               | 0.15598843    |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 15.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 199           |\n",
            "|    time_elapsed         | 97            |\n",
            "|    total_timesteps      | 46168         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00041215328 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.59         |\n",
            "|    explained_variance   | 0.00337       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 9.29          |\n",
            "|    n_updates            | 1980          |\n",
            "|    policy_gradient_loss | -0.00125      |\n",
            "|    reward               | 0.20310968    |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 20            |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 200          |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 46400        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014824109 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.59        |\n",
            "|    explained_variance   | -0.0201      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 3.86         |\n",
            "|    n_updates            | 1990         |\n",
            "|    policy_gradient_loss | -0.00343     |\n",
            "|    reward               | 0.021901112  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 9.04         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 201          |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 46632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025339674 |\n",
            "|    clip_fraction        | 0.000862     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.6         |\n",
            "|    explained_variance   | 0.0254       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 16.6         |\n",
            "|    n_updates            | 2000         |\n",
            "|    policy_gradient_loss | 0.00243      |\n",
            "|    reward               | -5.6986046   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 35.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 202           |\n",
            "|    time_elapsed         | 98            |\n",
            "|    total_timesteps      | 46864         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00025684797 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.6          |\n",
            "|    explained_variance   | -0.0037       |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 31            |\n",
            "|    n_updates            | 2010          |\n",
            "|    policy_gradient_loss | -0.000587     |\n",
            "|    reward               | 2.8964663     |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 63.1          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 203          |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 47096        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039908397 |\n",
            "|    clip_fraction        | 0.00517      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.6         |\n",
            "|    explained_variance   | -0.00556     |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 35.1         |\n",
            "|    n_updates            | 2020         |\n",
            "|    policy_gradient_loss | -0.00496     |\n",
            "|    reward               | -0.22250272  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 71.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 47328        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011314675 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.6         |\n",
            "|    explained_variance   | 0.0104       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 44.9         |\n",
            "|    n_updates            | 2030         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    reward               | -0.28037897  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 91.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 205          |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 47560        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008492141 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.6         |\n",
            "|    explained_variance   | -0.0793      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 4.17         |\n",
            "|    n_updates            | 2040         |\n",
            "|    policy_gradient_loss | -0.00267     |\n",
            "|    reward               | -0.56551975  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 9.76         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 206           |\n",
            "|    time_elapsed         | 100           |\n",
            "|    total_timesteps      | 47792         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00046854827 |\n",
            "|    clip_fraction        | 0.00388       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.61         |\n",
            "|    explained_variance   | 0.0349        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 1.64          |\n",
            "|    n_updates            | 2050          |\n",
            "|    policy_gradient_loss | -0.00304      |\n",
            "|    reward               | -0.36506066   |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 4.52          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 207          |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 48024        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003762836 |\n",
            "|    clip_fraction        | 0.00388      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.61        |\n",
            "|    explained_variance   | -0.018       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 7.72         |\n",
            "|    n_updates            | 2060         |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    reward               | -1.2763308   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 16.8         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 208           |\n",
            "|    time_elapsed         | 101           |\n",
            "|    total_timesteps      | 48256         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00026649135 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.61         |\n",
            "|    explained_variance   | -0.019        |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 6.54          |\n",
            "|    n_updates            | 2070          |\n",
            "|    policy_gradient_loss | -0.000764     |\n",
            "|    reward               | -0.8964052    |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 14.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 209           |\n",
            "|    time_elapsed         | 101           |\n",
            "|    total_timesteps      | 48488         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00028551216 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -7.61         |\n",
            "|    explained_variance   | -0.00274      |\n",
            "|    learning_rate        | 0.000206      |\n",
            "|    loss                 | 5.95          |\n",
            "|    n_updates            | 2080          |\n",
            "|    policy_gradient_loss | -0.00256      |\n",
            "|    reward               | -2.2431536    |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 13.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 210          |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 48720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010084142 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.61        |\n",
            "|    explained_variance   | -0.0135      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 4.99         |\n",
            "|    n_updates            | 2090         |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    reward               | 3.9603152    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 11.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 211          |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 48952        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010598053 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.61        |\n",
            "|    explained_variance   | 0.00977      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 23           |\n",
            "|    n_updates            | 2100         |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    reward               | -1.7982966   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 47.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 212         |\n",
            "|    time_elapsed         | 103         |\n",
            "|    total_timesteps      | 49184       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012583073 |\n",
            "|    clip_fraction        | 0.0483      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.61       |\n",
            "|    explained_variance   | -0.000186   |\n",
            "|    learning_rate        | 0.000206    |\n",
            "|    loss                 | 32.5        |\n",
            "|    n_updates            | 2110        |\n",
            "|    policy_gradient_loss | -0.00896    |\n",
            "|    reward               | 0.18769093  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 66.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 213          |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 49416        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026006377 |\n",
            "|    clip_fraction        | 0.00474      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.62        |\n",
            "|    explained_variance   | 0.00225      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 48.9         |\n",
            "|    n_updates            | 2120         |\n",
            "|    policy_gradient_loss | 0.00665      |\n",
            "|    reward               | 0.02856359   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 99           |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 476        |\n",
            "|    iterations           | 214        |\n",
            "|    time_elapsed         | 104        |\n",
            "|    total_timesteps      | 49648      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00159279 |\n",
            "|    clip_fraction        | 0.000431   |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -7.62      |\n",
            "|    explained_variance   | 0.336      |\n",
            "|    learning_rate        | 0.000206   |\n",
            "|    loss                 | 2.74       |\n",
            "|    n_updates            | 2130       |\n",
            "|    policy_gradient_loss | -0.00291   |\n",
            "|    reward               | 0.95056087 |\n",
            "|    std                  | 1.11       |\n",
            "|    value_loss           | 7.09       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 215          |\n",
            "|    time_elapsed         | 104          |\n",
            "|    total_timesteps      | 49880        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020040344 |\n",
            "|    clip_fraction        | 0.000431     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.62        |\n",
            "|    explained_variance   | 0.0389       |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 3.2          |\n",
            "|    n_updates            | 2140         |\n",
            "|    policy_gradient_loss | -0.00536     |\n",
            "|    reward               | 0.4778616    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 7.77         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 216          |\n",
            "|    time_elapsed         | 105          |\n",
            "|    total_timesteps      | 50112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019528064 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.63        |\n",
            "|    explained_variance   | -0.0367      |\n",
            "|    learning_rate        | 0.000206     |\n",
            "|    loss                 | 5.03         |\n",
            "|    n_updates            | 2150         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | 1.7483658    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = training_environment)\n",
        "ppo_params = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "\n",
        "ppo_tuned_params = {\n",
        "    \"n_steps\": 232,\n",
        "    \"ent_coef\": 0.08005421293955037,\n",
        "    \"learning_rate\": 0.0002058992300570136,\n",
        "    \"batch_size\": 238\n",
        "\n",
        "\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = ppo_tuned_params)\n",
        "\n",
        "# set up logger\n",
        "new_logger_ppo = configure(RESULTS_DIR + '/ppo', [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "# Set new logger\n",
        "model_ppo.set_logger(new_logger_ppo)\n",
        "\n",
        "trained_ppo = agent.train_model(model=model_ppo,\n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=50000)\n",
        "\n",
        "# DDPG HYPERPARAMS MOST IMPORTANT\n",
        "# learning_rate: Determines how quickly the model learns from new data. Too low may learn slowly, too high can destabilize training.\n",
        "# buffer_size: The size of the replay buffer holding experiences. Larger buffers allow longer term learning but cost memory.\n",
        "# batch_size: The size of sampled batch from the replay buffer for learning updates. Too small may underutilize GPU/CPU resources.\n",
        "# tau: Controls weighting between older and newer Q-network weights during update. Controls stability vs plasticity.\n",
        "# train_freq: How frequently the model trains. Balance between learning from more data vs more frequent updates.\n",
        "# gradient_steps: Number of gradient steps during each training update. More may increase stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt8eIQKYM4G3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 556         |\n",
            "|    iterations           | 1           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 2048        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008732445 |\n",
            "|    clip_fraction        | 0.0947      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.1        |\n",
            "|    explained_variance   | 0.293       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 17.2        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00872    |\n",
            "|    reward               | -8.01567    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 33          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 519          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056018685 |\n",
            "|    clip_fraction        | 0.0456       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.11        |\n",
            "|    explained_variance   | 0.283        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 9.74         |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00521     |\n",
            "|    reward               | 0.7833154    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 22.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 505         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006726606 |\n",
            "|    clip_fraction        | 0.0641      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.12       |\n",
            "|    explained_variance   | 0.191       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 13.2        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00546    |\n",
            "|    reward               | 2.3873515   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 31.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 498          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053163674 |\n",
            "|    clip_fraction        | 0.0525       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.12        |\n",
            "|    explained_variance   | 0.208        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 31.9         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00632     |\n",
            "|    reward               | -0.6634719   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 36.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 493         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007613427 |\n",
            "|    clip_fraction        | 0.0441      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.12       |\n",
            "|    explained_variance   | 0.184       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 29.4        |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00246    |\n",
            "|    reward               | -1.1522442  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 41.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 461         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 26          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005209225 |\n",
            "|    clip_fraction        | 0.0356      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.12       |\n",
            "|    explained_variance   | 0.27        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.6        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00165    |\n",
            "|    reward               | -3.6970289  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 38.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069035445 |\n",
            "|    clip_fraction        | 0.059        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.12        |\n",
            "|    explained_variance   | 0.237        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 17.6         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00395     |\n",
            "|    reward               | -0.8931979   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 38.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064875395 |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.12        |\n",
            "|    explained_variance   | 0.266        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 13           |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00634     |\n",
            "|    reward               | 1.0542415    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 42.1         |\n",
            "------------------------------------------\n",
            "day: 2136, episode: 60\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3199997.24\n",
            "total_reward: 2199997.24\n",
            "total_cost: 25192.48\n",
            "total_trades: 10293\n",
            "Sharpe: 0.767\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039926637 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.12        |\n",
            "|    explained_variance   | 0.175        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 19.3         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00498     |\n",
            "|    reward               | -0.81809956  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 48.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 470          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058192634 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.11        |\n",
            "|    explained_variance   | 0.139        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 31.2         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00374     |\n",
            "|    reward               | -0.5275623   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 50.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 471         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004976755 |\n",
            "|    clip_fraction        | 0.0356      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.1        |\n",
            "|    explained_variance   | 0.184       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 17.1        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00356    |\n",
            "|    reward               | -1.323824   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 55.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 471         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006693519 |\n",
            "|    clip_fraction        | 0.0423      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.09       |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.8        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00432    |\n",
            "|    reward               | -1.1984695  |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 54.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 471         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008010149 |\n",
            "|    clip_fraction        | 0.0802      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.1        |\n",
            "|    explained_variance   | 0.224       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 31.3        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00639    |\n",
            "|    reward               | 0.38171554  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 51.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059644533 |\n",
            "|    clip_fraction        | 0.05         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.11        |\n",
            "|    explained_variance   | 0.289        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 23.7         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    reward               | -0.50256866  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 65.1         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 466        |\n",
            "|    iterations           | 15         |\n",
            "|    time_elapsed         | 65         |\n",
            "|    total_timesteps      | 30720      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00730025 |\n",
            "|    clip_fraction        | 0.0727     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -7.14      |\n",
            "|    explained_variance   | 0.314      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 25.2       |\n",
            "|    n_updates            | 390        |\n",
            "|    policy_gradient_loss | -0.00833   |\n",
            "|    reward               | -1.3053089 |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 45.7       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053738453 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.15        |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 39           |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    reward               | -0.019328674 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 48.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 74          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009728946 |\n",
            "|    clip_fraction        | 0.0684      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.16       |\n",
            "|    explained_variance   | 0.413       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 11.9        |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00772    |\n",
            "|    reward               | 0.6797547   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 37.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008388812 |\n",
            "|    clip_fraction        | 0.0715      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.16       |\n",
            "|    explained_variance   | 0.391       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 20.2        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.00605    |\n",
            "|    reward               | 0.8038909   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 45.2        |\n",
            "-----------------------------------------\n",
            "day: 2136, episode: 70\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2691353.51\n",
            "total_reward: 1691353.51\n",
            "total_cost: 28301.03\n",
            "total_trades: 10262\n",
            "Sharpe: 0.657\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076707695 |\n",
            "|    clip_fraction        | 0.0447       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.16        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 22.9         |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00401     |\n",
            "|    reward               | 0.78057814   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 48.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 470         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 87          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006141173 |\n",
            "|    clip_fraction        | 0.0627      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.16       |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 23.3        |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.00557    |\n",
            "|    reward               | -0.24496846 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 38.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 472         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 91          |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009375268 |\n",
            "|    clip_fraction        | 0.0858      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.17       |\n",
            "|    explained_variance   | 0.412       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 21.8        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.00632    |\n",
            "|    reward               | 0.8827138   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 44.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 95          |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010493921 |\n",
            "|    clip_fraction        | 0.0969      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.18       |\n",
            "|    explained_variance   | 0.471       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.1        |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.0056     |\n",
            "|    reward               | 0.79594594  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 39          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 475         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004686798 |\n",
            "|    clip_fraction        | 0.0613      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.2        |\n",
            "|    explained_variance   | 0.376       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 15          |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00318    |\n",
            "|    reward               | 0.09614684  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 43.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 103         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010143095 |\n",
            "|    clip_fraction        | 0.0812      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.22       |\n",
            "|    explained_variance   | 0.379       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.4        |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.00607    |\n",
            "|    reward               | 0.005195607 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 43.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 478         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009207145 |\n",
            "|    clip_fraction        | 0.0706      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.23       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 45.8        |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.00559    |\n",
            "|    reward               | -1.2498199  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 52.5        |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "efwBi84ch1jE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date\n",
            "tic\n",
            "open\n",
            "high\n",
            "low\n",
            "close\n",
            "volume\n",
            "day\n",
            "macd\n",
            "boll_ub\n",
            "boll_lb\n",
            "rsi_30\n",
            "cci_30\n",
            "dx_30\n",
            "close_30_sma\n",
            "close_60_sma\n",
            "vix\n",
            "turbulence\n"
          ]
        }
      ],
      "source": [
        "data_risk_indicator = preprocessed_df[(preprocessed_df.date<'2020-07-01') & (preprocessed_df.date>='2012-01-01')]\n",
        "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date']) # INCLUDES THE VIX AND TURBULENCE INDICATORS ALONGSIDE WITH PREV TECHNICAL INDICATORS\n",
        "\n",
        "for col in insample_risk_indicator: \n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHZMBpSqh1jG",
        "outputId": "bfc76e6c-2831-491e-efb3-4a0b28b5f7b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2137.000000\n",
              "mean       16.258573\n",
              "std         6.805276\n",
              "min         9.140000\n",
              "25%        12.740000\n",
              "50%        14.530000\n",
              "75%        17.500000\n",
              "max        82.690002\n",
              "Name: vix, dtype: float64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.vix.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDkszkMloRWT",
        "outputId": "40570340-db9c-4f27-e84c-c9998775c1c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "61.626479248046884"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.vix.quantile(0.996)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL7hs7svnNWT",
        "outputId": "cfed8ac7-406a-4ee6-e611-e83fb4f16de3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2137.000000\n",
              "mean        5.070206\n",
              "std        10.291582\n",
              "min         0.000000\n",
              "25%         0.998157\n",
              "50%         2.360579\n",
              "75%         5.081053\n",
              "max       134.426655\n",
              "Name: turbulence, dtype: float64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.turbulence.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N78hfHckoqJ9",
        "outputId": "9912a51d-bcc2-4b99-bcfb-ecafa83f1446"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89.72780414401996"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.turbulence.quantile(0.996)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cIqoV0GSI52v"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# TESTING OVER HERE\n",
        "trading_environment = StockTradingEnv(df = test, turbulence_threshold = 70,risk_indicator_col='vix', hmax= 100,\n",
        "    initial_amount= 1000000, # STARTING AMOUNT HERE\n",
        "    num_stock_shares= [0] * stock_size,\n",
        "    buy_cost_pct= [.1/100] * stock_size, # Transaction fee percent of buys per stock\n",
        "    sell_cost_pct= [.1/100] * stock_size,\n",
        "    state_space= state_space,\n",
        "    stock_dim= stock_size, # Stock dimensions\n",
        "    tech_indicator_list= ['macd',\n",
        "    'boll_ub',\n",
        "    'boll_lb',\n",
        "    'rsi_30',\n",
        "    'cci_30',\n",
        "    'dx_30',\n",
        "    'close_30_sma',\n",
        "    'close_60_sma'],\n",
        "    action_space= stock_size, \n",
        "    reward_scaling= 1e-4)\n",
        "env_trade, obs_trade = trading_environment.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLOnL5eYh1jR",
        "outputId": "fd6f7bb2-8fae-4fa9-cf06-e0167a6920ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "# trained_model_ddpg = trained_ddpg\n",
        "# df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
        "#     model=trained_model_ddpg,\n",
        "#     environment = trading_environment)\n",
        "\n",
        "\n",
        "testing_a2c_model = trained_a2c\n",
        "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
        "    model=testing_a2c_model,\n",
        "    environment = trading_environment)\n",
        "\n",
        "testing_ppo_model = trained_ppo\n",
        "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
        "    model=testing_ppo_model,\n",
        "    environment = trading_environment)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train\n",
        "a2c_params =  testing_a2c_model.get_parameters()\n",
        "a2c_params['policy']\n",
        "a2c_params['policy.optimizer']    \n",
        "df_account_value_a2c\n",
        "df_actions_a2c\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annual return          0.158991\n",
            "Cumulative returns     0.633397\n",
            "Annual volatility      0.210330\n",
            "Sharpe ratio           0.807632\n",
            "Calmar ratio           0.655063\n",
            "Stability              0.646879\n",
            "Max drawdown          -0.242711\n",
            "Omega ratio            1.147221\n",
            "Sortino ratio          1.169749\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.036394\n",
            "Daily value at risk   -0.025825\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning:\n",
            "\n",
            "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "perf_stats_all = pd.DataFrame(backtest_stats(account_value=df_account_value_a2c))\n",
        "# perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_\"+datetime.datetime.now().strftime('%Y%m%d-%Hh%M')+'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annual return          0.161888\n",
            "Cumulative returns     0.647015\n",
            "Annual volatility      0.230459\n",
            "Sharpe ratio           0.767060\n",
            "Calmar ratio           0.540674\n",
            "Stability              0.478780\n",
            "Max drawdown          -0.299420\n",
            "Omega ratio            1.139112\n",
            "Sortino ratio          1.134703\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.125191\n",
            "Daily value at risk   -0.028334\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning:\n",
            "\n",
            "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "perf_stats_all = pd.DataFrame(backtest_stats(account_value=df_account_value_ppo))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative Returns Value: 0.7324311717380643\n"
          ]
        }
      ],
      "source": [
        "cumulative_return_value = perf_stats_all.loc[\"Cumulative returns\"].iloc[0]\n",
        "print(\"Cumulative Returns Value:\", cumulative_return_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkV-LB66iwhD",
        "outputId": "3deaecb7-7307-4b42-ed26-14511d0ddc41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (837, 8)\n",
            "Annual return          0.100053\n",
            "Cumulative returns     0.372626\n",
            "Annual volatility      0.245511\n",
            "Sharpe ratio           0.511750\n",
            "Calmar ratio           0.281339\n",
            "Stability              0.043634\n",
            "Max drawdown          -0.355631\n",
            "Omega ratio            1.088727\n",
            "Sortino ratio          0.723289\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.952692\n",
            "Daily value at risk   -0.030433\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning:\n",
            "\n",
            "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "baseline_df = get_baseline(\n",
        "        ticker=\"^NDX\",\n",
        "        start = df_account_value_a2c.loc[0,'date'],\n",
        "        end = df_account_value_a2c.loc[len(df_account_value_a2c)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (837, 8)\n",
            "Annual return          0.100053\n",
            "Cumulative returns     0.372626\n",
            "Annual volatility      0.245511\n",
            "Sharpe ratio           0.511750\n",
            "Calmar ratio           0.281339\n",
            "Stability              0.043634\n",
            "Max drawdown          -0.355631\n",
            "Omega ratio            1.088727\n",
            "Sortino ratio          0.723289\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.952692\n",
            "Daily value at risk   -0.030433\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning:\n",
            "\n",
            "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "baseline_df = get_baseline(\n",
        "        ticker=\"^NDX\",\n",
        "        start = df_account_value_ppo.loc[0,'date'],\n",
        "        end = df_account_value_ppo.loc[len(df_account_value_ppo)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      2020-07-01\n",
              "1      2020-07-02\n",
              "2      2020-07-06\n",
              "3      2020-07-07\n",
              "4      2020-07-08\n",
              "          ...    \n",
              "833    2023-10-23\n",
              "834    2023-10-24\n",
              "835    2023-10-25\n",
              "836    2023-10-26\n",
              "837    2023-10-27\n",
              "Name: date, Length: 838, dtype: object"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value_a2c['date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qg1kvfemrrQH",
        "outputId": "94f27dce-2615-4401-b12e-2386cc9a408b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2020-07-01'"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value_a2c.loc[0,'date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tt1bzL5OrsTa",
        "outputId": "3abd2d76-36d9-47ad-898d-5a2d5d8a30a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2023-10-27'"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value_a2c.loc[len(df_account_value_a2c)-1,'date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, trading_environment):\n",
        "    df_account_value, _ = DRLAgent.DRL_prediction(model=model, environment=trading_environment)\n",
        "    perf_stats = pd.DataFrame(backtest_stats(account_value=df_account_value))\n",
        "    return perf_stats\n",
        "\n",
        "# Define your hyperparameter search space\n",
        "n_steps_values = [5, 10, 15]\n",
        "ent_coef_values = [0.01, 0.1, 0.2]\n",
        "learning_rate_values = [1e-4, 5e-4, 1e-3]\n",
        "\n",
        "best_performance = float('-inf')\n",
        "best_params = None\n",
        "\n",
        "# Training and evaluation loop\n",
        "for n_steps in n_steps_values:\n",
        "    for ent_coef in ent_coef_values:\n",
        "        for learning_rate in learning_rate_values:\n",
        "            a2c_params = {\n",
        "                \"n_steps\": n_steps,\n",
        "                \"ent_coef\": ent_coef,\n",
        "                \"learning_rate\": learning_rate,\n",
        "                \"gamma\": 0.99,\n",
        "                \"gae_lambda\": 0.95\n",
        "            }\n",
        "\n",
        "            agent = DRLAgent(training_environment)\n",
        "            a2c_model = agent.get_model(\"a2c\", model_kwargs=a2c_params)\n",
        "            trained_a2c = DRLAgent(training_environment).train_model(model=a2c_model, tb_log_name='a2c', total_timesteps=50000)\n",
        "\n",
        "            # Evaluate the model\n",
        "            perf_stats = evaluate_model(trained_a2c, trading_environment)\n",
        "\n",
        "            # Update best_params if needed\n",
        "            if perf_stats.loc[\"Cumulative returns\"].iloc[-1] > best_performance:\n",
        "                best_performance = perf_stats.loc[\"Cumulative returns\"].iloc[-1]\n",
        "                best_params = a2c_params\n",
        "\n",
        "# Print the best hyperparameters and their performance\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Performance (Cumulative Return):\", best_performance)\n",
        "\n",
        "#TOOK 57 MINS:\n",
        "# Best Hyperparameters: {'n_steps': 15, 'ent_coef': 0.2, 'learning_rate': 0.0005, 'gamma': 0.99, 'gae_lambda': 0.95}\n",
        "# Best Performance (Cumulative Return): 0.822119795194425\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna import Trial\n",
        "\n",
        "def objective(trial: Trial, model_name=None):\n",
        "    # Define the search space for hyperparameters\n",
        "    a2c_params = {\n",
        "        \"n_steps\": trial.suggest_int(\"n_steps\", 1, 10),\n",
        "        \"ent_coef\": trial.suggest_float(\"ent_coef\", 0.001, 0.1),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.9, 0.999),\n",
        "        \"gae_lambda\": trial.suggest_float(\"gae_lambda\", 0.9, 0.999)\n",
        "    }\n",
        "\n",
        "    # Train the A2C model with the current set of hyperparameters\n",
        "    agent = DRLAgent(training_environment)\n",
        "    a2c_model = agent.get_model(\"a2c\", model_kwargs=a2c_params)\n",
        "    trained_a2c = DRLAgent(training_environment).train_model(\n",
        "        model=a2c_model,\n",
        "        tb_log_name='a2c',\n",
        "        total_timesteps=50000\n",
        "    ) \n",
        "\n",
        "    # Evaluate the model\n",
        "    trading_environment = StockTradingEnv(df=test, turbulence_threshold=70, risk_indicator_col='vix', hmax=100,\n",
        "                                          initial_amount=1000000, num_stock_shares=[0] * stock_size,\n",
        "                                          buy_cost_pct=[.1/100] * stock_size, sell_cost_pct=[.1/100] * stock_size,\n",
        "                                          state_space=state_space, stock_dim=stock_size,\n",
        "                                          tech_indicator_list=['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
        "                                                               'close_30_sma', 'close_60_sma'],\n",
        "                                          action_space=stock_size, reward_scaling=1e-4)\n",
        "    # env_trade, obs_trade = trading_environment.get_sb_env()\n",
        "\n",
        "    # df_account_value_a2c, _ = DRLAgent.DRL_prediction(model=trained_a2c, environment=trading_environment)\n",
        "    perf_stats = evaluate_model(trained_a2c, trading_environment)\n",
        "\n",
        "    # Return the metric to be optimized (negative because Optuna minimizes)\n",
        "    return -perf_stats.loc[\"Cumulative returns\"].iloc[-1]\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best parameters found by Optuna\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"Value: \", trial.value)\n",
        "print(\"Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "    \"\"\" \n",
        "    Best trial:\n",
        "Value:  0.12409658470314999\n",
        "Params: \n",
        "    n_steps: 1\n",
        "    ent_coef: 0.0755882482216129\n",
        "    learning_rate: 2.637065887731285e-05\n",
        "    gamma: 0.9048260592925886\n",
        "    gae_lambda: 0.9717236074963396\n",
        "\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna.visualization as optuna_viz\n",
        "\n",
        "# Assuming 'study' is your Optuna study object\n",
        "\n",
        "# Plot parameter importances\n",
        "optuna_viz.plot_param_importances(study)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\formatters.py:922\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    920\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\basedatatypes.py:832\u001b[0m, in \u001b[0;36mBaseFigure._ipython_display_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mrender_on_display \u001b[38;5;129;01mand\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mdefault:\n\u001b[1;32m--> 832\u001b[0m     \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\io\\_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         )\n\u001b[0;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "markers",
                  "name": "Objective Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49
                  ],
                  "y": [
                    -0.7100865569435306,
                    -0.7195320700691088,
                    -0.21397259812175662,
                    -0.653599096744427,
                    -0.37752717289553495,
                    -0.5790002077570349,
                    -0.5711034486442714,
                    -0.5360902805172256,
                    -0.4841272107642509,
                    -0.6261749796743128,
                    -0.3248685810119971,
                    0.12409658470314999,
                    0.02317805519986038,
                    -0.6789874794013588,
                    -0.43500485183106785,
                    -0.6608291936854449,
                    -0.3559460030409325,
                    -0.5658216957263,
                    -0.5237312706607529,
                    -0.7535816634058707,
                    -0.5814642885425079,
                    -0.614065379881674,
                    -0.5726323166092748,
                    -0.7781096778574896,
                    -0.6174028560114775,
                    -0.464042394880424,
                    -0.5612922745275717,
                    -0.6192042410588361,
                    -0.8262293498936188,
                    -0.7755439236564563,
                    -0.6013280649762904,
                    -0.6812763696700326,
                    -0.3933415068326016,
                    -0.718565920500916,
                    -0.41798778088211375,
                    -0.7298353604430796,
                    -0.3914286885474445,
                    -0.767049809489861,
                    -0.5909543206847574,
                    -0.7370372834066552,
                    0.038590935364935075,
                    0.03393171807313422,
                    -0.6587258395489368,
                    -0.7085886625311508,
                    -0.5244446417626787,
                    -0.655679023996615,
                    -0.755125656934424,
                    -0.6976262149840324,
                    -0.06419525318622621,
                    -0.2572215670602409
                  ]
                },
                {
                  "mode": "lines",
                  "name": "Best Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49
                  ],
                  "y": [
                    -0.7100865569435306,
                    -0.7100865569435306,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    -0.21397259812175662,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999,
                    0.12409658470314999
                  ]
                },
                {
                  "marker": {
                    "color": "#cccccc"
                  },
                  "mode": "markers",
                  "name": "Infeasible Trial",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [],
                  "y": []
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Optimization History Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "Trial"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                }
              }
            },
            "text/html": [
              "<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"4bae44cc-47d2-47d0-8337-65510fca1601\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4bae44cc-47d2-47d0-8337-65510fca1601\")) {                    Plotly.newPlot(                        \"4bae44cc-47d2-47d0-8337-65510fca1601\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[-0.7100865569435306,-0.7195320700691088,-0.21397259812175662,-0.653599096744427,-0.37752717289553495,-0.5790002077570349,-0.5711034486442714,-0.5360902805172256,-0.4841272107642509,-0.6261749796743128,-0.3248685810119971,0.12409658470314999,0.02317805519986038,-0.6789874794013588,-0.43500485183106785,-0.6608291936854449,-0.3559460030409325,-0.5658216957263,-0.5237312706607529,-0.7535816634058707,-0.5814642885425079,-0.614065379881674,-0.5726323166092748,-0.7781096778574896,-0.6174028560114775,-0.464042394880424,-0.5612922745275717,-0.6192042410588361,-0.8262293498936188,-0.7755439236564563,-0.6013280649762904,-0.6812763696700326,-0.3933415068326016,-0.718565920500916,-0.41798778088211375,-0.7298353604430796,-0.3914286885474445,-0.767049809489861,-0.5909543206847574,-0.7370372834066552,0.038590935364935075,0.03393171807313422,-0.6587258395489368,-0.7085886625311508,-0.5244446417626787,-0.655679023996615,-0.755125656934424,-0.6976262149840324,-0.06419525318622621,-0.2572215670602409],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[-0.7100865569435306,-0.7100865569435306,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,-0.21397259812175662,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999,0.12409658470314999],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    )                };                            </script>        </div>"
            ],
            "text/plain": [
              "Figure({\n",
              "    'data': [{'mode': 'markers',\n",
              "              'name': 'Objective Value',\n",
              "              'type': 'scatter',\n",
              "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "                    34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
              "              'y': [-0.7100865569435306, -0.7195320700691088,\n",
              "                    -0.21397259812175662, -0.653599096744427, -0.37752717289553495,\n",
              "                    -0.5790002077570349, -0.5711034486442714, -0.5360902805172256,\n",
              "                    -0.4841272107642509, -0.6261749796743128, -0.3248685810119971,\n",
              "                    0.12409658470314999, 0.02317805519986038, -0.6789874794013588,\n",
              "                    -0.43500485183106785, -0.6608291936854449, -0.3559460030409325,\n",
              "                    -0.5658216957263, -0.5237312706607529, -0.7535816634058707,\n",
              "                    -0.5814642885425079, -0.614065379881674, -0.5726323166092748,\n",
              "                    -0.7781096778574896, -0.6174028560114775, -0.464042394880424,\n",
              "                    -0.5612922745275717, -0.6192042410588361, -0.8262293498936188,\n",
              "                    -0.7755439236564563, -0.6013280649762904, -0.6812763696700326,\n",
              "                    -0.3933415068326016, -0.718565920500916, -0.41798778088211375,\n",
              "                    -0.7298353604430796, -0.3914286885474445, -0.767049809489861,\n",
              "                    -0.5909543206847574, -0.7370372834066552, 0.038590935364935075,\n",
              "                    0.03393171807313422, -0.6587258395489368, -0.7085886625311508,\n",
              "                    -0.5244446417626787, -0.655679023996615, -0.755125656934424,\n",
              "                    -0.6976262149840324, -0.06419525318622621, -0.2572215670602409]},\n",
              "             {'mode': 'lines',\n",
              "              'name': 'Best Value',\n",
              "              'type': 'scatter',\n",
              "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "                    34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
              "              'y': [-0.7100865569435306, -0.7100865569435306,\n",
              "                    -0.21397259812175662, -0.21397259812175662,\n",
              "                    -0.21397259812175662, -0.21397259812175662,\n",
              "                    -0.21397259812175662, -0.21397259812175662,\n",
              "                    -0.21397259812175662, -0.21397259812175662,\n",
              "                    -0.21397259812175662, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999, 0.12409658470314999, 0.12409658470314999,\n",
              "                    0.12409658470314999]},\n",
              "             {'marker': {'color': '#cccccc'},\n",
              "              'mode': 'markers',\n",
              "              'name': 'Infeasible Trial',\n",
              "              'showlegend': False,\n",
              "              'type': 'scatter',\n",
              "              'x': [],\n",
              "              'y': []}],\n",
              "    'layout': {'template': '...',\n",
              "               'title': {'text': 'Optimization History Plot'},\n",
              "               'xaxis': {'title': {'text': 'Trial'}},\n",
              "               'yaxis': {'title': {'text': 'Objective Value'}}}\n",
              "})"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Assuming 'study' is your Optuna study object\n",
        "optuna_viz.plot_optimization_history(study)\n",
        "# This plot tells us that Optuna made the score converge to the minimum after only a few trials.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "\n",
        "from optuna import Trial\n",
        "\n",
        "def objective(trial: Trial):\n",
        "    # Define the search space for hyperparameters\n",
        "    ppo_params = {\n",
        "        \"n_steps\": trial.suggest_int(\"n_steps\", 16, 512),\n",
        "        \"ent_coef\": trial.suggest_float(\"ent_coef\", 0.01, 0.1),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3),\n",
        "        \"batch_size\": trial.suggest_int(\"batch_size\", 32, 256),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    # Train the PPO model with the current set of hyperparameters\n",
        "    agent = DRLAgent(training_environment)\n",
        "    ppo_model = agent.get_model(\"ppo\", model_kwargs=ppo_params)\n",
        "    trained_ppo = DRLAgent(training_environment).train_model(\n",
        "        model=ppo_model,\n",
        "        tb_log_name='ppo',\n",
        "        total_timesteps=50000\n",
        "    ) \n",
        "\n",
        "    # Evaluate the model\n",
        "    trading_environment = StockTradingEnv(df=test, turbulence_threshold=70, risk_indicator_col='vix', hmax=100,\n",
        "                                          initial_amount=1000000, num_stock_shares=[0] * stock_size,\n",
        "                                          buy_cost_pct=[.1/100] * stock_size, sell_cost_pct=[.1/100] * stock_size,\n",
        "                                          state_space=state_space, stock_dim=stock_size,\n",
        "                                          tech_indicator_list=['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
        "                                                               'close_30_sma', 'close_60_sma'],\n",
        "                                          action_space=stock_size, reward_scaling=1e-4)\n",
        "    # env_trade, obs_trade = trading_environment.get_sb_env()\n",
        "\n",
        "    perf_stats = evaluate_model(trained_ppo, trading_environment)\n",
        "\n",
        "    # Return the metric to be optimized (negative because Optuna minimizes)\n",
        "    return -perf_stats.loc[\"Cumulative returns\"].iloc[-1]\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best parameters found by Optuna\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"Value: \", trial.value)\n",
        "print(\"Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\formatters.py:922\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    920\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\basedatatypes.py:832\u001b[0m, in \u001b[0;36mBaseFigure._ipython_display_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mrender_on_display \u001b[38;5;129;01mand\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mdefault:\n\u001b[1;32m--> 832\u001b[0m     \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\io\\_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         )\n\u001b[0;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "cliponaxis": false,
                  "hovertemplate": [
                    "batch_size (IntDistribution): 0.11105907981747143<extra></extra>",
                    "ent_coef (FloatDistribution): 0.13197466891561388<extra></extra>",
                    "learning_rate (FloatDistribution): 0.14949195384014954<extra></extra>",
                    "n_steps (IntDistribution): 0.6074742974267653<extra></extra>"
                  ],
                  "name": "Objective Value",
                  "orientation": "h",
                  "text": [
                    "0.11",
                    "0.13",
                    "0.15",
                    "0.61"
                  ],
                  "textposition": "outside",
                  "type": "bar",
                  "x": [
                    0.11105907981747143,
                    0.13197466891561388,
                    0.14949195384014954,
                    0.6074742974267653
                  ],
                  "y": [
                    "batch_size",
                    "ent_coef",
                    "learning_rate",
                    "n_steps"
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Hyperparameter Importances"
                },
                "xaxis": {
                  "title": {
                    "text": "Hyperparameter Importance"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Hyperparameter"
                  }
                }
              }
            },
            "text/html": [
              "<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"dcfa2b22-94af-40f4-a6f9-bbcdc7353043\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dcfa2b22-94af-40f4-a6f9-bbcdc7353043\")) {                    Plotly.newPlot(                        \"dcfa2b22-94af-40f4-a6f9-bbcdc7353043\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"batch_size (IntDistribution): 0.11105907981747143\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"ent_coef (FloatDistribution): 0.13197466891561388\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.14949195384014954\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_steps (IntDistribution): 0.6074742974267653\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.11\",\"0.13\",\"0.15\",\"0.61\"],\"textposition\":\"outside\",\"x\":[0.11105907981747143,0.13197466891561388,0.14949195384014954,0.6074742974267653],\"y\":[\"batch_size\",\"ent_coef\",\"learning_rate\",\"n_steps\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    )                };                            </script>        </div>"
            ],
            "text/plain": [
              "Figure({\n",
              "    'data': [{'cliponaxis': False,\n",
              "              'hovertemplate': [batch_size (IntDistribution):\n",
              "                                0.11105907981747143<extra></extra>, ent_coef\n",
              "                                (FloatDistribution):\n",
              "                                0.13197466891561388<extra></extra>, learning_rate\n",
              "                                (FloatDistribution):\n",
              "                                0.14949195384014954<extra></extra>, n_steps\n",
              "                                (IntDistribution):\n",
              "                                0.6074742974267653<extra></extra>],\n",
              "              'name': 'Objective Value',\n",
              "              'orientation': 'h',\n",
              "              'text': [0.11, 0.13, 0.15, 0.61],\n",
              "              'textposition': 'outside',\n",
              "              'type': 'bar',\n",
              "              'x': [0.11105907981747143, 0.13197466891561388, 0.14949195384014954,\n",
              "                    0.6074742974267653],\n",
              "              'y': [batch_size, ent_coef, learning_rate, n_steps]}],\n",
              "    'layout': {'template': '...',\n",
              "               'title': {'text': 'Hyperparameter Importances'},\n",
              "               'xaxis': {'title': {'text': 'Hyperparameter Importance'}},\n",
              "               'yaxis': {'title': {'text': 'Hyperparameter'}}}\n",
              "})"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optuna_viz.plot_param_importances(study)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\formatters.py:922\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    920\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\basedatatypes.py:832\u001b[0m, in \u001b[0;36mBaseFigure._ipython_display_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mrender_on_display \u001b[38;5;129;01mand\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mdefault:\n\u001b[1;32m--> 832\u001b[0m     \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\plotly\\io\\_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         )\n\u001b[0;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "markers",
                  "name": "Objective Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49
                  ],
                  "y": [
                    -0.5124958705334111,
                    -0.5856866617642265,
                    -0.5194945501737318,
                    -0.6184199020473322,
                    -0.5077888902906698,
                    -0.6791946261028796,
                    -0.6599081975650161,
                    -0.1837706936784973,
                    -0.7195930793213208,
                    -0.7584044135307464,
                    -0.43030969964823407,
                    -0.5073396363975156,
                    -0.43553434007988945,
                    -0.6310313428191201,
                    -0.3938149295723623,
                    0.05375602830212822,
                    -0.3031673732712039,
                    -0.5923634997030798,
                    -0.5645960089080171,
                    -0.6631998443791045,
                    -0.2043443953084263,
                    -0.5877518686713887,
                    -0.3670727513821881,
                    0.07473550367390036,
                    -0.5476359159729913,
                    -0.6317554726800689,
                    0.10039041118762804,
                    -0.592510855007248,
                    -0.7045172120405618,
                    -0.598332406853753,
                    -0.512576725967173,
                    -0.4920544592379146,
                    -0.6257581237981031,
                    -0.611195066986697,
                    -0.5100382937231676,
                    -0.5038613130974894,
                    -0.20959089985741408,
                    -0.64197243611566,
                    -0.6484012471186971,
                    0.04142650937903869,
                    -0.4271411404354941,
                    -0.6711611925488983,
                    -0.7624863368493024,
                    -0.646098971840162,
                    -0.3943767163141665,
                    -0.7210185731162555,
                    0.10974241150833364,
                    -0.24748483284490486,
                    -0.515170005581935,
                    -0.9134124409489994
                  ]
                },
                {
                  "mode": "lines",
                  "name": "Best Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    40,
                    41,
                    42,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49
                  ],
                  "y": [
                    -0.5124958705334111,
                    -0.5124958705334111,
                    -0.5124958705334111,
                    -0.5124958705334111,
                    -0.5077888902906698,
                    -0.5077888902906698,
                    -0.5077888902906698,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    -0.1837706936784973,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.05375602830212822,
                    0.07473550367390036,
                    0.07473550367390036,
                    0.07473550367390036,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10039041118762804,
                    0.10974241150833364,
                    0.10974241150833364,
                    0.10974241150833364,
                    0.10974241150833364
                  ]
                },
                {
                  "marker": {
                    "color": "#cccccc"
                  },
                  "mode": "markers",
                  "name": "Infeasible Trial",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [],
                  "y": []
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Optimization History Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "Trial"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                }
              }
            },
            "text/html": [
              "<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"6e174c99-3b3d-4b4b-8e11-e7dbe2bf4501\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6e174c99-3b3d-4b4b-8e11-e7dbe2bf4501\")) {                    Plotly.newPlot(                        \"6e174c99-3b3d-4b4b-8e11-e7dbe2bf4501\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[-0.5124958705334111,-0.5856866617642265,-0.5194945501737318,-0.6184199020473322,-0.5077888902906698,-0.6791946261028796,-0.6599081975650161,-0.1837706936784973,-0.7195930793213208,-0.7584044135307464,-0.43030969964823407,-0.5073396363975156,-0.43553434007988945,-0.6310313428191201,-0.3938149295723623,0.05375602830212822,-0.3031673732712039,-0.5923634997030798,-0.5645960089080171,-0.6631998443791045,-0.2043443953084263,-0.5877518686713887,-0.3670727513821881,0.07473550367390036,-0.5476359159729913,-0.6317554726800689,0.10039041118762804,-0.592510855007248,-0.7045172120405618,-0.598332406853753,-0.512576725967173,-0.4920544592379146,-0.6257581237981031,-0.611195066986697,-0.5100382937231676,-0.5038613130974894,-0.20959089985741408,-0.64197243611566,-0.6484012471186971,0.04142650937903869,-0.4271411404354941,-0.6711611925488983,-0.7624863368493024,-0.646098971840162,-0.3943767163141665,-0.7210185731162555,0.10974241150833364,-0.24748483284490486,-0.515170005581935,-0.9134124409489994],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[-0.5124958705334111,-0.5124958705334111,-0.5124958705334111,-0.5124958705334111,-0.5077888902906698,-0.5077888902906698,-0.5077888902906698,-0.1837706936784973,-0.1837706936784973,-0.1837706936784973,-0.1837706936784973,-0.1837706936784973,-0.1837706936784973,-0.1837706936784973,-0.1837706936784973,0.05375602830212822,0.05375602830212822,0.05375602830212822,0.05375602830212822,0.05375602830212822,0.05375602830212822,0.05375602830212822,0.05375602830212822,0.07473550367390036,0.07473550367390036,0.07473550367390036,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10039041118762804,0.10974241150833364,0.10974241150833364,0.10974241150833364,0.10974241150833364],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    )                };                            </script>        </div>"
            ],
            "text/plain": [
              "Figure({\n",
              "    'data': [{'mode': 'markers',\n",
              "              'name': 'Objective Value',\n",
              "              'type': 'scatter',\n",
              "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "                    34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
              "              'y': [-0.5124958705334111, -0.5856866617642265, -0.5194945501737318,\n",
              "                    -0.6184199020473322, -0.5077888902906698, -0.6791946261028796,\n",
              "                    -0.6599081975650161, -0.1837706936784973, -0.7195930793213208,\n",
              "                    -0.7584044135307464, -0.43030969964823407, -0.5073396363975156,\n",
              "                    -0.43553434007988945, -0.6310313428191201, -0.3938149295723623,\n",
              "                    0.05375602830212822, -0.3031673732712039, -0.5923634997030798,\n",
              "                    -0.5645960089080171, -0.6631998443791045, -0.2043443953084263,\n",
              "                    -0.5877518686713887, -0.3670727513821881, 0.07473550367390036,\n",
              "                    -0.5476359159729913, -0.6317554726800689, 0.10039041118762804,\n",
              "                    -0.592510855007248, -0.7045172120405618, -0.598332406853753,\n",
              "                    -0.512576725967173, -0.4920544592379146, -0.6257581237981031,\n",
              "                    -0.611195066986697, -0.5100382937231676, -0.5038613130974894,\n",
              "                    -0.20959089985741408, -0.64197243611566, -0.6484012471186971,\n",
              "                    0.04142650937903869, -0.4271411404354941, -0.6711611925488983,\n",
              "                    -0.7624863368493024, -0.646098971840162, -0.3943767163141665,\n",
              "                    -0.7210185731162555, 0.10974241150833364, -0.24748483284490486,\n",
              "                    -0.515170005581935, -0.9134124409489994]},\n",
              "             {'mode': 'lines',\n",
              "              'name': 'Best Value',\n",
              "              'type': 'scatter',\n",
              "              'x': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "                    18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "                    34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
              "              'y': [-0.5124958705334111, -0.5124958705334111, -0.5124958705334111,\n",
              "                    -0.5124958705334111, -0.5077888902906698, -0.5077888902906698,\n",
              "                    -0.5077888902906698, -0.1837706936784973, -0.1837706936784973,\n",
              "                    -0.1837706936784973, -0.1837706936784973, -0.1837706936784973,\n",
              "                    -0.1837706936784973, -0.1837706936784973, -0.1837706936784973,\n",
              "                    0.05375602830212822, 0.05375602830212822, 0.05375602830212822,\n",
              "                    0.05375602830212822, 0.05375602830212822, 0.05375602830212822,\n",
              "                    0.05375602830212822, 0.05375602830212822, 0.07473550367390036,\n",
              "                    0.07473550367390036, 0.07473550367390036, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10039041118762804, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10039041118762804, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10039041118762804, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10039041118762804, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10039041118762804, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10039041118762804, 0.10039041118762804,\n",
              "                    0.10039041118762804, 0.10974241150833364, 0.10974241150833364,\n",
              "                    0.10974241150833364, 0.10974241150833364]},\n",
              "             {'marker': {'color': '#cccccc'},\n",
              "              'mode': 'markers',\n",
              "              'name': 'Infeasible Trial',\n",
              "              'showlegend': False,\n",
              "              'type': 'scatter',\n",
              "              'x': [],\n",
              "              'y': []}],\n",
              "    'layout': {'template': '...',\n",
              "               'title': {'text': 'Optimization History Plot'},\n",
              "               'xaxis': {'title': {'text': 'Trial'}},\n",
              "               'yaxis': {'title': {'text': 'Objective Value'}}}\n",
              "})"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optuna_viz.plot_optimization_history(study)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>account_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>1.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-07-02</td>\n",
              "      <td>1.000051e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-07-06</td>\n",
              "      <td>1.000295e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-07-07</td>\n",
              "      <td>9.998629e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-07-08</td>\n",
              "      <td>1.000341e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>2023-10-23</td>\n",
              "      <td>1.369411e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>2023-10-24</td>\n",
              "      <td>1.377961e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>2023-10-25</td>\n",
              "      <td>1.410907e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>2023-10-26</td>\n",
              "      <td>1.359492e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>2023-10-27</td>\n",
              "      <td>1.363655e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>838 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  account_value\n",
              "0    2020-07-01   1.000000e+06\n",
              "1    2020-07-02   1.000051e+06\n",
              "2    2020-07-06   1.000295e+06\n",
              "3    2020-07-07   9.998629e+05\n",
              "4    2020-07-08   1.000341e+06\n",
              "..          ...            ...\n",
              "833  2023-10-23   1.369411e+06\n",
              "834  2023-10-24   1.377961e+06\n",
              "835  2023-10-25   1.410907e+06\n",
              "836  2023-10-26   1.359492e+06\n",
              "837  2023-10-27   1.363655e+06\n",
              "\n",
              "[838 rows x 2 columns]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value_ppo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (839, 8)\n",
            "Annual return          0.105063\n",
            "Cumulative returns     0.394607\n",
            "Annual volatility      0.245297\n",
            "Sharpe ratio           0.530538\n",
            "Calmar ratio           0.295428\n",
            "Stability              0.044324\n",
            "Max drawdown          -0.355631\n",
            "Omega ratio            1.092124\n",
            "Sortino ratio          0.750085\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.952510\n",
            "Daily value at risk   -0.030388\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\adiln\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning:\n",
            "\n",
            "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "df_ndx_ = get_baseline(\n",
        "        ticker=\"^NDX\", \n",
        "        start = '2020-07-01',\n",
        "        end = '2023-10-31')\n",
        "stats = backtest_stats(df_ndx_, value_col_name = 'close')\n",
        "df_ndx = pd.DataFrame()\n",
        "df_ndx['date'] = df_account_value_a2c['date']\n",
        "df_ndx['account_value'] = df_ndx_['close'] / df_ndx_['close'][0] * 1000000 # INITIAL AMOUNT HERE!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>account_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>1.000000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-07-02</td>\n",
              "      <td>1.006094e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-07-06</td>\n",
              "      <td>1.031599e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-07-07</td>\n",
              "      <td>1.023811e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-07-08</td>\n",
              "      <td>1.037692e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>2023-10-23</td>\n",
              "      <td>1.420809e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>2023-10-24</td>\n",
              "      <td>1.434527e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>2023-10-25</td>\n",
              "      <td>1.399094e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>2023-10-26</td>\n",
              "      <td>1.372626e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>2023-10-27</td>\n",
              "      <td>1.379519e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>838 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  account_value\n",
              "0    2020-07-01   1.000000e+06\n",
              "1    2020-07-02   1.006094e+06\n",
              "2    2020-07-06   1.031599e+06\n",
              "3    2020-07-07   1.023811e+06\n",
              "4    2020-07-08   1.037692e+06\n",
              "..          ...            ...\n",
              "833  2023-10-23   1.420809e+06\n",
              "834  2023-10-24   1.434527e+06\n",
              "835  2023-10-25   1.399094e+06\n",
              "836  2023-10-26   1.372626e+06\n",
              "837  2023-10-27   1.379519e+06\n",
              "\n",
              "[838 rows x 2 columns]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ndx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# BEFORE TUNING AND AFTER TUNING\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting code\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.plot(df_account_value_a2c.index, df_account_value_a2c['account_value'], label='A2C')\n",
        "# plt.plot(df_account_value_ddpg.index, df_account_value_ddpg['account_value'], label='DDPG')\n",
        "plt.plot(df_account_value_ppo.index, df_account_value_ppo['account_value'], label='PPO')\n",
        "plt.plot(df_ndx.index, df_ndx['account_value'], label='NDX')\n",
        "\n",
        "plt.title('A2C vs PPO Performance')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Account Value')\n",
        "plt.legend()\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_gDkU-j-fCmZ",
        "3Zpv4S0-fDBv"
      ],
      "name": "Stock_NeurIPS2018.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
